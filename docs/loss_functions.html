---

title: Loss functions


keywords: fastai
sidebar: home_sidebar

summary: "API details."
description: "API details."
nb_path: "nbs/60_loss_functions.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/60_loss_functions.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c1f0>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c1f0></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c1f0></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="prox_D_gaussian" class="doc_header"><code>prox_D_gaussian</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L2843" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>prox_D_gaussian</code>(<strong><code>z</code></strong>, <strong><code>z_hat</code></strong>, <strong><code>a</code></strong>, <strong><code>beta</code></strong>)</p>
</blockquote>
<p>Proximal operator of the Gaussian log-likelihood.</p>
<p>:param z:           D x K x My x Mx x 2, updated exit waves
:param z_hat:       D x K x My x Mx x 2, current model exit waves
:param a:           D x K x My x Mx,     measured amplitudes
:param beta:        float                hyperparameter</p>
<p>:return: z</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c220>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c220></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c220></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gradz_poisson_sparse" class="doc_header"><code>gradz_poisson_sparse</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L2897" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gradz_poisson_sparse</code>(<strong><code>out</code></strong>, <strong><code>z</code></strong>, <strong><code>a_indices</code></strong>, <strong><code>a_counts</code></strong>)</p>
</blockquote>
<p>Proximal operator of the Gaussian log-likelihood. Sparse version</p>
<p>:param z:           D x K x My x Mx x 2, updated exit waves
:param z_hat:       D x K x My x Mx x 2, current model exit waves
:param a_indices:   D x K x cts,     measured amplitude indices
:param a_counts:    D x K x cts,     measured amplitude counts
:param beta:        float                hyperparameter</p>
<p>:return: z</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c070>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c070></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c070></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gradz_gaussian_sparse" class="doc_header"><code>gradz_gaussian_sparse</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L2953" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gradz_gaussian_sparse</code>(<strong><code>out</code></strong>, <strong><code>z</code></strong>, <strong><code>a_indices</code></strong>, <strong><code>a_counts</code></strong>)</p>
</blockquote>
<p>Proximal operator of the Gaussian log-likelihood. Sparse version</p>
<p>:param z:           D x K x My x Mx x 2, updated exit waves
:param z_hat:       D x K x My x Mx x 2, current model exit waves
:param a_indices:   D x K x cts,     measured amplitude indices
:param a_counts:    D x K x cts,     measured amplitude counts
:param beta:        float                hyperparameter</p>
<p>:return: z</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c250>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c250></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c250></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sparse_amplitude_loss" class="doc_header"><code>sparse_amplitude_loss</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L2995" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>sparse_amplitude_loss</code>(<strong><code>a_model</code></strong>, <strong><code>indices_target</code></strong>, <strong><code>counts_target</code></strong>, <strong><code>frame_dimensions</code></strong>)</p>
</blockquote>
<p>:param a_model:             K x M1 x M2
:param indices_target:      K x num_max_counts
:param counts_target:       K x num_max_counts
:param frame_dimensions:    2
:return: loss (1,), grad (K x M1 x M2)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c280>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c280></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c280></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sparse_smooth_truncated_amplitude_loss" class="doc_header"><code>sparse_smooth_truncated_amplitude_loss</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L3045" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>sparse_smooth_truncated_amplitude_loss</code>(<strong><code>a_model</code></strong>, <strong><code>indices_target</code></strong>, <strong><code>counts_target</code></strong>, <strong><code>frame_dimensions</code></strong>, <strong><code>eps</code></strong>=<em><code>0.1</code></em>)</p>
</blockquote>
<p>Smooth truncated amplitude loss from Chang et al., Overlapping Domain Decomposition Methods for Ptychographic Imaging, (2020)</p>
<p>:param a_model:             K x M1 x M2
:param indices_target:      K x num_max_counts
:param counts_target:       K x num_max_counts
:param frame_dimensions:    2
:return: loss (K,), grad (K x M1 x M2)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c2b0>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c2b0></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c2b0></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sparse_smooth_truncated_amplitude_prox" class="doc_header"><code>sparse_smooth_truncated_amplitude_prox</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L3099" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>sparse_smooth_truncated_amplitude_prox</code>(<strong><code>a_model</code></strong>, <strong><code>indices_target</code></strong>, <strong><code>counts_target</code></strong>, <strong><code>frame_dimensions</code></strong>, <strong><code>eps</code></strong>=<em><code>0.5</code></em>, <strong><code>lam</code></strong>=<em><code>0.6</code></em>)</p>
</blockquote>
<p>Smooth truncated amplitude loss from Chang et al., Overlapping Domain Decomposition Methods for Ptychographic Imaging, (2020)</p>
<p>:param a_model:             K x M1 x M2
:param indices_target:      K x num_max_counts
:param counts_target:       K x num_max_counts
:param frame_dimensions:    2
:return: loss (K,), grad (K x M1 x M2)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="AutoJitCUDAKernel object at 0x7fd266a0c2e0>" class="doc_header"><code>AutoJitCUDAKernel object at 0x7fd266a0c2e0></code><a href="" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>AutoJitCUDAKernel object at 0x7fd266a0c2e0></code>(<strong>*<code>args</code></strong>)</p>
</blockquote>
<p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
&amp; compute capability, and launch on the device associated with the current
context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the :func:<code>numba.cuda.jit</code> decorator.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="sparse_amplitude_prox" class="doc_header"><code>sparse_amplitude_prox</code><a href="https://github.com/s-matrix/smpr3d/tree/master/smpr3d/util.py#L3146" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>sparse_amplitude_prox</code>(<strong><code>a_model</code></strong>, <strong><code>indices_target</code></strong>, <strong><code>counts_target</code></strong>, <strong><code>frame_dimensions</code></strong>, <strong><code>eps</code></strong>=<em><code>0.5</code></em>, <strong><code>lam</code></strong>=<em><code>0.6</code></em>)</p>
</blockquote>
<p>Smooth truncated amplitude loss from Chang et al., Overlapping Domain Decomposition Methods for Ptychographic Imaging, (2020)</p>
<p>:param a_model:             K x M1 x M2
:param indices_target:      K x num_max_counts
:param counts_target:       K x num_max_counts
:param frame_dimensions:    2
:return: loss (K,), grad (K x M1 x M2)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

</div>
 

