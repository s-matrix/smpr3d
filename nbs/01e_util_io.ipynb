{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util io\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import h5py\n",
    "import numpy as np\n",
    "# import cPickle\n",
    "import time\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "h5options = dict(\n",
    "    H5RW_VERSION='0.1',\n",
    "    H5PY_VERSION=h5py.version.version,\n",
    "    # UNSUPPORTED = 'pickle'\n",
    "    # UNSUPPORTED = 'ignore'\n",
    "    UNSUPPORTED='fail',\n",
    "    SLASH_ESCAPE='_SLASH_')\n",
    "\n",
    "\n",
    "def sdebug(f):\n",
    "    \"\"\" \n",
    "    debugging decorator for _store functions\n",
    "    \"\"\"\n",
    "\n",
    "    def newf(*args, **kwds):\n",
    "        print('{0:20} {1:20}'.format(f.func_name, args[2]))\n",
    "        return f(*args, **kwds)\n",
    "\n",
    "    newf.__doc__ = f.__doc__\n",
    "    return newf\n",
    "\n",
    "\n",
    "def _h5write(filename, mode, *args, **kwargs):\n",
    "    \"\"\"\\\n",
    "    _h5write(filename, mode, {'var1'=..., 'var2'=..., ...})\n",
    "    _h5write(filename, mode, var1=..., var2=..., ...)\n",
    "    _h5write(filename, mode, dict, var1=..., var2=...)\n",
    "    \n",
    "    Writes variables var1, var2, ... to file filename. The file mode\n",
    "    can be chosen according to the h5py documentation. The key-value\n",
    "    arguments have precedence on the provided dictionnary.\n",
    "\n",
    "    supported variable types are:\n",
    "    * scalars\n",
    "    * numpy arrays\n",
    "    * strings\n",
    "    * lists\n",
    "    * dictionaries\n",
    "\n",
    "    (if the option UNSUPPORTED is equal to 'pickle', any other type\n",
    "    is pickled and saved. UNSUPPORTED = 'ignore' silently eliminates\n",
    "    unsupported types. Default is 'fail', which raises an error.) \n",
    "    \n",
    "    The file mode can be chosen according to the h5py documentation.\n",
    "    It defaults to overwriting an existing file.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = os.path.abspath(os.path.expanduser(filename))\n",
    "\n",
    "    ctime = time.asctime()\n",
    "    mtime = ctime\n",
    "\n",
    "    # Update input dictionnary\n",
    "    if args:\n",
    "        d = args[0].copy()  # shallow copy\n",
    "    else:\n",
    "        d = {}\n",
    "    d.update(kwargs)\n",
    "\n",
    "    # List of object ids to make sure we are not saving something twice.\n",
    "    ids = []\n",
    "\n",
    "    # This is needed to store strings\n",
    "    dt = h5py.new_vlen(str)\n",
    "\n",
    "    def check_id(id):\n",
    "        if id in ids:\n",
    "            raise RuntimeError('Circular reference detected! Aborting save.')\n",
    "        else:\n",
    "            ids.append(id)\n",
    "\n",
    "    def pop_id(id):\n",
    "        ids[:] = [x for x in ids if x != id]\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_numpy(group, a, name, compress=True):\n",
    "        if compress:\n",
    "            dset = group.create_dataset(name, data=a, compression='gzip')\n",
    "        else:\n",
    "            dset = group.create_dataset(name, data=a)\n",
    "        dset.attrs['type'] = 'array'\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_string(group, s, name):\n",
    "        dset = group.create_dataset(name, data=np.asarray(s), dtype=dt)\n",
    "        dset.attrs['type'] = 'string'\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_unicode(group, s, name):\n",
    "        dset = group.create_dataset(name, data=np.asarray(s.encode('utf8')), dtype=dt)\n",
    "        dset.attrs['type'] = 'unicode'\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_list(group, l, name):\n",
    "        check_id(id(l))\n",
    "        arrayOK = len(set([type(x) for x in l])) == 1\n",
    "        if arrayOK:\n",
    "            try:\n",
    "                # Try conversion to a numpy array\n",
    "                la = np.array(l)\n",
    "                if la.dtype.type is np.string_:\n",
    "                    arrayOK = False\n",
    "                else:\n",
    "                    dset = _store_numpy(group, la, name)\n",
    "                    dset.attrs['type'] = 'arraylist'\n",
    "            except:\n",
    "                arrayOK = False\n",
    "        if not arrayOK:\n",
    "            # inhomogenous list. Store all elements individually\n",
    "            dset = group.create_group(name)\n",
    "            for i, v in enumerate(l):\n",
    "                _store(dset, v, '%05d' % i)\n",
    "            dset.attrs['type'] = 'list'\n",
    "        pop_id(id(l))\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_tuple(group, t, name):\n",
    "        dset = _store_list(group, list(t), name)\n",
    "        dset_type = dset.attrs['type']\n",
    "        dset.attrs['type'] = 'arraytuple' if dset_type == 'arraylist' else 'tuple'\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_dict(group, d, name):\n",
    "        check_id(id(d))\n",
    "        if any([type(k) not in [str,] for k in d.keys()]):\n",
    "            raise RuntimeError('Only dictionaries with string keys are supported.')\n",
    "        dset = group.create_group(name)\n",
    "        dset.attrs['type'] = 'dict'\n",
    "        for k, v in d.items():\n",
    "            if k.find('/') > -1:\n",
    "                k = k.replace('/', h5options['SLASH_ESCAPE'])\n",
    "                ndset = _store(dset, v, k)\n",
    "                if ndset is not None:\n",
    "                    ndset.attrs['escaped'] = '1'\n",
    "            else:\n",
    "                _store(dset, v, k)\n",
    "        pop_id(id(d))\n",
    "        return dset\n",
    "\n",
    "    def _store_dict_new(group, d, name):\n",
    "        check_id(id(d))\n",
    "        dset = group.create_group(name)\n",
    "        dset.attrs['type'] = 'dict'\n",
    "        for i, kv in enumerate(d.iteritems()):\n",
    "            _store(dset, kv, '%05d' % i)\n",
    "        pop_id(id(d))\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store_None(group, a, name):\n",
    "        dset = group.create_dataset(name, data=np.zeros((1,)))\n",
    "        dset.attrs['type'] = 'None'\n",
    "        return dset\n",
    "\n",
    "    # @sdebug\n",
    "    # def _store_pickle(group, a, name):\n",
    "    #     apic = cPickle.dumps(a)\n",
    "    #     dset = group.create_dataset(name, data=np.asarray(apic), dtype=dt)\n",
    "    #     dset.attrs['type'] = 'pickle'\n",
    "    #     return dset\n",
    "\n",
    "    # @sdebug\n",
    "    def _store(group, a, name):\n",
    "        if type(a) is str:\n",
    "            dset = _store_string(group, a, name)\n",
    "        # elif type(a) is unicode:\n",
    "        #     dset = _store_unicode(group, a, name)\n",
    "        elif type(a) is dict:\n",
    "            dset = _store_dict(group, a, name)\n",
    "        elif type(a) is list:\n",
    "            dset = _store_list(group, a, name)\n",
    "        elif type(a) is tuple:\n",
    "            dset = _store_tuple(group, a, name)\n",
    "        elif type(a) is np.ndarray:\n",
    "            dset = _store_numpy(group, a, name)\n",
    "        elif np.isscalar(a):\n",
    "            dset = _store_numpy(group, np.asarray(a), name, compress=False)\n",
    "            dset.attrs['type'] = 'scalar'\n",
    "        elif a is None:\n",
    "            dset = _store_None(group, a, name)\n",
    "        else:\n",
    "            if h5options['UNSUPPORTED'] == 'fail':\n",
    "                raise RuntimeError('Unsupported data type : %s' % type(a))\n",
    "            elif h5options['UNSUPPORTED'] == 'pickle':\n",
    "                dset = _store_pickle(group, a, name)\n",
    "            else:\n",
    "                dset = None\n",
    "        return dset\n",
    "\n",
    "    # Open the file and save everything\n",
    "    with h5py.File(filename, mode) as f:\n",
    "        f.attrs['h5rw_version'] = h5options['H5RW_VERSION']\n",
    "        f.attrs['ctime'] = ctime\n",
    "        f.attrs['mtime'] = mtime\n",
    "        for k, v in d.items():\n",
    "            _store(f, v, k)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def h5write(filename, *args, **kwargs):\n",
    "    \"\"\"\\\n",
    "    h5write(filename, {'var1'=..., 'var2'=..., ...})\n",
    "    h5write(filename, var1=..., var2=..., ...)\n",
    "    h5write(filename, dict, var1=..., var2=...)\n",
    "    \n",
    "    Writes variables var1, var2, ... to file filename. The key-value\n",
    "    arguments have precedence on the provided dictionnary.\n",
    "\n",
    "    supported variable types are:\n",
    "    * scalars\n",
    "    * numpy arrays\n",
    "    * strings\n",
    "    * lists\n",
    "    * dictionaries\n",
    "\n",
    "    (if the option UNSUPPORTED is equal to 'pickle', any other type\n",
    "    is pickled and saved. UNSUPPORTED = 'ignore' silently eliminates\n",
    "    unsupported types. Default is 'fail', which raises an error.) \n",
    "    \n",
    "    The file mode can be chosen according to the h5py documentation.\n",
    "    It defaults to overwriting an existing file.\n",
    "    \"\"\"\n",
    "\n",
    "    _h5write(filename, 'w', *args, **kwargs)\n",
    "    return\n",
    "\n",
    "\n",
    "def h5append(filename, *args, **kwargs):\n",
    "    \"\"\"\\\n",
    "    h5append(filename, {'var1'=..., 'var2'=..., ...})\n",
    "    h5append(filename, var1=..., var2=..., ...)\n",
    "    h5append(filename, dict, var1=..., var2=...)\n",
    "    \n",
    "    Appends variables var1, var2, ... to file filename. The \n",
    "    key-value arguments have precedence on the provided dictionnary.\n",
    "\n",
    "    supported variable types are:\n",
    "    * scalars\n",
    "    * numpy arrays\n",
    "    * strings\n",
    "    * lists\n",
    "    * dictionaries\n",
    "\n",
    "    (if the option UNSUPPORTED is equal to 'pickle', any other type\n",
    "    is pickled and saved. UNSUPPORTED = 'ignore' silently eliminates\n",
    "    unsupported types. Default is 'fail', which raises an error.) \n",
    "    \n",
    "    The file mode can be chosen according to the h5py documentation.\n",
    "    It defaults to overwriting an existing file.\n",
    "    \"\"\"\n",
    "\n",
    "    _h5write(filename, 'a', *args, **kwargs)\n",
    "    return\n",
    "\n",
    "\n",
    "def h5read(filename, *args, **kwargs):\n",
    "    \"\"\"\\\n",
    "    h5read(filename)\n",
    "    h5read(filename, s1, s2, ...)\n",
    "    h5read(filename, (s1,s2, ...))\n",
    "    \n",
    "    Read variables from a hdf5 file created with h5write and returns them as \n",
    "    a dictionary.\n",
    "    \n",
    "    If specified, only variable named s1, s2, ... are loaded.\n",
    "    \n",
    "    Variable names support slicing and group access. For instance, provided \n",
    "    that the file contains the appropriate objects, the following syntax is \n",
    "    valid:\n",
    "        \n",
    "    a = h5read('file.h5', 'myarray[2:4]')\n",
    "    a = h5read('file.h5', 'adict.thekeyIwant')\n",
    "    \n",
    "    h5read(filename_with_wildcard, ... , doglob=True)\n",
    "    Reads sequentially all globbed filenames. \n",
    " \n",
    "    \"\"\"\n",
    "    doglob = kwargs.get('doglob', None)\n",
    "\n",
    "    # Used if we read a list of files\n",
    "    fnames = []\n",
    "    if not isinstance(filename, str):\n",
    "        # We have a list\n",
    "        fnames = filename\n",
    "    else:\n",
    "        if doglob is None:\n",
    "            # glob only if there is a wildcard in the filename\n",
    "            doglob = glob.has_magic(filename)\n",
    "        if doglob:\n",
    "            fnames = sorted(glob.glob(filename))\n",
    "            if not fnames:\n",
    "                raise IOError('%s : no match.' % filename)\n",
    "\n",
    "    if fnames:\n",
    "        # We are here only if globbing was allowed.\n",
    "        dl = []\n",
    "        # Loop over file names\n",
    "        for f in fnames:\n",
    "            # Call again, but this time without globbing.\n",
    "            d = h5read(f, *args, doglob=False, **kwargs)\n",
    "            dl.append(d)\n",
    "        return dl\n",
    "\n",
    "    # We are here only if there was no globbing (fnames is empty)\n",
    "    filename = os.path.abspath(os.path.expanduser(filename))\n",
    "\n",
    "    def _load_dict_new(dset):\n",
    "        d = {}\n",
    "        keys = dset.keys()\n",
    "        keys.sort()\n",
    "        for k in keys:\n",
    "            dk, dv = _load(dset[k])\n",
    "            d[dk] = dv\n",
    "        return d\n",
    "\n",
    "    def _load_dict(dset):\n",
    "        d = {}\n",
    "        for k, v in dset.items():\n",
    "            if v.attrs.get('escaped', None) is not None:\n",
    "                k = k.replace(h5options['SLASH_ESCAPE'], '/')\n",
    "            d[k] = _load(v)\n",
    "        return d\n",
    "\n",
    "    def _load_list(dset):\n",
    "        l = []\n",
    "        keys = dset.keys()\n",
    "        keys.sort()\n",
    "        for k in keys:\n",
    "            l.append(_load(dset[k]))\n",
    "        return l\n",
    "\n",
    "    def _load_numpy(dset, sl=None):\n",
    "        if sl is not None:\n",
    "            return dset[sl]\n",
    "        else:\n",
    "            return dset[...]\n",
    "\n",
    "    def _load_scalar(dset):\n",
    "        try:\n",
    "            return dset[...].item()\n",
    "        except:\n",
    "            return dset[...]\n",
    "\n",
    "    def _load_str(dset):\n",
    "        return dset.value\n",
    "\n",
    "    def _load_unicode(dset):\n",
    "        return dset.value.decode('utf8')\n",
    "\n",
    "    # def _load_pickle(dset):\n",
    "    #     return cPickle.loads(dset[...])\n",
    "\n",
    "    def _load(dset, sl=None):\n",
    "        dset_type = dset.attrs.get('type', None)\n",
    "\n",
    "        # Treat groups as dicts\n",
    "        if (dset_type is None) and (type(dset) is h5py.Group):\n",
    "            dset_type = 'dict'\n",
    "\n",
    "        if dset_type == b'dict' or dset_type == 'dict':\n",
    "            if sl is not None:\n",
    "                raise RuntimeError('Dictionaries do not support slicing')\n",
    "            val = _load_dict(dset)\n",
    "        elif dset_type == b'list' or dset_type == 'list':\n",
    "            val = _load_list(dset)\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'array' or dset_type == 'array':\n",
    "            val = _load_numpy(dset, sl)\n",
    "        elif dset_type == b'arraylist' or dset_type == 'arraylist':\n",
    "            val = [x for x in _load_numpy(dset)]\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'tuple' or dset_type == 'tuple':\n",
    "            val = tuple(_load_list(dset))\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'arraytuple' or dset_type == 'arraytuple':\n",
    "            val = tuple(_load_numpy(dset).tolist())\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'string' or dset_type == 'string':\n",
    "            val = _load_str(dset)\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'unicode' or dset_type == 'unicode':\n",
    "            val = _load_str(dset)\n",
    "            if sl is not None:\n",
    "                val = val[sl]\n",
    "        elif dset_type == b'scalar' or dset_type == 'scalar':\n",
    "            val = _load_scalar(dset)\n",
    "        elif dset_type == 'None':\n",
    "            # 24.4.13 : B.E. commented due to hr5read not being able to return None type\n",
    "            # try:\n",
    "            #   val = _load_numpy(dset)\n",
    "            # except:\n",
    "            #    val = None\n",
    "            val = None\n",
    "        # elif dset_type == 'pickle':\n",
    "        #     val = _load_pickle(dset)\n",
    "        elif dset_type is None:\n",
    "            val = _load_numpy(dset)\n",
    "        else:\n",
    "            raise RuntimeError('Unsupported data type : %s' % dset_type)\n",
    "        return val\n",
    "\n",
    "    outdict = {}\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        h5rw_version = f.attrs.get('h5rw_version', None)\n",
    "        #        if h5rw_version is None:\n",
    "        #            print('Warning: this file does not seem to follow h5read format.')\n",
    "        ctime = f.attrs.get('ctime', None)\n",
    "        if ctime is not None:\n",
    "            print(f\"file created : {ctime}\")\n",
    "        if len(args) == 0:\n",
    "            # no input arguments - load everything\n",
    "            key_list = f.keys()\n",
    "        else:\n",
    "            if (len(args) == 1) and (type(args[0]) is list):\n",
    "                # input argument is a list of object names\n",
    "                key_list = args[0]\n",
    "            else:\n",
    "                # arguments form a list\n",
    "                key_list = list(args)\n",
    "        for k in key_list:\n",
    "            # detect slicing\n",
    "            if '[' in k:\n",
    "                k, slice_string = k.split('[')\n",
    "                slice_string = slice_string.split(']')[0]\n",
    "                sldims = slice_string.split(',')\n",
    "                sl = tuple(\n",
    "                    [slice(*[None if x.strip() == '' else int(x) for x in (s.split(':') + ['', '', ''])[:3]]) for s in\n",
    "                     sldims])\n",
    "            else:\n",
    "                sl = None\n",
    "\n",
    "            # detect group access\n",
    "            if '.' in k:\n",
    "                glist = k.split('.')\n",
    "                k = glist[-1]\n",
    "                gr = f[glist[0]]\n",
    "                for gname in glist[1:-1]:\n",
    "                    gr = gr[gname]\n",
    "                outdict[k] = _load(gr[k], sl)\n",
    "            else:\n",
    "                outdict[k] = _load(f[k], sl)\n",
    "\n",
    "    return outdict\n",
    "\n",
    "\n",
    "def h5info(filename, output=None):\n",
    "    \"\"\"\\\n",
    "    h5info(filename)\n",
    "\n",
    "    Prints out a tree structure of given h5 file.\n",
    "    \n",
    "    [17/01/2012 guillaume potdevin]\n",
    "    added optional argument output:\n",
    "    \tif output is set to 1, then the printed string is returned\n",
    "    \"\"\"\n",
    "\n",
    "    indent = 4\n",
    "    filename = os.path.abspath(os.path.expanduser(filename))\n",
    "\n",
    "    def _format_dict(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * %s [dict]:\\n' % key[1]\n",
    "        for k, v in dset.items():\n",
    "            if v.attrs.get('escaped', None) is not None:\n",
    "                k = k.replace(h5options['SLASH_ESCAPE'], '/')\n",
    "            stringout += _format((key[0] + indent, k), v)\n",
    "        return stringout\n",
    "\n",
    "    def _format_list(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * %s [list]:\\n' % key[1]\n",
    "        keys = dset.keys()\n",
    "        keys.sort()\n",
    "        for k in keys:\n",
    "            stringout += _format((key[0] + indent, ''), dset[k])\n",
    "        return stringout\n",
    "\n",
    "    def _format_tuple(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * %s [tuple]:\\n' % key[1]\n",
    "        keys = dset.keys()\n",
    "        keys.sort()\n",
    "        for k in keys:\n",
    "            stringout += _format((key[0] + indent, ''), dset[k])\n",
    "        return stringout\n",
    "\n",
    "    def _format_arraytuple(key, dset):\n",
    "        a = dset[...]\n",
    "        if len(a) < 5:\n",
    "            stringout = ' ' * key[0] + ' * ' + key[1] + ' [tuple = ' + str(tuple(a.ravel())) + ']\\n'\n",
    "        else:\n",
    "            try:\n",
    "                float(a.ravel()[0])\n",
    "                stringout = ' ' * key[0] + ' * ' + key[1] + ' [tuple = (' + (\n",
    "                            ('%f, ' * 4) % tuple(a.ravel()[:4])) + ' ...)]\\n'\n",
    "            except ValueError:\n",
    "                stringout = ' ' * key[0] + ' * ' + key[1] + ' [tuple = (%d x %s objects)]\\n' % (a.size, str(a.dtype))\n",
    "        return stringout\n",
    "\n",
    "    def _format_arraylist(key, dset):\n",
    "        a = dset[...]\n",
    "        if len(a) < 5:\n",
    "            stringout = ' ' * key[0] + ' * ' + key[1] + ' [list = ' + str(a.tolist()) + ']\\n'\n",
    "        else:\n",
    "            try:\n",
    "                float(a.ravel()[0])\n",
    "                stringout = ' ' * key[0] + ' * ' + key[1] + ' [list = [' + (\n",
    "                            ('%f, ' * 4) % tuple(a.ravel()[:4])) + ' ...]]\\n'\n",
    "            except ValueError:\n",
    "                stringout = ' ' * key[0] + ' * ' + key[1] + ' [list = [%d x %s objects]]\\n' % (a.size, str(a.dtype))\n",
    "        return stringout\n",
    "\n",
    "    def _format_numpy(key, dset):\n",
    "        a = dset[...]\n",
    "        if len(a) < 5 and a.ndim == 1:\n",
    "            stringout = ' ' * key[0] + ' * ' + key[1] + ' [array = ' + str(a.ravel()) + ']\\n'\n",
    "        else:\n",
    "            stringout = ' ' * key[0] + ' * ' + key[1] + ' [' + (('%dx' * (a.ndim - 1) + '%d') % a.shape) + ' ' + str(\n",
    "                a.dtype) + ' array]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_scalar(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [scalar = ' + str(dset[...]) + ']\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_str(key, dset):\n",
    "        s = str(dset[...])\n",
    "        if len(s) > 40:\n",
    "            s = s[:40] + '...'\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [string = \"' + s + '\"]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_unicode(key, dset):\n",
    "        s = str(dset[...]).decode('utf8')\n",
    "        if len(s) > 40:\n",
    "            s = s[:40] + '...'\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [unicode = \"' + s + '\"]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_pickle(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [pickled object]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_None(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [None]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format_unknown(key, dset):\n",
    "        stringout = ' ' * key[0] + ' * ' + key[1] + ' [unknown]\\n'\n",
    "        return stringout\n",
    "\n",
    "    def _format(key, dset):\n",
    "        dset_type = dset.attrs.get('type', None)\n",
    "\n",
    "        # Treat groups as dicts\n",
    "        if (dset_type is None) and (type(dset) is h5py.Group):\n",
    "            dset_type = 'dict'\n",
    "\n",
    "        if dset_type == 'dict':\n",
    "            stringout = _format_dict(key, dset)\n",
    "        elif dset_type == 'list':\n",
    "            stringout = _format_list(key, dset)\n",
    "        elif dset_type == 'array':\n",
    "            stringout = _format_numpy(key, dset)\n",
    "        elif dset_type == 'arraylist':\n",
    "            stringout = _format_arraylist(key, dset)\n",
    "        elif dset_type == 'tuple':\n",
    "            stringout = _format_tuple(key, dset)\n",
    "        elif dset_type == 'arraytuple':\n",
    "            stringout = _format_arraytuple(key, dset)\n",
    "        elif dset_type == 'string':\n",
    "            stringout = _format_str(key, dset)\n",
    "        elif dset_type == 'unicode':\n",
    "            stringout = _format_unicode(key, dset)\n",
    "        elif dset_type == 'scalar':\n",
    "            stringout = _format_scalar(key, dset)\n",
    "        elif dset_type == 'None':\n",
    "            try:\n",
    "                stringout = _format_numpy(key, dset)\n",
    "            except:\n",
    "                stringout = _format_None(key, dset)\n",
    "        elif dset_type == 'pickle':\n",
    "            stringout = _format_pickle(dset)\n",
    "        elif dset_type is None:\n",
    "            stringout = _format_numpy(key, dset)\n",
    "        else:\n",
    "            stringout = _format_unknown(key, dset)\n",
    "        return stringout\n",
    "\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        h5rw_version = f.attrs.get('h5rw_version', None)\n",
    "        #        if h5rw_version is None:\n",
    "        #            print('Warning: this file does not seem to follow h5read format.')\n",
    "        ctime = f.attrs.get('ctime', None)\n",
    "        #        if ctime is not None:\n",
    "        #            print('File created : ' + ctime)\n",
    "        key_list = f.keys()\n",
    "        outstring = ''\n",
    "        for k in key_list:\n",
    "            outstring += _format((0, k), f[k])\n",
    "\n",
    "    print(outstring)\n",
    "\n",
    "    # return string if output variable passed as option\n",
    "    if output != None:\n",
    "        return outstring\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
