{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasta algorithm\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63f3ee34bc17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearIndexEncoded4DDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense4DDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "#export \n",
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from smpr3d.operators import Qoverlap_real,  calc_psi_denom, \\\n",
    "    calc_psi, A_realspace, Qsplit, Qoverlap, SubpixShift, gradient_fourier_2d, prox_D_gaussian\n",
    "\n",
    "from tqdm import trange\n",
    "from smpr3d.util import plotAbsAngle, plot \n",
    "from typing import TYPE_CHECKING, List, NamedTuple, Optional, Union, Callable\n",
    "from dataclasses import dataclass\n",
    "from .data import LinearIndexEncoded4DDataset, Dense4DDataset, SMeta\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "import logging\n",
    "\n",
    "@dataclass\n",
    "class ADMMOptions:\n",
    "    r12 : float\n",
    "    r22 : float\n",
    "    eps1 : float\n",
    "    eps2 : float\n",
    "    dL_dr_momentum : float\n",
    "    dL_dr_step : float\n",
    "    beta : float \n",
    "    do_position_correction : Callable\n",
    "    do_subpix : bool\n",
    "    non_blocking : bool\n",
    "    margin : int\n",
    "    do_smoothing : bool\n",
    "    kernel_size : tuple\n",
    "    sigma : np.array\n",
    "    \n",
    "    def __init__(self, \n",
    "                 beta = 0.9, \n",
    "                 r12 = 1e-6, \n",
    "                 r22 = 1e-3, \n",
    "                 eps1 = 1e-6, \n",
    "                 eps2 = 1e-6, \n",
    "                 dL_dr_momentum = 1.0, \n",
    "                 dL_dr_step = 1e-3,\n",
    "                 do_position_correction = lambda it: True if it > 1 else False,\n",
    "                 do_subpix = True,\n",
    "                 non_blocking = False,\n",
    "                 verbose = False,\n",
    "                 do_smoothing = True,\n",
    "                 margin = 5,\n",
    "                 kernel_size = (9, 9),\n",
    "                 sigma = np.array((2.5, 2.5)),\n",
    "                 ):\n",
    "        self.r12 = r12\n",
    "        self.r22 = r22\n",
    "        self.eps1 = eps1\n",
    "        self.eps2 = eps2\n",
    "        self.dL_dr_momentum = dL_dr_momentum\n",
    "        self.dL_dr_step = dL_dr_step\n",
    "        self.do_position_correction = do_position_correction\n",
    "        self.do_subpix = do_subpix\n",
    "        self.non_blocking = non_blocking\n",
    "        self.beta = beta\n",
    "        self.verbose = verbose\n",
    "        self.do_smoothing = do_smoothing\n",
    "        self.margin = margin\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "    \n",
    "import h5py\n",
    "@dataclass\n",
    "class SMPRSolution:\n",
    "    converged: bool\n",
    "    smatrix: th.Tensor\n",
    "    probe: th.Tensor\n",
    "    positions: th.Tensor\n",
    "    r_factor: float\n",
    "    r_factor_history: th.Tensor\n",
    "    s_matrix_meta : SMeta\n",
    "    \n",
    "    def __init__(self, \n",
    "                 converged : bool, \n",
    "                 smatrix : th.Tensor, \n",
    "                 probe : th.tensor, \n",
    "                 positions : th.Tensor,\n",
    "                 r_factor : float,\n",
    "                 r_factor_history : th.Tensor,\n",
    "                 s_matrix_meta : SMeta):\n",
    "        self.converged = converged\n",
    "        self.smatrix = smatrix\n",
    "        self.probe = probe\n",
    "        self.positions = positions\n",
    "        self.r_factor = r_factor\n",
    "        self.r_factor_history = r_factor_history\n",
    "        self.s_matrix_meta = s_matrix_meta\n",
    "\n",
    "    def to_h5(self, file_path, key):\n",
    "        with h5py.File(file_path, 'a') as f:\n",
    "            g = f.create_group(key)\n",
    "            g.create_dataset('converged', data=self.converged)\n",
    "            g.create_dataset('smatrix', data=self.smatrix.cpu().numpy())\n",
    "            g.create_dataset('probe', data=self.probe.cpu().numpy())\n",
    "            g.create_dataset('positions', data=self.positions.cpu().numpy())\n",
    "            g.create_dataset('r_factor', data=self.r_factor)\n",
    "            g.create_dataset('r_factor_history', data=self.r_factor_history.cpu().numpy())\n",
    "        self.s_matrix_meta.to_h5(file_path, key + 's_meta')\n",
    "            \n",
    "    @staticmethod        \n",
    "    def from_h5(file_path, key):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            g = f[key]\n",
    "            converged = bool(g['converged'][()])\n",
    "            smatrix = th.as_tensor(g['smatrix'][...])\n",
    "            probe = th.as_tensor(g['probe'][...])\n",
    "            positions = th.as_tensor(g['positions'][...])\n",
    "            r_factor = float(g['r_factor'][()])\n",
    "            r_factor_history = th.as_tensor(g['r_factor_history'][...])\n",
    "            \n",
    "        s_meta = SMeta.from_h5(file_path, key + 's_meta')\n",
    "        \n",
    "        res = SMPRSolution(converged,\n",
    "                           smatrix,\n",
    "                           probe,\n",
    "                           positions,\n",
    "                           r_factor, \n",
    "                           r_factor_history, \n",
    "                           s_meta)\n",
    "        return res \n",
    "\n",
    "from kornia.filters import  gaussian_blur2d\n",
    "def gaussian(x, kernel_size, sigma):\n",
    "        srmax = x.real.max()\n",
    "        simax = x.real.max()\n",
    "        smr = gaussian_blur2d(x.real.unsqueeze(0), kernel_size, sigma,border_type='reflect')\n",
    "        smi = gaussian_blur2d(x.imag.unsqueeze(0), kernel_size, sigma,border_type='reflect')\n",
    "        smr = smr / smr.max() * srmax\n",
    "        smi = smi / smr.max() * simax\n",
    "        ret = smr + 1j * smi\n",
    "        return th.clone(ret[0])\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "def admm(measurements : Union[LinearIndexEncoded4DDataset, Dense4DDataset], \n",
    "         r : th.tensor, \n",
    "         psi0 : th.tensor, \n",
    "         s_meta : SMeta, \n",
    "         n_iter : int, \n",
    "         n_batches : int, \n",
    "         options : ADMMOptions) -> SMPRSolution:\n",
    "    \n",
    "    do_position_correction = options.do_position_correction\n",
    "    do_subpix = options.do_subpix\n",
    "    beta = options.beta\n",
    "    dL_dr_momentum = options.dL_dr_momentum\n",
    "    dL_dr_step = options.dL_dr_step\n",
    "    non_blocking = options.non_blocking\n",
    "    r12 = options.r12\n",
    "    r22 = options.r22\n",
    "    eps1 = options.eps1\n",
    "    eps2 = options.eps2\n",
    "    verbose = options.verbose\n",
    "    margin = options.margin\n",
    "    kernel_size = options.kernel_size\n",
    "    sigma = options.sigma.copy()\n",
    "    \n",
    "    cx_dtype = th.complex64\n",
    "    dev_z = th.device(f'cpu')\n",
    "    dev_compute = [th.device(f'cuda:{i}') for i in [0]]\n",
    "\n",
    "    M = s_meta.M\n",
    "    MY, MX = M[0].item(), M[1].item()\n",
    "    N = s_meta.N\n",
    "    NY, NX = N[0].item(), N[1].item()\n",
    "    K = r.shape[0]\n",
    "    batch_size = int(np.ceil(K / n_batches))\n",
    "    slic = np.s_[0, MY // 2 + margin:-MY *2 - margin, MX // 2 + margin:-MX *2 - margin]\n",
    "    \n",
    "    shift = SubpixShift(MY, MX, dev_compute[0])\n",
    "    sampler = BatchSampler(SequentialSampler(range(K)), batch_size=batch_size, drop_last=False)\n",
    "    \n",
    "    if isinstance(measurements, Dense4DDataset):\n",
    "        sum_I = 0\n",
    "        for batch_inds in sampler:\n",
    "            I_b = measurements[batch_inds]\n",
    "            sum_I += th.sum(I_b).item()   \n",
    "    elif isinstance(measurements, LinearIndexEncoded4DDataset):\n",
    "        sum_I = 0\n",
    "        for batch_inds in sampler:\n",
    "            I_b = measurements[batch_inds]\n",
    "            sum_I += th.sum(I_b.counts).item()        \n",
    "            \n",
    "    a_norm = np.sqrt(sum_I)   \n",
    "    Bp = s_meta.Bp\n",
    "    \n",
    "    z = th.zeros((K, MY, MX), dtype=cx_dtype, device=dev_z).pin_memory()\n",
    "    S_model = th.zeros((Bp, NY, NX), dtype=cx_dtype, device=dev_compute[0])\n",
    "    # S_model = th.ones((Bp, NY, NX), dtype=cx_dtype, device=dev_compute[0])\n",
    "    # S_model.imag[:] = 0\n",
    "    AtA = th.zeros((Bp, NY, NX), dtype=th.float32, device=dev_compute[0]) + 1e-6\n",
    "    z_hat = th.zeros_like(z)\n",
    "    Lambda = th.zeros_like(z)\n",
    "    r = th.as_tensor(r, device=dev_compute[0])\n",
    "    dL_dr_old = th.zeros_like(r)\n",
    "    \n",
    "    r_int = th.round(r).long()\n",
    "    dr = r - r_int\n",
    "    \n",
    "    sampler = BatchSampler(SequentialSampler(range(K)), batch_size=batch_size, drop_last=False)\n",
    "    # data_loader = DataLoader(measurements, shuffle=False, num_workers=0, pin_memory=False, sampler=sampler)\n",
    "    \n",
    "    for batch_inds in sampler:\n",
    "        zb = z[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "        I_b = measurements[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "        K_b = zb.shape[0]\n",
    "        \n",
    "        psi = th.broadcast_to(psi0[:, None, ...], (Bp, K_b, MY, MX))\n",
    "        zhb = th.fft.fft2(th.sum(psi, 0), norm='ortho') + 1e-4\n",
    "    \n",
    "        zb, _ = prox_D_gaussian(zb, zhb, I_b, 0)\n",
    "        z[batch_inds] = zb.to(dev_z, non_blocking=non_blocking)\n",
    "        \n",
    "    for batch_inds in sampler:\n",
    "        psi = shift(psi0, dr[batch_inds])\n",
    "        AtA = Qoverlap_real(r_int[batch_inds], th.abs(psi) ** 2, AtA)\n",
    "\n",
    "    for batch_inds in sampler:\n",
    "        psi = shift(psi0, dr[batch_inds])\n",
    "        zb = z[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "        zb = th.fft.ifft2(zb, norm='ortho')\n",
    "        zb = th.conj(psi) * zb\n",
    "        zb = shift(zb, dr[batch_inds])\n",
    "        S_model = Qoverlap(r_int[batch_inds], zb, S_model)\n",
    "    S_model /= AtA  \n",
    "\n",
    "    if verbose:\n",
    "        plotAbsAngle(S_model[slic].cpu(), 'S_model init')\n",
    "    \n",
    "    R_factors = []\n",
    "    # for i in trange(n_iter, desc = 'ADMM iterations'):\n",
    "    for i in range(n_iter):\n",
    "        start = timer()\n",
    "        for batch_inds in sampler:\n",
    "            zz = z[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            LL = Lambda[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            z_hat[batch_inds] = th.fft.ifft2(zz + LL / beta, norm='ortho').to(dev_z, non_blocking=non_blocking)\n",
    "        \n",
    "        if do_subpix and do_position_correction(i):\n",
    "            for batch_inds in sampler:\n",
    "                K_b = len(batch_inds)\n",
    "                S_split = th.zeros((Bp, K_b, MY, MX), dtype=cx_dtype, device=dev_compute[0])\n",
    "                z_hatb = z_hat[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "                \n",
    "                psi = shift(psi0, dr[batch_inds])\n",
    "                S_split = Qsplit(r_int[batch_inds], S_model, S_split)\n",
    "    \n",
    "                # 2 x Bp x K x MY x MX\n",
    "                dS_split_dr = gradient_fourier_2d(S_split)\n",
    "                # 2 x K x Bp x MY x MX\n",
    "                dS_split_drP = dS_split_dr * psi[None, ...]\n",
    "    \n",
    "                # 2 x Bp x K x MY x MX\n",
    "                nom = th.real(th.conj(dS_split_drP) * z_hatb[None, None, ...])\n",
    "                denom = th.abs(dS_split_drP) ** 2\n",
    "    \n",
    "                # 2 x K\n",
    "                dL_dr = th.sum(nom, (1, 3, 4)) / th.sum(denom, (1, 3, 4))\n",
    "                # K x 2\n",
    "                dL_dr = dL_dr.transpose(0, 1)\n",
    "                # max shift of +/-0.2 pixels\n",
    "                dL_dr = th.min(th.stack([th.abs(dL_dr), th.zeros_like(dL_dr).fill_(0.2)]), 0).values * th.sgn(dL_dr)\n",
    "    \n",
    "                dL_dr_up = dL_dr * dL_dr_step + dL_dr_old[batch_inds] * dL_dr_momentum\n",
    "                r[batch_inds] += dL_dr_up\n",
    "                r[batch_inds, 0] = th.clamp(r[batch_inds, 0], 0, NY - MY)\n",
    "                r[batch_inds, 1] = th.clamp(r[batch_inds, 1], 0, NX - MX)\n",
    "    \n",
    "                dL_dr_old[batch_inds] = dL_dr_up\n",
    "        del S_split\n",
    "        new_psi = th.zeros_like(psi0)\n",
    "        new_psi_denom = th.zeros(psi0.shape, device=dev_compute[0])\n",
    "        \n",
    "        for batch_inds in sampler:\n",
    "            K_b = len(batch_inds)\n",
    "            S_split = th.zeros((Bp, K_b, MY, MX), dtype=cx_dtype, device=dev_compute[0])\n",
    "            if do_subpix:\n",
    "                z_hatb = z_hat[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "                S_split = Qsplit(r_int[batch_inds], S_model, S_split)\n",
    "    \n",
    "                psi0 = th.conj(S_split) * z_hatb\n",
    "                # shift update in opposite direction\n",
    "                psi0 = shift(psi0, -dr[batch_inds])\n",
    "                # sum over K\n",
    "                new_psi += th.sum(psi0, 1)\n",
    "    \n",
    "                S_split = shift(S_split, -dr[batch_inds])\n",
    "                # sum over K\n",
    "    \n",
    "                new_psi_denom += th.sum(th.abs(S_split) ** 2, 1)\n",
    "            else:\n",
    "                new_psi_denom += calc_psi_denom(r_int[batch_inds], S_model, th.zeros(psi0.shape, device=dev_compute[0]))\n",
    "                new_psi += calc_psi(r_int[batch_inds], S_model, z_hat[batch_inds], th.zeros_like(psi0))\n",
    "        # # Bp x MY x MX\n",
    "        psi0 = new_psi / new_psi_denom\n",
    "        Psi0 = s_meta.beamlets * th.fft.fft2(psi0, norm='ortho')\n",
    "        psi0 = th.fft.ifft2(Psi0, norm='ortho')\n",
    "        del Psi0\n",
    "        del new_psi\n",
    "        del new_psi_denom\n",
    "        del S_split\n",
    "    \n",
    "        # print(f\"psi norm: {th.norm(psi0[0, 0])}\")\n",
    "        # plot(new_psi_denom[0].cpu().numpy(), 'psi_denom')\n",
    "        # plotAbsAngle(psi0[0].cpu().numpy(),'torch')\n",
    "        # plotcx(psi0[0].cpu().numpy(), 'torch')\n",
    "        # update normalisation\n",
    "        AtA[:] = 1e-6\n",
    "        for batch_inds in sampler:\n",
    "            psi = shift(psi0, dr[batch_inds])\n",
    "            AtA = Qoverlap_real(r_int[batch_inds], th.abs(psi) ** 2, AtA)\n",
    "    \n",
    "        h2 = th.max(AtA)\n",
    "        M2 = (h2 <= eps2) * eps2 + (h2 > eps2) * h2 * r22\n",
    "        M2 = M2.to(th.float32)\n",
    "        \n",
    "        S_model_new = th.zeros_like(S_model)\n",
    "        for batch_inds in sampler:\n",
    "            psi = shift(psi0, dr[batch_inds])\n",
    "            zhb = z_hat[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            S_model_new = Qoverlap(r_int[batch_inds], th.conj(psi) * zhb, S_model_new)\n",
    "    \n",
    "        S_model_new += M2 * S_model\n",
    "        S_model = S_model_new / (AtA + M2)\n",
    "        # del S_model_new\n",
    "    \n",
    "        if Bp > 1:\n",
    "            S_model = gaussian(S_model, kernel_size, tuple(sigma))\n",
    "            sigma *= 0.97\n",
    "            \n",
    "        # if verbose:\n",
    "        #     plotAbsAngle(S_model[slic].cpu(), f'S_model {i}')\n",
    "        # update model exit waves\n",
    "        for batch_inds in sampler:\n",
    "            psi = shift(psi0, dr[batch_inds])\n",
    "            zh = A_realspace(r_int[batch_inds], S_model, psi, th.zeros_like(z_hat[batch_inds], device=dev_compute[0]))\n",
    "            z_hat[batch_inds] = th.fft.fft2(zh, norm='ortho').to(dev_z, non_blocking=non_blocking)\n",
    "        losses = []\n",
    "        #  update model from data, update auxiliary variables\n",
    "        for batch_inds in sampler:\n",
    "            zhb = z_hat[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            Lb = Lambda[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            zb = z[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "            I_b = measurements[batch_inds].to(dev_compute[0], non_blocking=non_blocking)\n",
    "    \n",
    "            zhb -= Lb / beta\n",
    "            # zb, loss = sparse_amplitude_prox(zb, zhb, Ii_b, I_b, beta)\n",
    "            zb, loss = prox_D_gaussian(zb, zhb, I_b, beta)\n",
    "            zhb += Lb / beta\n",
    "    \n",
    "            Lb += beta * zb\n",
    "            Lb -= beta * zhb\n",
    "    \n",
    "            z[batch_inds] = zb.to(dev_z, non_blocking=non_blocking)\n",
    "            z_hat[batch_inds] = zhb.to(dev_z, non_blocking=non_blocking)\n",
    "            Lambda[batch_inds] = Lb.to(dev_z, non_blocking=non_blocking)\n",
    "            losses.append(loss)\n",
    "    \n",
    "        losses = np.concatenate(losses)\n",
    "        R_factor = np.sqrt(np.sum(losses)) / a_norm\n",
    "        R_factors.append(R_factor)\n",
    "        end = timer()\n",
    "        if options.verbose:\n",
    "            logging.info(f\"{i:03d}/{n_iter:03d} [{(end - start):-02.2f}s] R-factor: {R_factor:3.3g}\")\n",
    "    \n",
    "        if do_position_correction(i):\n",
    "            for batch_inds in sampler:\n",
    "                r_int[batch_inds] = th.round(r[batch_inds]).long()\n",
    "                dr[batch_inds] = r[batch_inds] - r_int[batch_inds]\n",
    "\n",
    "    out = SMPRSolution(\n",
    "        converged=True,\n",
    "        smatrix = S_model,\n",
    "        probe = psi0,\n",
    "        positions = r,\n",
    "        r_factor = R_factors[-1],\n",
    "        r_factor_history = th.tensor(R_factors),\n",
    "        s_matrix_meta = s_meta\n",
    "    )\n",
    "    \n",
    "    return out "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
