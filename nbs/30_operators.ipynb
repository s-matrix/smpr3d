{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "from smpr3d.kernels import smatrix_forward_kernel, split_kernel, smatrix_forward_kernel_fast_full4\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import math as m\n",
    "import numba.cuda as cuda\n",
    "\n",
    "def A(S, Psi, r, r_min, out=None, Mx=0, My=0):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   B x D x K x 2\n",
    "    :param r:               D x K x 2\n",
    "    :param out:             D x K x MY x MX\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    if out is None and My > 0 and Mx > 0:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((D, K, My, Mx, 2), dtype=th.float32, device=S.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "    D, K, MY, MX, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((B, MX, MY))) / threadsperblock)\n",
    "    smatrix_forward_kernel[blockspergrid, threadsperblock, th.cuda.current_stream().cuda_stream]\\\n",
    "        (th.view_as_real(S), Psi.phase_factors, r, r_min, out)\n",
    "    return th.view_as_complex(out)\n",
    "\n",
    "@th.jit.script\n",
    "def complex_matmul(a, b):\n",
    "    \"\"\"\n",
    "    Complex matrix multiplication of tensors a and b.\n",
    "\n",
    "    Pass conjugate = True to conjugate tensor b in the multiplication.\n",
    "    \"\"\"\n",
    "    are, aim = th.unbind(a, -1)\n",
    "    bre, bim = th.unbind(b, -1)\n",
    "    real = are @ bre - aim @ bim\n",
    "    imag = are @ bim + aim @ bre\n",
    "    return th.stack([real, imag], -1)\n",
    "\n",
    "def A_fast_full2(S, phase_factors, r, r_min, MY, MX):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   K x B x 2\n",
    "    :param r:               K x 2\n",
    "    :param out:             K x MY x MX x 2\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((K, MY, MX, B, 2), dtype=th.float32, device=S.device)\n",
    "    K, MYMX, _, _, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 256  # gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((K, MX, MY, B))) / threadsperblock)\n",
    "\n",
    "    phase_factors2 = phase_factors.unsqueeze(2)\n",
    "    # 1 - get crops from S-matrix\n",
    "    split_kernel[blockspergrid, threadsperblock, stream](th.view_as_real(S), r, out)\n",
    "    out = out.view((K, MY * MX, B, 2))\n",
    "    # 2 - complex batched matmul: K x MY*MX x B x 2 @ K x B x 1 x 2\n",
    "    # print(out.shape)\n",
    "    # print(phase_factors2.shape)\n",
    "    exitwaves = complex_matmul(out, phase_factors2)\n",
    "    # 3 - reshape\n",
    "    exitwaves = exitwaves.view((K, MY, MX, 2))\n",
    "    return exitwaves\n",
    "\n",
    "def A_fast_full3(S, phase_factors, r, r_min, MY, MX):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   K x B \n",
    "    :param r:               K x 2\n",
    "    :param out:             K x MY x MX  \n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((K, MY, MX, B, 2), dtype=th.float32, device=S.device)\n",
    "    K, MYMX, _, _, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128  # gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((K, MX, MY, B))) / threadsperblock)\n",
    "\n",
    "    phase_factors2 = phase_factors.unsqueeze(2)\n",
    "    # 1 - get crops from S-matrix\n",
    "    split_kernel[blockspergrid, threadsperblock, stream](th.view_as_real(S), r, out)\n",
    "    out = out.view((K, MY * MX, B, 2))\n",
    "    out = th.view_as_complex(out)\n",
    "    # 1.5 - convert to cupy\n",
    "    # 2 - complex batched matmul: K x MY*MX x B @ K x B x 1\n",
    "    # print(out.shape)\n",
    "    # print(phase_factors2.shape)\n",
    "    # print(out.dtype)\n",
    "    # print(phase_factors2.dtype)\n",
    "    exitwaves = out @ phase_factors2\n",
    "    # 3 - reshape\n",
    "    exitwaves = exitwaves.view((K, MY, MX))\n",
    "    #4 convert to pytorch\n",
    "    return exitwaves\n",
    "\n",
    "def A_fast_full4(S, phase_factors, r, r_min, out=None, Mx=0, My=0):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   B x D x K x 2\n",
    "    :param r:               D x K x 2\n",
    "    :param out:             D x K x MY x MX\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    if out is None and My > 0 and Mx > 0:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((D, K, My, Mx, 2), dtype=th.float32, device=S.device)\n",
    "    D, K, MY, MX, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    tbp = int(gpu.MAX_THREADS_PER_BLOCK**(1/3))\n",
    "\n",
    "    # max dim of thread block (1024,1024,64), with a total of 1024 max\n",
    "    # max dim of grid (2^32-1 , 2^16-1, 2^16-1)\n",
    "    #                 (2^32-1 , 65535, 65535)\n",
    "\n",
    "    threadsperblock = (tbp, tbp, tbp)\n",
    "    blockspergrid = tuple(np.ceil((K/tbp, MY/tbp, MX/tbp)).astype(np.int))# m.ceil(np.prod(np.array((B, MX, MY))) / threadsperblock)\n",
    "    smatrix_forward_kernel_fast_full4[blockspergrid, threadsperblock, stream](th.view_as_real(S), phase_factors, r, r_min, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import smatrix_backward_kernel_S\n",
    "def AH_S(z, Psi, r, r_min, out=None, tau = th.tensor([1.0]), Ny=-1, Nx=-1):\n",
    "    \"\"\"\n",
    "    Adjoint S-matrix operator for the full S-matrix. Expects pre-computed phase-factors as inputs.\n",
    "\n",
    "    :param z:               D x K x My x Mx\n",
    "    :param Psi:             D x My x Mx\n",
    "    :param r:               D x K x 2\n",
    "    :param r_min:           2\n",
    "    :param out:             B x NY x NX x 2\n",
    "    :param Ny:              optional, int\n",
    "    :param Nx:              optional, int\n",
    "    :return: result of adjoint S-matrix operator, shape (B x NY x NX x 2)\n",
    "    \"\"\"\n",
    "    D, K, MY, MX = z.shape\n",
    "    B = Psi.phase_factors.shape[0]\n",
    "\n",
    "    if out is None and Ny > 0 and Nx > 0:\n",
    "        out_is_gradient = True\n",
    "        out = th.zeros((B, Ny, Nx, 2), dtype=th.float32, device=z.device)\n",
    "    else:\n",
    "        out_is_gradient = False\n",
    "        tau /= (K * D)\n",
    "\n",
    "    # shape D\n",
    "    mean_probe_intensities = th.norm(Psi, p=2, dim=(1, 2))\n",
    "    mean_probe_intensities /= MX * MY\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((B, MY, MX))) / threadsperblock)\n",
    "    smatrix_backward_kernel_S[blockspergrid, threadsperblock, stream] \\\n",
    "        (th.view_as_real(z), Psi.phase_factors, mean_probe_intensities, r, r_min, out, tau)\n",
    "\n",
    "    if out_is_gradient:\n",
    "        out /= (K * D)\n",
    "\n",
    "    return th.view_as_complex(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import phase_factor_kernelDBK\n",
    "def smatrix_phase_factorsBDK(Psi, r, take_beams, q, B, out=None):\n",
    "    \"\"\"\n",
    "    Abbreviations:\n",
    "    B: number of (input) beams in S-matrix\n",
    "    D: number of scans/ aperture functions\n",
    "    K: number of scan positions\n",
    "    MY/MX: detector shape\n",
    "    NY/NX: S-matrix shape\n",
    "\n",
    "    :param Psi: q           D x B\n",
    "    :param r:               D x K x 2\n",
    "    :param take_beams:      MY x MX\n",
    "    :param q:               2 x MY x MX\n",
    "    :param out:             B x D x K x 2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if out is None:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((B, D, K, 2), dtype=th.float32, device=Psi.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "        _, D, K, c = out.shape\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array(out.shape[:-1])) / threadsperblock)\n",
    "    tb = take_beams[None, ...].expand(*Psi.shape)\n",
    "    Psi_DB = Psi[tb].reshape(D, B)\n",
    "    tb = take_beams[None, ...].expand(*q.shape)\n",
    "    qB = q[tb].reshape(2, B)\n",
    "    phase_factor_kernelDBK[blockspergrid, threadsperblock, stream](th.view_as_real(Psi_DB), r, qB, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import phase_factor_kernelKB\n",
    "def smatrix_phase_factorsKB(Psi, r, take_beams, q, q_indices, B, out=None):\n",
    "    \"\"\"\n",
    "    Abbreviations:\n",
    "    B: number of (input) beams in S-matrix\n",
    "    K: number of scan positions\n",
    "    MY/MX: detector shape\n",
    "    NY/NX: S-matrix shape\n",
    "\n",
    "    :param Psi: q           MY x MX\n",
    "    :param r:               K x 2\n",
    "    :param take_beams:      MY x MX\n",
    "    :param q:               2 x MY x MX\n",
    "    :param q_indices:       2 x MY x MX\n",
    "    :param out:             K x B x 2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if out is None:\n",
    "        K, _ = r.shape\n",
    "        out = th.zeros((K, B, 2), dtype=th.float32, device=Psi.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "        K, B, c = out.shape\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array(out.shape[:-1])) / threadsperblock)\n",
    "    tb = take_beams.expand(*Psi.shape)\n",
    "    Psi_B = Psi[tb].reshape(B)\n",
    "    tb = take_beams[None, ...].expand(*q_indices.shape)\n",
    "    qB = q[tb].reshape(2, B)\n",
    "    phase_factor_kernelKB[blockspergrid, threadsperblock, stream](th.view_as_real(Psi_B), r, qB, out)\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
