{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from smpr3d.kernels import *\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import math as m\n",
    "import numba.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import cmath as cm\n",
    "from numpy.fft import fftfreq \n",
    "th.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def r2c(real_tensor):\n",
    "    '''Convert from real to complex'''\n",
    "    return real_tensor+0j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def convolve_kernel(tensor_in, kernel, n_dim=1, flag_inplace=True):\n",
    "    '''\n",
    "    Compute convolution FFT(tensor_in) and kernel\n",
    "    Required Args:\n",
    "        tensor_in: variable 1 in real space\n",
    "        kernel: variable 2 in reciprocal space\n",
    "\n",
    "    Optional Args [default]\n",
    "        n_dim: number of dimensions to compute convolution [1]\n",
    "        flag_inplace: Whether or not compute convolution inplace, result saved in 'tensor_in' [True]\n",
    "    '''\n",
    "    dim = [-n_dim+i for i in range(n_dim)]\n",
    "    if flag_inplace:\n",
    "        tensor_in  = th.fft.fftn(tensor_in, dim=dim)\n",
    "        tensor_in *= kernel\n",
    "        tensor_in  = th.fft.ifftn(tensor_in, dim=dim)\n",
    "        return tensor_in\n",
    "    else:\n",
    "        output  = th.fft.fftn(tensor_in, dim=dim)\n",
    "        output *= kernel\n",
    "        output  = th.fft.ifftn(output, dim=dim)\n",
    "        return output\n",
    "    \n",
    "def generate_grid_1d(shape, pixel_size = 1, flag_fourier = False, dtype = th.float32, device = th.device('cuda')):\n",
    "    \"\"\"\n",
    "    This function generates 1D Fourier grid, and is centered at the middle of the array\n",
    "    Inputs:\n",
    "        shape    - length of the array\n",
    "        pixel_size      - pixel size\n",
    "    Optional parameters:\n",
    "        flag_fourier - flag indicating whether the final array is circularly shifted\n",
    "                     should be false when computing real space coordinates\n",
    "                     should be true when computing Fourier coordinates\n",
    "    Outputs:\n",
    "        x_lin       - 1D grid (real or fourier)\n",
    "\n",
    "    \"\"\"\n",
    "    pixel_size = 1./pixel_size/shape if flag_fourier else pixel_size\n",
    "    x_lin = (th.arange(shape, dtype=dtype, device=device) - shape//2) * pixel_size\n",
    "    if flag_fourier:\n",
    "        x_lin = th.roll(x_lin, -1 * int(shape)//2)\n",
    "    return x_lin\n",
    "\n",
    "def generate_grid_2d(shape, pixel_size = 1, flag_fourier = False, dtype = th.float32, device = th.device('cuda')):\n",
    "    \"\"\"\n",
    "    This function generates 2D Fourier grid, and is centered at the middle of the array\n",
    "    Inputs:\n",
    "        shape              - shape of the grid (number of y pixels, number of x pixels)\n",
    "        pixel_size         - pixel size\n",
    "    Optional parameters:\n",
    "        flag_fourier       - flag indicating whether the final array is circularly shifted\n",
    "                             should be false when computing real space coordinates\n",
    "                             should be true when computing Fourier coordinates\n",
    "    Outputs:\n",
    "        y_lin, x_lin       - 2D grid\n",
    "    Usage:\n",
    "        y_lin, x_lin = generate_grid_2d(...)\n",
    "\n",
    "    \"\"\"    \n",
    "    assert len(shape) == 2, \"shape should be two dimensional!\"\n",
    "    #recompute pixel size for fourier space sampling\n",
    "    y_lin  = generate_grid_1d(shape[0], pixel_size, flag_fourier = flag_fourier, dtype=dtype, device=device)\n",
    "    x_lin  = generate_grid_1d(shape[1], pixel_size, flag_fourier = flag_fourier, dtype=dtype, device=device)\n",
    "    y_lin, x_lin = th.meshgrid(y_lin, x_lin)\n",
    "    return y_lin, x_lin\n",
    "def generate_hard_pupil(shape, pixel_size, numerical_aperture, wavelength, \\\n",
    "                   dtype=th.float32, device=th.device('cuda')):\n",
    "    \"\"\"\n",
    "    This function generates pupil function(circular function) given shape, pixel_size, na, and wavelength\n",
    "    \"\"\"\n",
    "    assert len(shape) == 2, \"pupil should be two dimensional!\"\n",
    "    ky_lin, kx_lin = generate_grid_2d(shape, pixel_size, flag_fourier=True, dtype=dtype, device=device)\n",
    "\n",
    "    pupil_radius = numerical_aperture/wavelength\n",
    "    pupil        = (kx_lin**2 + ky_lin**2 <= pupil_radius**2).type(dtype)\n",
    "    return op.r2c(pupil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def generate_angular_spectrum_kernel(shape, pixel_size, wavelength, \\\n",
    "                                     numerical_aperture=None,  flag_band_limited=True, \\\n",
    "                                     dtype=th.float32, device=th.device('cuda')):\n",
    "    \"\"\"\n",
    "    Function that generates angular spectrum propagation kernel WITHOUT the distance\n",
    "    The angular spectrum has the following form:\n",
    "    p = exp(distance * kernel)\n",
    "    kernel = 1j * 2 * pi * sqrt((ri/wavelength)**2-x**2-y**2)\n",
    "    and this function generates the kernel only!\n",
    "    \"\"\"\n",
    "    assert len(shape) == 2, \"pupil should be two dimensional!\"\n",
    "    ky_lin, kx_lin = generate_grid_2d(shape, pixel_size, flag_fourier=True, dtype=dtype, device=device)\n",
    "    if flag_band_limited:\n",
    "        assert numerical_aperture is not None, \"need to provide numerical aperture of the system!\"\n",
    "        pupil_crop    = r2c(generate_hard_pupil(shape, pixel_size, numerical_aperture, wavelength, dtype, device))\n",
    "    else: \n",
    "        pupil_crop    = 1.0\n",
    "    # prop_kernel = 2.0 * np.pi * pupil_crop * \\\n",
    "    #               ((1./wavelength)**2 - kx_lin**2 - ky_lin**2) ** 0.5\n",
    "    prop_kernel = -1 * np.pi * wavelength * pupil_crop * (kx_lin**2 + ky_lin**2)\n",
    "    return 1j *prop_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class Pupil(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for applying pupil in forward model computation\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, pixel_size, wavelength, \\\n",
    "                 numerical_aperture = 1.0, pupil = None, \\\n",
    "                 dtype=th.float32, device=th.device('cuda'), **kwargs):\n",
    "        super(Pupil, self).__init__()\n",
    "        if pupil is not None:\n",
    "            self.pupil = pupil.type(dtype).to(device)\n",
    "            if len(self.pupil.shape) == 2:\n",
    "                self.pupil = r2c(self.pupil)\n",
    "        else:\n",
    "            self.pupil = generate_hard_pupil(shape, pixel_size, numerical_aperture, wavelength, dtype, device)\n",
    "    def get_pupil(self):\n",
    "        return self.pupil.cpu()\n",
    "    def forward(self, field):\n",
    "        field_out = convolve_kernel(field, self.pupil, 2, False)\n",
    "        return field_out\n",
    "\n",
    "MAX_DIM = 512*512*850\n",
    "class ImageRotation:\n",
    "    \"\"\"\n",
    "    A rotation class compute 3D rotation using FFT\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, axis = 0, pad = True, pad_value = 0, dtype = th.float32, device = th.device('cuda')):\n",
    "        self.dim       = np.array(shape)\n",
    "        self.axis      = axis\n",
    "        self.pad_value = pad_value\n",
    "        if pad:\n",
    "            self.pad_size            = np.ceil(self.dim / 2.0).astype('int')\n",
    "            self.pad_size[self.axis] = 0\n",
    "            self.dim                += 2*self.pad_size\n",
    "        else:\n",
    "            self.pad_size  = np.asarray([0,0,0])\n",
    "        \n",
    "        self.dim          = [int(size) for size in self.dim]\n",
    "\n",
    "        self.range_crop_y = slice(self.pad_size[0],self.pad_size[0] + shape[0])\n",
    "        self.range_crop_x = slice(self.pad_size[1],self.pad_size[1] + shape[1])\n",
    "        self.range_crop_z = slice(self.pad_size[2],self.pad_size[2] + shape[2])\n",
    "\n",
    "        self.y            = generate_grid_1d(self.dim[0], dtype=dtype, device=device).unsqueeze(-1).unsqueeze(-1)\n",
    "        self.x            = generate_grid_1d(self.dim[1], dtype=dtype, device=device).unsqueeze(0).unsqueeze(-1)\n",
    "        self.z            = generate_grid_1d(self.dim[2], dtype=dtype, device=device).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        self.ky           = generate_grid_1d(self.dim[0], flag_fourier = True, dtype=dtype, device=device).unsqueeze(-1).unsqueeze(-1)\n",
    "        self.kx           = generate_grid_1d(self.dim[1], flag_fourier = True, dtype=dtype, device=device).unsqueeze(0).unsqueeze(-1)\n",
    "        self.kz           = generate_grid_1d(self.dim[2], flag_fourier = True, dtype=dtype, device=device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        #Compute FFTs sequentially if object size is too large\n",
    "        self.slice_per_tile = int(np.min([np.floor(MAX_DIM * self.dim[self.axis] / np.prod(self.dim)), self.dim[self.axis]]))            \n",
    "        self.dtype          = dtype\n",
    "        self.device         = device\n",
    "\n",
    "        if self.axis == 0:\n",
    "            self.coord_phase_1 = -2.0 * np.pi * self.kz * self.x\n",
    "            self.coord_phase_2 = -2.0 * np.pi * self.kx * self.z\n",
    "        elif self.axis == 1:\n",
    "            self.coord_phase_1 = -2.0 * np.pi * self.kz * self.y\n",
    "            self.coord_phase_2 = -2.0 * np.pi * self.ky * self.z\n",
    "        elif self.axis == 2:\n",
    "            self.coord_phase_1 = -2.0 * np.pi * self.kx * self.y\n",
    "            self.coord_phase_2 = -2.0 * np.pi * self.ky * self.x\n",
    "\n",
    "    def _rotate_3d(self, obj, shear_phase_1, shear_phase_2):\n",
    "        \"\"\"\n",
    "        This function rotates a 3D image by shearing, (applied in Fourier space)\n",
    "        ** Note: the rotation is performed along the z axis\n",
    "\n",
    "        [ cos(theta)  -sin(theta) ] = [ 1  alpha ] * [ 1     0  ] * [ 1  alpha ]\n",
    "        [ sin(theta)  cos(theta)  ]   [ 0    1   ]   [ beta  1  ]   [ 0    1   ]\n",
    "        alpha = tan(theta/2)\n",
    "        beta = -sin(theta)\n",
    "\n",
    "        Shearing in one shapeension is applying phase shift in 1D fourier transform\n",
    "        Input:\n",
    "          obj: 3D array (supposed to be an image), the axes are [z,y,x]\n",
    "          theta: desired angle of rotation in *degrees*\n",
    "        Output:\n",
    "          obj_rotate: rotate 3D array\n",
    "        \"\"\"\n",
    "        flag_complex = obj.is_complex()\n",
    "        self.obj_rotate[self.range_crop_y, self.range_crop_x, self.range_crop_z] = r2c(obj)\n",
    "        if self.axis == 0:\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate, shear_phase_1) #y,x,z\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_2.permute([0,2,1])) #y,z,x\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_1) #y,x,z\n",
    "\n",
    "        elif self.axis == 1:\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([1,0,2]), shear_phase_1.permute([1,0,2])) #x,y,z\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_2.permute([1,2,0])) #x,z,y\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_1.permute([1,0,2])) #x,y,z\n",
    "            self.obj_rotate = self.obj_rotate.permute([1,0,2])\n",
    "\n",
    "        elif self.axis == 2:\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([2,0,1]), shear_phase_1.permute([2,0,1])) #z,y,x\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_2.permute([2,1,0])) #z,x,y\n",
    "            self.obj_rotate = convolve_kernel(self.obj_rotate.permute([0,2,1]), shear_phase_1.permute([2,0,1])) #z,y,x\n",
    "            self.obj_rotate = self.obj_rotate.permute([1,2,0])\n",
    "        if flag_complex:\n",
    "            obj[:] = self.obj_rotate[self.range_crop_y, self.range_crop_x, self.range_crop_z]\n",
    "        else:\n",
    "            obj[:] = self.obj_rotate[self.range_crop_y, self.range_crop_x, self.range_crop_z].real\n",
    "        return obj\n",
    "\n",
    "    def forward(self, obj, theta):\n",
    "        self.theta = theta\n",
    "        if theta == 0:\n",
    "            return obj\n",
    "        else:\n",
    "            flag_cpu = False\n",
    "            if self.device == th.device('cuda'):\n",
    "                if not obj.is_cuda:\n",
    "                    flag_cpu = True\n",
    "            #         obj = obj.to(self.device)\n",
    "            theta      *= np.pi / 180.0\n",
    "            alpha       = 1.0 * np.tan(theta / 2.0)\n",
    "            beta        = np.sin(-1.0 * theta)\n",
    "\n",
    "            shear_phase_1 = th.exp(1j * self.coord_phase_1 * alpha)\n",
    "            shear_phase_2 = th.exp(1j * self.coord_phase_2 * beta)\n",
    "\n",
    "            self.dim[self.axis] = self.slice_per_tile\n",
    "            self.obj_rotate = r2c(th.ones([self.dim[0], self.dim[1], self.dim[2]], dtype=self.dtype, device=self.device) * self.pad_value)\n",
    "\n",
    "            for idx_start in range(0, obj.shape[self.axis], self.slice_per_tile):\n",
    "                idx_end = np.min([obj.shape[self.axis], idx_start+self.slice_per_tile])\n",
    "                idx_slice = slice(idx_start, idx_end)\n",
    "                self.dim[self.axis] = int(idx_end - idx_start)\n",
    "                if self.axis == 0:\n",
    "                    self.range_crop_y = slice(0, self.dim[self.axis])\n",
    "                    obj[idx_slice,:,:] = self._rotate_3d(obj[idx_slice,:,:].cuda(), shear_phase_1, shear_phase_2).cpu()\n",
    "                elif self.axis == 1:\n",
    "                    self.range_crop_x = slice(0, self.dim[self.axis])\n",
    "                    obj[:,idx_slice,:] = self._rotate_3d(obj[:,idx_slice,:].cuda(), shear_phase_1, shear_phase_2).cpu()\n",
    "                elif self.axis == 2:\n",
    "                    self.range_crop_z = slice(0, self.dim[self.axis])\n",
    "                    obj[:,:,idx_slice] = self._rotate_3d(obj[:,:,idx_slice].cuda(), shear_phase_1, shear_phase_2).cpu()\n",
    "                self.obj_rotate[:] = self.pad_value + 0.j\n",
    "            self.dim[self.axis] = obj.shape[self.axis]\n",
    "            self.obj_rotate = None\n",
    "            if self.device == th.device('cuda'):\n",
    "                th.cuda.empty_cache()\n",
    "            if flag_cpu:\n",
    "                obj = obj.cpu()\n",
    "            return obj\n",
    "\n",
    "    def backward(self, obj):\n",
    "        theta = -1 * self.theta\n",
    "        if theta == 0:\n",
    "            return obj\n",
    "        else:\n",
    "            if self.device == th.device(\"cuda\"):\n",
    "                if not obj.is_cuda:\n",
    "                    obj = obj.to(self.device)\n",
    "            theta      *= np.pi / 180.0\n",
    "            alpha       = 1.0 * np.tan(theta / 2.0)\n",
    "            beta        = np.sin(-1.0 * theta)\n",
    "            \n",
    "            shear_phase_1 = th.exp(1j * self.coord_phase_1 * alpha)\n",
    "            shear_phase_2 = th.exp(1j * self.coord_phase_2 * beta)\n",
    "\n",
    "            self.dim[self.axis] = self.slice_per_tile\n",
    "            self.obj_rotate = r2c(th.zeros([self.dim[0], self.dim[1], self.dim[2]], dtype=self.dtype, device=self.device))\n",
    "\n",
    "            for idx_start in range(0, obj.shape[self.axis], self.slice_per_tile):\n",
    "                idx_end = np.min([obj.shape[self.axis], idx_start+self.slice_per_tile])\n",
    "                idx_slice = slice(idx_start, idx_end)\n",
    "                self.dim[self.axis] = int(idx_end - idx_start)\n",
    "                if self.axis == 0:\n",
    "                    self.range_crop_y = slice(0, self.dim[self.axis])\n",
    "                    obj[idx_slice,:,:] = self._rotate_3d(obj[idx_slice,:,:], alpha, beta, shear_phase_1, shear_phase_2)\n",
    "                elif self.axis == 1:\n",
    "                    self.range_crop_x = slice(0, self.dim[self.axis])\n",
    "                    obj[:,idx_slice,:] = self._rotate_3d(obj[:,idx_slice,:], alpha, beta, shear_phase_1, shear_phase_2)\n",
    "                elif self.axis == 2:\n",
    "                    self.range_crop_z = slice(0, self.dim[self.axis])\n",
    "                    obj[:,:,idx_slice] = self._rotate_3d(obj[:,:,idx_slice], alpha, beta, shear_phase_1, shear_phase_2)\n",
    "                self.obj_rotate[:] = 0.0\n",
    "            self.dim[self.axis] = obj.shape[self.axis]\n",
    "            self.obj_rotate = None         \n",
    "            if not obj.is_cuda:\n",
    "                obj = obj.cpu()\n",
    "            return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def calc_psi(r, t, z, out):\n",
    "    out[:] = 0\n",
    "    K = r.shape[0]\n",
    "    MY, MX = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(K * MY * MX / threadsperblock)\n",
    "    psi_kernel[blockspergrid, threadsperblock](r, t, z, out)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class ComplexAbs(th.autograd.Function):\n",
    "    '''Absolute value class for autograd'''\n",
    "    @staticmethod\n",
    "    def forward(ctx, tensor_in):\n",
    "        output = th.abs(tensor_in)\n",
    "        ctx.save_for_backward(th.angle(tensor_in))\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        tensor_in_angle,     = ctx.saved_tensors\n",
    "        return 0.5*th.exp(1j * tensor_in_angle) * grad_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class BinObject(th.autograd.Function):\n",
    "    '''\n",
    "    Class that bins the object along the direction of beam propagation (z)\n",
    "    inputs:\n",
    "    obj_in: input object \n",
    "    factor: factor at which the object will be binned\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def forward(ctx, obj_in, factor):\n",
    "        assert (obj_in.shape[2] % factor) == 0\n",
    "        assert len(obj_in.shape) == 3\n",
    "        ctx.factor = factor\n",
    "        if factor == 1:\n",
    "            return obj_in\n",
    "        n_y, n_x, n_z = obj_in.shape\n",
    "        obj_out = obj_in.reshape(n_y, n_x, n_z//factor, factor).sum(3)\n",
    "        return obj_out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        factor = ctx.factor\n",
    "        if factor == 1:\n",
    "            return grad_output, None\n",
    "\n",
    "        return grad_output.repeat_interleave(factor, dim=-1), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def AtF2(z, psi, r, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param z:   K x MY x MX\n",
    "    :param psi: B x K x MY x MX\n",
    "    :param r:   K x 2\n",
    "    :param out: B x NY x NX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(z.shape) / threadsperblock)\n",
    "    AtF2_kernel[blockspergrid, threadsperblock](z, psi, r, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def dS(z, z_old, psi, psi_int, psi_int_max, r, out, alpha=0.1):\n",
    "    \"\"\"\n",
    "    :param z:           K x MY x MX\n",
    "    :param z_old:       K x MY x MX\n",
    "    :param psi:         B x K x MY x MX\n",
    "    :param psi_int:     B x K x MY x MX\n",
    "    :param psi_int_max: B x K\n",
    "    :param r:           K x 2\n",
    "    :param out:         B x NY x NX\n",
    "    :param alpha:       float\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(z.shape) / threadsperblock)\n",
    "    dS_kernel[blockspergrid, threadsperblock](z, z_old, psi, psi_int, psi_int_max, alpha, r, th.view_as_real(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def A_realspace(r, t, psi, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r:   K x 2\n",
    "    :param t:   BB x NY x NX\n",
    "    :param psi: B x K x MY x MX\n",
    "    :param out: K x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(out.shape) / threadsperblock)\n",
    "    # print(r.shape,t.shape,psi.shape,out.shape)\n",
    "    A_realspace_kernel[blockspergrid, threadsperblock](r, th.view_as_real(t), th.view_as_real(psi), th.view_as_real(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "def calc_psi_denom(r, t, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r: K x 2\n",
    "    :param t: BB x NY x NX\n",
    "    :param out: BB x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    out[:] = 0\n",
    "    K = r.shape[0]\n",
    "    BB, MY, MX = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(BB * K * MY * MX / threadsperblock)\n",
    "    psi_denom_kernel[blockspergrid, threadsperblock](r, t, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def Qoverlap_real2(r, z, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r: K x 2\n",
    "    :param z: BB x K x MY x MX\n",
    "    :param out: BB x NY x NX\n",
    "    :return: out\n",
    "    \"\"\"\n",
    "    BB = out.shape[0]\n",
    "    K = r.shape[0]\n",
    "    out[:] = 1\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(BB * K * np.prod(z.shape) / threadsperblock)\n",
    "    overlap_kernel_real2[blockspergrid, threadsperblock](r, z, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def split(S, r, MY, MX):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param S:  B x NY x NX\n",
    "    :param r:  K x 2\n",
    "    :param MY: int\n",
    "    :param MX: int\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((B, K, MY, MX), dtype=th.complex64, device=S.device)\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(out.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    split_kernel4[blockspergrid, threadsperblock, stream](S, r, out)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def A(S, Psi, r, r_min, out=None, Mx=0, My=0):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   B x D x K x 2\n",
    "    :param r:               D x K x 2\n",
    "    :param out:             D x K x MY x MX\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    if out is None and My > 0 and Mx > 0:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((D, K, My, Mx, 2), dtype=th.float32, device=S.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "    D, K, MY, MX, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((B, MX, MY))) / threadsperblock)\n",
    "    smatrix_forward_kernel[blockspergrid, threadsperblock, th.cuda.current_stream().cuda_stream]\\\n",
    "        (th.view_as_real(S), Psi.phase_factors, r, r_min, out)\n",
    "    return th.view_as_complex(out)\n",
    "\n",
    "@th.jit.script\n",
    "def complex_matmul(a, b):\n",
    "    \"\"\"\n",
    "    Complex matrix multiplication of tensors a and b.\n",
    "\n",
    "    Pass conjugate = True to conjugate tensor b in the multiplication.\n",
    "    \"\"\"\n",
    "    are, aim = th.unbind(a, -1)\n",
    "    bre, bim = th.unbind(b, -1)\n",
    "    real = are @ bre - aim @ bim\n",
    "    imag = are @ bim + aim @ bre\n",
    "    return th.stack([real, imag], -1)\n",
    "\n",
    "def A_fast_full2(S, phase_factors, r, r_min, MY, MX):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   K x B x 2\n",
    "    :param r:               K x 2\n",
    "    :param out:             K x MY x MX x 2\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((K, MY, MX, B, 2), dtype=th.float32, device=S.device)\n",
    "    K, MYMX, _, _, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 256  # gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((K, MX, MY, B))) / threadsperblock)\n",
    "\n",
    "    phase_factors2 = phase_factors.unsqueeze(2)\n",
    "    # 1 - get crops from S-matrix\n",
    "    split_kernel[blockspergrid, threadsperblock, stream](th.view_as_real(S), r, out)\n",
    "    out = out.view((K, MY * MX, B, 2))\n",
    "    # 2 - complex batched matmul: K x MY*MX x B x 2 @ K x B x 1 x 2\n",
    "    # print(out.shape)\n",
    "    # print(phase_factors2.shape)\n",
    "    exitwaves = complex_matmul(out, phase_factors2)\n",
    "    # 3 - reshape\n",
    "    exitwaves = exitwaves.view((K, MY, MX, 2))\n",
    "    return exitwaves\n",
    "\n",
    "def A_fast_full3(S, phase_factors, r, r_min, MY, MX):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   K x B \n",
    "    :param r:               K x 2\n",
    "    :param out:             K x MY x MX  \n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((K, MY, MX, B, 2), dtype=th.float32, device=S.device)\n",
    "    K, MYMX, _, _, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    \n",
    "    threadsperblock = 128  # gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((K, MX, MY, B))) / threadsperblock)\n",
    "    # 1 - get crops from S-matrix\n",
    "    split_kernel[blockspergrid, threadsperblock, stream](th.view_as_real(S), r, out)\n",
    "    \n",
    "    # threadsperblock = 128  # gpu.MAX_THREADS_PER_BLOCK\n",
    "    # blockspergrid = m.ceil(np.prod(np.array((K, B))) / threadsperblock)\n",
    "    # # 1 - get crops from S-matrix\n",
    "    # split_kernel2[blockspergrid, threadsperblock, stream](th.view_as_real(S), r, out)\n",
    "    \n",
    "    out = out.view((K, MY * MX, B, 2))\n",
    "    out = th.view_as_complex(out)\n",
    "    # 1.5 - convert to cupy\n",
    "    # 2 - complex batched matmul: K x MY*MX x B @ K x B x 1\n",
    "    # print(out.shape)\n",
    "    # print(phase_factors2.shape)\n",
    "    # print(out.dtype)\n",
    "    # print(phase_factors2.dtype)\n",
    "    phase_factors2 = phase_factors.unsqueeze(2)\n",
    "    exitwaves = out @ phase_factors2\n",
    "    # 3 - reshape\n",
    "    exitwaves = exitwaves.view((K, MY, MX))\n",
    "    #4 convert to pytorch\n",
    "    return exitwaves\n",
    "\n",
    "def A_fast_full5(S, phase_factors, r, r_min, MY, MX):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   K x B \n",
    "    :param r:               K x 2\n",
    "    :param out:             K x MY x MX  \n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    K, _ = r.shape\n",
    "    out = th.zeros((K, B, MY, MX), dtype=th.complex64, device=S.device)\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    \n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(np.array((K, B, MY, MX))) / threadsperblock)\n",
    "    # 1 - get crops from S-matrix\n",
    "    split_kernel4[blockspergrid, threadsperblock, stream](S, r, out)\n",
    "    # 2 - complex batched matmul: K x 1 x B @ K x B x MY*MX --> K x 1 x MY * MX\n",
    "    exitwaves = phase_factors.unsqueeze(1) @ out.view((K, B, MY * MX))\n",
    "    # 3 - reshape\n",
    "    return exitwaves.view((K, MY, MX))\n",
    "\n",
    "def A_fast_full4(S, phase_factors, r, r_min, out=None, Mx=0, My=0):\n",
    "    \"\"\" Fastest version, takes precomputed phase factors, assumes S-matrix with beam tilt included\n",
    "\n",
    "    :param S:               B x NY x NX\n",
    "    :param phase_factors:   B x D x K x 2\n",
    "    :param r:               D x K x 2\n",
    "    :param out:             D x K x MY x MX\n",
    "    :return: exit waves in out\n",
    "    \"\"\"\n",
    "    B = S.shape[0]\n",
    "    if out is None and My > 0 and Mx > 0:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((D, K, My, Mx, 2), dtype=th.float32, device=S.device)\n",
    "    D, K, MY, MX, _ = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    tbp = int(gpu.MAX_THREADS_PER_BLOCK**(1/3))\n",
    "\n",
    "    # max dim of thread block (1024,1024,64), with a total of 1024 max\n",
    "    # max dim of grid (2^32-1 , 2^16-1, 2^16-1)\n",
    "    #                 (2^32-1 , 65535, 65535)\n",
    "\n",
    "    threadsperblock = (tbp, tbp, tbp)\n",
    "    blockspergrid = tuple(np.ceil((K/tbp, MY/tbp, MX/tbp)).astype(np.int32))# m.ceil(np.prod(np.array((B, MX, MY))) / threadsperblock)\n",
    "    smatrix_forward_kernel_fast_full4[blockspergrid, threadsperblock, stream](th.view_as_real(S), phase_factors, r, r_min, out)\n",
    "    return th.view_as_complex(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import smatrix_backward_kernel_S\n",
    "def AH_S(z, Psi, r, r_min, out=None, tau = th.tensor([1.0]), Ny=-1, Nx=-1):\n",
    "    \"\"\"\n",
    "    Adjoint S-matrix operator for the full S-matrix. Expects pre-computed phase-factors as inputs.\n",
    "\n",
    "    :param z:               D x K x My x Mx\n",
    "    :param Psi:             D x My x Mx\n",
    "    :param r:               D x K x 2\n",
    "    :param r_min:           2\n",
    "    :param out:             B x NY x NX x 2\n",
    "    :param Ny:              optional, int\n",
    "    :param Nx:              optional, int\n",
    "    :return: result of adjoint S-matrix operator, shape (B x NY x NX x 2)\n",
    "    \"\"\"\n",
    "    D, K, MY, MX = z.shape\n",
    "    B = Psi.phase_factors.shape[0]\n",
    "\n",
    "    if out is None and Ny > 0 and Nx > 0:\n",
    "        out_is_gradient = True\n",
    "        out = th.zeros((B, Ny, Nx, 2), dtype=th.float32, device=z.device)\n",
    "    else:\n",
    "        out_is_gradient = False\n",
    "        tau /= (K * D)\n",
    "\n",
    "    # shape D\n",
    "    mean_probe_intensities = th.norm(Psi, p=2, dim=(1, 2))\n",
    "    mean_probe_intensities /= MX * MY\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array((B, MY, MX))) / threadsperblock)\n",
    "    smatrix_backward_kernel_S[blockspergrid, threadsperblock, stream] \\\n",
    "        (th.view_as_real(z), Psi.phase_factors, mean_probe_intensities, r, r_min, out, tau)\n",
    "\n",
    "    if out_is_gradient:\n",
    "        out /= (K * D)\n",
    "\n",
    "    return th.view_as_complex(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import phase_factor_kernelDBK\n",
    "def smatrix_phase_factorsBDK(Psi, r, take_beams, q, B, out=None):\n",
    "    \"\"\"\n",
    "    Abbreviations:\n",
    "    B: number of (input) beams in S-matrix\n",
    "    D: number of scans/ aperture functions\n",
    "    K: number of scan positions\n",
    "    MY/MX: detector shape\n",
    "    NY/NX: S-matrix shape\n",
    "\n",
    "    :param Psi: q           D x B\n",
    "    :param r:               D x K x 2\n",
    "    :param take_beams:      MY x MX\n",
    "    :param q:               2 x MY x MX\n",
    "    :param out:             B x D x K x 2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if out is None:\n",
    "        D, K, _ = r.shape\n",
    "        out = th.zeros((B, D, K, 2), dtype=th.float32, device=Psi.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "        _, D, K, c = out.shape\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array(out.shape[:-1])) / threadsperblock)\n",
    "    tb = take_beams[None, ...].expand(*Psi.shape)\n",
    "    Psi_DB = Psi[tb].reshape(D, B)\n",
    "    tb = take_beams[None, ...].expand(*q.shape)\n",
    "    qB = q[tb].reshape(2, B)\n",
    "    phase_factor_kernelDBK[blockspergrid, threadsperblock, stream](th.view_as_real(Psi_DB), r, qB, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from smpr3d.kernels import phase_factor_kernelKB\n",
    "def smatrix_phase_factorsKB(Psi, r, take_beams, q, q_indices, B, out=None):\n",
    "    \"\"\"\n",
    "    Abbreviations:\n",
    "    B: number of (input) beams in S-matrix\n",
    "    K: number of scan positions\n",
    "    MY/MX: detector shape\n",
    "    NY/NX: S-matrix shape\n",
    "\n",
    "    :param Psi: q           MY x MX\n",
    "    :param r:               K x 2\n",
    "    :param take_beams:      MY x MX\n",
    "    :param q:               2 x MY x MX\n",
    "    :param q_indices:       2 x MY x MX\n",
    "    :param out:             K x B x 2\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if out is None:\n",
    "        K, _ = r.shape\n",
    "        out = th.zeros((K, B, 2), dtype=th.float32, device=Psi.device)\n",
    "    else:\n",
    "        out[:] = 0\n",
    "        K, B, c = out.shape\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    threadsperblock = 128#gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(np.array(out.shape[:-1])) / threadsperblock)\n",
    "    tb = take_beams.expand(*Psi.shape)\n",
    "    Psi_B = Psi[tb].reshape(B)\n",
    "    tb = take_beams[None, ...].expand(*q_indices.shape)\n",
    "    qB = q[tb].reshape(2, B)\n",
    "    phase_factor_kernelKB[blockspergrid, threadsperblock, stream](th.view_as_real(Psi_B), r, qB, out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def gradient_fourier_2d(x):\n",
    "    \"\"\"\n",
    "\n",
    "    :param x: B x K x MY x MX\n",
    "    :return: 2 x B x K x MY x MX\n",
    "    \"\"\"\n",
    "    qy, qx = th.meshgrid([th.fft.fftfreq(x.shape[-2]), th.fft.fftfreq(x.shape[-1])])\n",
    "    # 2 x MY x MX\n",
    "    q = th.stack([qy, qx]).to(x.device)\n",
    "    for i in range(len(x.shape) - 2):\n",
    "        q = q.unsqueeze(1)\n",
    "    # print('x.shape, q.shape', x.shape, q.shape)\n",
    "    dx_dr = th.fft.ifft2(th.fft.fft2(x, norm='ortho')[None, ...] * 2j * np.pi * q, norm='ortho')\n",
    "    return dx_dr\n",
    "\n",
    "class SubpixShift():\n",
    "    def __init__(self, MY, MX, device):\n",
    "        qy, qx = np.meshgrid(fftfreq(MY), fftfreq(MX), indexing='ij')\n",
    "        q = th.stack([th.as_tensor(qy, dtype=th.float32, device=device),\n",
    "                      th.as_tensor(qx, dtype=th.float32, device=device)])\n",
    "        self.qqy = q[0][None, None, ...]\n",
    "        self.qqx = q[1][None, None, ...]\n",
    "\n",
    "    def __call__(self, w, rs):\n",
    "        ramp = th.exp(-2j * np.pi * (self.qqy * rs[:, 0][:, None, None] + self.qqx * rs[:, 1][:, None, None]))\n",
    "        Psi = th.fft.fft2(w, norm='ortho')\n",
    "        # B x K x MY x MX\n",
    "        # print(ramp.shape,Psi.shape)\n",
    "        if len(Psi.shape) < 4:\n",
    "            Psi = Psi.unsqueeze(1)\n",
    "            Psi = Psi.repeat(1, ramp.shape[1], 1, 1)\n",
    "        # B x K x MY x MX\n",
    "        w = th.fft.ifft2(Psi * ramp, norm='ortho')\n",
    "        return w\n",
    "\n",
    "from typing import Union\n",
    "from smpr3d.data import Sparse3DData\n",
    "def prox_D_gaussian(\n",
    "        z : th.tensor, \n",
    "        z_hat : th.tensor, \n",
    "        a : Union[th.tensor, Sparse3DData], \n",
    "        beta : float):\n",
    "    \"\"\"\n",
    "    Proximal operator of the Gaussian log-likelihood.\n",
    "\n",
    "    :param z:           K x My x Mx x 2, updated exit waves\n",
    "    :param z_hat:       K x My x Mx x 2, current model exit waves\n",
    "    :param a:           K x My x Mx,     measured amplitudes\n",
    "    :param beta:        float                hyperparameter\n",
    "\n",
    "    :return: z\n",
    "    \"\"\"\n",
    "    # print(type(a))\n",
    "    gpu = cuda.get_current_device()\n",
    "    if isinstance(a, th.Tensor):\n",
    "        threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "        blockspergrid = m.ceil(np.prod(np.array(a.shape)) / threadsperblock)\n",
    "        stream = th.cuda.current_stream().cuda_stream\n",
    "        loss = th.zeros((z.shape[0],), device=z.device, dtype=th.float32)\n",
    "        prox_D_gaussian_kernel[blockspergrid, threadsperblock, stream](z, z_hat, a, loss, beta)\n",
    "        loss = loss.cpu().numpy()\n",
    "    elif isinstance(a, Sparse3DData):\n",
    "        # print(a.indices.device,a.indices.dtype)\n",
    "        # print(a.counts.device,a.counts.dtype)\n",
    "        z, loss = sparse_amplitude_prox(z, z_hat, a.indices, a.counts, beta)\n",
    "    return z, loss\n",
    "\n",
    "def sparse_amplitude_prox(z, z_hat, indices_target, counts_target, beta):\n",
    "    \"\"\"\n",
    "    Amplitude loss proximal operator\n",
    "\n",
    "    :param z:                   K x M1 x M2\n",
    "    :param z_hat:               K x M1 x M2\n",
    "    :param indices_target:      K x num_max_counts\n",
    "    :param counts_target:       K x num_max_counts\n",
    "    :return: z (K x M1 x M2), loss (K,),\n",
    "    \"\"\"\n",
    "\n",
    "    threadsperblock = (256,)\n",
    "    blockspergrid = tuple(np.ceil(np.array(np.prod(z.shape)) / threadsperblock).astype(np.int32))\n",
    "\n",
    "    loss = th.zeros((z.shape[0],), device=z.device, dtype=th.float32)\n",
    "    no_count_indicator = th.iinfo(indices_target.dtype).max\n",
    "\n",
    "    sparse_amplitude_prox_kernel[blockspergrid, threadsperblock](z, z_hat, indices_target, counts_target, loss,\n",
    "                                                                 no_count_indicator, beta)\n",
    "    return z, loss.cpu().numpy()\n",
    "\n",
    "def Qoverlap(r, z, out):\n",
    "    \"\"\"\n",
    "    :param r:       K x 2\n",
    "    :param z:       B x K x MY x MX\n",
    "    :param out:     B x NY x NX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(z.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    # overlap_kernel2[blockspergrid, threadsperblock, stream](r, th.view_as_real(z), th.view_as_real(out))\n",
    "    overlap_kernel2[blockspergrid, threadsperblock, stream](r, z, out)\n",
    "    return out\n",
    "\n",
    "def sparse_smooth_truncated_amplitude_prox(z_model, z_hat, indices_target, counts_target, frame_dimensions, eps=0.5,\n",
    "                                           lam=6e-1):\n",
    "    \"\"\"\n",
    "    Smooth truncated amplitude loss from Chang et al., Overlapping Domain Decomposition Methods for Ptychographic Imaging, (2020)\n",
    "\n",
    "    :param a_model:             K x M1 x M2\n",
    "    :param indices_target:      K x num_max_counts\n",
    "    :param counts_target:       K x num_max_counts\n",
    "    :param frame_dimensions:    2\n",
    "    :return: loss (K,), grad (K x M1 x M2)\n",
    "    \"\"\"\n",
    "\n",
    "    threadsperblock = (256,)\n",
    "    blockspergrid = tuple(np.ceil(np.array(np.prod(z_model.shape)) / threadsperblock).astype(np.int32))\n",
    "\n",
    "    loss = th.zeros((z_model.shape[0],), device=z_model.device, dtype=th.float32)\n",
    "    grad = th.ones_like(z_model)\n",
    "    no_count_indicator = th.iinfo(indices_target.dtype).max\n",
    "\n",
    "    sparse_smooth_truncated_amplitude_prox_kernel[blockspergrid, threadsperblock](z_model, indices_target,\n",
    "                                                                                  no_count_indicator, eps, lam)\n",
    "    return loss, grad\n",
    "\n",
    "\n",
    "def init_z(I_cts, I_inds, Psi_init, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param I_cts:    K x cts       , integer\n",
    "    :param I_inds:   K x cts       , long\n",
    "    :param Psi_init: MY x MX   , complex64\n",
    "    :param out:      K x MY x MX   , complex64\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(np.prod(out.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    no_count_indicator = th.iinfo(I_inds.dtype).max\n",
    "    init_z_kernel[blockspergrid, threadsperblock, stream](I_cts, I_inds, Psi_init, no_count_indicator, out)\n",
    "    return out\n",
    "\n",
    "def Qoverlap_real(r, z, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r:   K x 2\n",
    "    :param z:   B x K x MY x MX\n",
    "    :param out: B x NY x NX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(z.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    overlap_kernel_real[blockspergrid, threadsperblock, stream](r, z, out)\n",
    "    return out\n",
    "\n",
    "def Qoverlap_real2(r, z, out):\n",
    "    K = r.shape[0]\n",
    "    out[:] = 1\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(K * np.prod(z.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    overlap_kernel_real2[blockspergrid, threadsperblock, stream](r, z, out)\n",
    "    return out\n",
    "\n",
    "def Qsplit(r, t, out):\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(out.shape) / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    split_kernel[blockspergrid, threadsperblock, stream](r, t, out)\n",
    "    return out\n",
    "\n",
    "def calc_psi_denom(r, t, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r:   K x 2\n",
    "    :param t:   B x NY x NX\n",
    "    :param out: B x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out[:] = 0\n",
    "    K = r.shape[0]\n",
    "    B, MY, MX = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK\n",
    "    blockspergrid = m.ceil(B * K * MY * MX / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    psi_denom_kernel[blockspergrid, threadsperblock, stream](r, t, out)\n",
    "    return out\n",
    "\n",
    "def calc_psi(r, t, z, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r:   K x 2\n",
    "    :param t:   B x NY x NX\n",
    "    :param z:   K x MY x MX\n",
    "    :param out: B x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out[:] = 0\n",
    "    K = r.shape[0]\n",
    "    B, MY, MX = out.shape\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(B * K * MY * MX / threadsperblock)\n",
    "    stream = th.cuda.current_stream().cuda_stream\n",
    "    psi_kernel[blockspergrid, threadsperblock, stream](r, t, z, th.view_as_real(out))\n",
    "    return out\n",
    "\n",
    "def A_realspace(r, t, psi, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param r:   K x 2\n",
    "    :param t:   BB x NY x NX\n",
    "    :param psi: B x K x MY x MX\n",
    "    :param out: K x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gpu = cuda.get_current_device()\n",
    "    threadsperblock = gpu.MAX_THREADS_PER_BLOCK // 2\n",
    "    blockspergrid = m.ceil(np.prod(out.shape) / threadsperblock)\n",
    "    # print(r.shape,t.shape,psi.shape,out.shape)\n",
    "    A_realspace_kernel[blockspergrid, threadsperblock](r, th.view_as_real(t), th.view_as_real(psi),\n",
    "                                                       th.view_as_real(out))\n",
    "    return out\n",
    "\n",
    "def A(t, psi, r, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param t:   B x NY x NX\n",
    "    :param psi: B x K x MY x MX\n",
    "    :param r:   K x 2\n",
    "    :param out: K x MY x MX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    Qsplit(r, t, out)\n",
    "    out *= psi\n",
    "    out = th.fft.fft2(out, norm='ortho')\n",
    "    return out\n",
    "\n",
    "def At(z, psi, r, out):\n",
    "    \"\"\"\n",
    "\n",
    "    :param z:    K x MY x MX\n",
    "    :param psi:  B x K x MY x MX\n",
    "    :param r:    K x 2\n",
    "    :param out:  B x NY x NX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out[:] = 0\n",
    "    return Qoverlap(r, th.conj(psi) * th.fft.ifft2(z, norm='ortho'), out)\n",
    "\n",
    "def AtF(z, psi, r, out):\n",
    "    \"\"\"\n",
    "    AtF(z_hat, psi, r, S_model_tmp)\n",
    "    :param z:       K x MY x MX\n",
    "    :param psi:     B x K x MY x MX\n",
    "    :param r:       K x 2\n",
    "    :param out:     B x NY x NX\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return Qoverlap(r, th.conj(psi) * z, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
