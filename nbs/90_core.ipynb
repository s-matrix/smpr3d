{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from __future__ import annotations\n",
    "from smpr3d.util import fourier_coordinates_2D, imsave, array_split_divpoints_ntotal\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import TYPE_CHECKING, List, NamedTuple, Optional, Union, Callable\n",
    "from smpr3d.util import fourier_coordinates_2D\n",
    "import torch as th\n",
    "import numpy as np \n",
    "from numpy.fft import fftshift\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "from smpr3d.util import advanced_raster_scan, ZernikeProbeSingle, beamlet_samples, natural_neighbor_weights\n",
    "from numpy.fft import fftfreq\n",
    "from smpr3d.algorithm import admm, ADMMOptions\n",
    "from smpr3d.data import LinearIndexEncoded4DDataset, Dense4DDataset, Metadata4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "@dataclass\n",
    "class ReconstructionOptions:\n",
    "    algorithm : str \n",
    "    algorithm_options : ADMMOptions\n",
    "    compute_device : List[th.device]\n",
    "    auxiliary_variable_device : th.device\n",
    "    n_iter : int\n",
    "    n_batches : int\n",
    "    radius : float\n",
    "    n_angular_samples : int\n",
    "    n_radial_samples : int\n",
    "    \n",
    "    def __init__(self, algorithm = 'admm', \n",
    "                 algorithm_options = ADMMOptions(),\n",
    "                 compute_device = [th.device(f'cuda:{i}') for i in [0]],\n",
    "                 auxiliary_variable_device = th.device(f'cpu'),\n",
    "                 n_iter = 20,\n",
    "                 n_batches = 20,\n",
    "                 radius = 15,\n",
    "                 n_angular_samples = 6,\n",
    "                 n_radial_samples = 4,):\n",
    "        self.algorithm = algorithm\n",
    "        self.algorithm_options = algorithm_options\n",
    "        self.compute_device = compute_device\n",
    "        self.auxiliary_variable_device = auxiliary_variable_device\n",
    "        self.n_iter = n_iter\n",
    "        self.n_batches = n_batches\n",
    "        self.radius = radius\n",
    "        self.n_angular_samples = n_angular_samples\n",
    "        self.n_radial_samples = n_radial_samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "\n",
    "from smpr3d.algorithm import SMPRSolution\n",
    "from smpr3d.data import SMeta\n",
    "def reconstruct_smatrix(data : Union[LinearIndexEncoded4DDataset, Dense4DDataset], \n",
    "                        vacuum_probe_dataset : Union[LinearIndexEncoded4DDataset, Dense4DDataset],\n",
    "                        metadata : Metadata4D, \n",
    "                        options : ReconstructionOptions) -> SMPRSolution:\n",
    "           \n",
    "    r = advanced_raster_scan(data.scan_dimensions[0], \n",
    "                             data.scan_dimensions[1], \n",
    "                             fast_axis=1, \n",
    "                             mirror=[1, 1], \n",
    "                             theta=metadata.rotation_deg, \n",
    "                             dy=metadata.pixel_step[0],                         \n",
    "                             dx=metadata.pixel_step[1])\n",
    "    \n",
    "    sampler = BatchSampler(SequentialSampler(range(len(vacuum_probe_dataset))), batch_size=len(vacuum_probe_dataset), drop_last=False)\n",
    "    vacuum_probe_intensities = 0\n",
    "    max_intensity = 0\n",
    "    if isinstance(vacuum_probe_dataset, Dense4DDataset):\n",
    "        for batch_inds in sampler:\n",
    "            max_batch = th.max(th.sum(vacuum_probe_dataset[batch_inds], dim=(1,2)))\n",
    "            if max_batch > max_intensity:\n",
    "                max_intensity = max_batch.item()\n",
    "            print(max_intensity)\n",
    "            vacuum_probe_intensities += th.sum(vacuum_probe_dataset[batch_inds], dim=(0,))\n",
    "    elif isinstance(vacuum_probe_dataset, LinearIndexEncoded4DDataset):\n",
    "        for batch_inds in sampler:\n",
    "            vacuum_batch = vacuum_probe_dataset[batch_inds]\n",
    "            print(vacuum_batch)\n",
    "            print(vacuum_batch.indices.dtype)\n",
    "            print(type(vacuum_batch.indices))\n",
    "            max_batch = th.max(th.sum(vacuum_batch.counts, dim=1))\n",
    "            if max_batch > max_intensity:\n",
    "                max_intensity = max_batch.item()\n",
    "            w = th.zeros(tuple(vacuum_batch.frame_dimensions), dtype=th.float32)\n",
    "            take = vacuum_batch.indices != th.iinfo(vacuum_batch.indices.dtype).max\n",
    "            w.view(-1).scatter_add_(0, \n",
    "                                    th.tensor(vacuum_batch.indices[take]).long(), \n",
    "                                    th.tensor(vacuum_batch.counts[take], dtype=th.float32))\n",
    "            vacuum_probe_intensities += w\n",
    "    \n",
    "    vacuum_probe0 = vacuum_probe_intensities / len(vacuum_probe_dataset)\n",
    "    vacuum_probe = vacuum_probe0 * (vacuum_probe0 > vacuum_probe0.max() * 15e-2)\n",
    "    vacuum_probe = vacuum_probe * (max_intensity / vacuum_probe.sum())\n",
    "    vacuum_probe = vacuum_probe.cpu().numpy()\n",
    "    \n",
    "    if options.algorithm_options.verbose:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(fftshift(vacuum_probe))\n",
    "        plt.title(f'Vacuum probe intensity: {max_intensity:2.2g} (should be centered)')\n",
    "        plt.show()\n",
    "    \n",
    "    radius = options.radius\n",
    "    n_angular_samples = options.n_angular_samples\n",
    "    n_radial_samples = options.n_radial_samples\n",
    "    \n",
    "    take_beams = vacuum_probe > vacuum_probe.max() * 0.3\n",
    "    dx = 1 / 2 / metadata.k_max\n",
    "    print('data.frame_dimensions',data.frame_dimensions)\n",
    "    print('dx',dx)\n",
    "    \n",
    "    MY, MX = data.frame_dimensions\n",
    "    NY = int((np.ceil((r.max(axis=0)[0] + MY + options.algorithm_options.margin) / MY) * MY).item())\n",
    "    NX = int((np.ceil((r.max(axis=0)[1] + MX + options.algorithm_options.margin) / MX) * MX).item())\n",
    "    N = th.as_tensor([NY, NX])\n",
    "    M = th.as_tensor([MY, MX])\n",
    "        \n",
    "    s_meta = SMeta(take_beams, take_beams, radius, dx, N.numpy(), M.numpy(), options.compute_device[0])\n",
    "    s_meta = s_meta.make_beamlet_meta(n_radial_samples, n_angular_samples)\n",
    "       \n",
    "    if options.algorithm_options.verbose:\n",
    "        fig, ax = plt.subplots(2, s_meta.natural_neighbor_weights.shape[1] // 2 + 1, figsize=(35, 10))\n",
    "        axs = ax.ravel()\n",
    "        for j in range(s_meta.natural_neighbor_weights.shape[1]):\n",
    "            imax = axs[j].imshow(fftshift(s_meta.beamlets[j].cpu().numpy()))\n",
    "            axs[j].set_xticks([])\n",
    "            axs[j].set_yticks([])\n",
    "        axs[-1].imshow(fftshift(vacuum_probe))\n",
    "        plt.show()\n",
    "\n",
    "    qnp = fourier_coordinates_2D(data.frame_dimensions, dx, centered=False)\n",
    "    q = th.as_tensor(qnp)\n",
    "    \n",
    "    Psi_gen = ZernikeProbeSingle(q, metadata.wavelength, fft_shifted=True)\n",
    "    Ap0 = th.as_tensor(vacuum_probe).float()\n",
    "    C1 = th.as_tensor(metadata.aberrations)\n",
    "    \n",
    "    Psi_model = Psi_gen(C1, Ap0).to(options.compute_device[0]).detach()\n",
    "    Psi_init = s_meta.beamlets * Psi_model[None, ...]\n",
    "    Psi_init = Psi_init * (np.sqrt(vacuum_probe.sum())/th.norm(th.sum(Psi_init,0)))\n",
    "    \n",
    "    psi0 = th.fft.ifft2(Psi_init, norm='ortho')\n",
    "    \n",
    "    if options.algorithm_options.verbose:\n",
    "        print(f\"Psi_init norm: {th.norm(th.sum(Psi_init,0))**2}\")\n",
    "        print(f\"psi_init norm: {th.norm(th.sum(psi0,0))**2}\")\n",
    "        \n",
    "        fig, ax = plt.subplots(2, s_meta.Bp // 2 + 1, figsize=(35, 10))\n",
    "        axs = ax.ravel()\n",
    "        for j in range(s_meta.Bp):\n",
    "            imax = axs[j].imshow(imsave(psi0[j].cpu().numpy()))\n",
    "            axs[j].set_xticks([])\n",
    "            axs[j].set_yticks([])\n",
    "        axs[-1].imshow(fftshift(vacuum_probe))\n",
    "        plt.show()\n",
    "        \n",
    "    if options.algorithm_options.verbose:\n",
    "        print(f\"B           : {s_meta.B}\")\n",
    "        print(f\"Bp          : {s_meta.Bp}\")\n",
    "        print(f\"K           : {len(data)}\")\n",
    "        print(f\"NY, NX      : {NY},{NX}\")\n",
    "        print(f\"MY, MX      : {MY},{MX}\")\n",
    "        \n",
    "    if options.algorithm == 'admm':\n",
    "        res = admm(data, r, psi0, s_meta, options.n_iter, options.n_batches, options.algorithm_options)\n",
    "    else:\n",
    "        res = admm(data, r, psi0, s_meta, options.n_iter, options.n_batches, options.algorithm_options)\n",
    "        \n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
