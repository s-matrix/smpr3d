{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Main\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numpy.fft import fftfreq\n",
    "import numpy as np\n",
    "from smpr3d.torch_imports import *\n",
    "from numba import cuda\n",
    "import math as m\n",
    "import cmath as cm\n",
    "import sigpy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fftshift_checkerboard(w, h):\n",
    "    re = np.r_[w * [-1, 1]]  # even-numbered rows\n",
    "    ro = np.r_[w * [1, -1]]  # odd-numbered rows\n",
    "    return np.row_stack(h * (re, ro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cartesian_aberrations(qx, qy, lam, C):\n",
    "    \"\"\"\n",
    "    Zernike polynomials in the cartesian coordinate system\n",
    "    :param qx:\n",
    "    :param qy:\n",
    "    :param lam: wavelength in Angstrom\n",
    "    :param C:   12 x D\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    u = qx * lam\n",
    "    v = qy * lam\n",
    "    u2 = u ** 2\n",
    "    u3 = u ** 3\n",
    "    u4 = u ** 4\n",
    "    # u5 = u ** 5\n",
    "\n",
    "    v2 = v ** 2\n",
    "    v3 = v ** 3\n",
    "    v4 = v ** 4\n",
    "    # v5 = v ** 5\n",
    "\n",
    "    aberr = Param()\n",
    "    aberr.C1 = C[0].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C12a = C[1].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C12b = C[2].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C21a = C[3].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C21b = C[4].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C23a = C[5].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C23b = C[6].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C3 = C[7].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C32a = C[8].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C32b = C[9].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C34a = C[10].unsqueeze(1).unsqueeze(1)\n",
    "    aberr.C34b = C[11].unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    chi = 0\n",
    "\n",
    "    # r-2 = x-2 +y-2.\n",
    "    chi += 1 / 2 * aberr.C1 * (u2 + v2) # r^2\n",
    "    #r-2 cos(2*phi) = x\"2 -y-2.\n",
    "    # r-2 sin(2*phi) = 2*x*y.\n",
    "    chi += 1 / 2 * (aberr.C12a * (u2 - v2) + 2 * aberr.C12b * u * v) # r^2 cos(2 phi) + r^2 sin(2 phi)\n",
    "    # r-3 cos(3*phi) = x-3 -3*x*y'2. r\"3 sin(3*phi) = 3*y*x-2 -y-3.\n",
    "    chi += 1 / 3 * (aberr.C23a * (u3 - 3 * u * v2) + aberr.C23b * (3 * u2 * v - v3))# r^3 cos(3phi) + r^3 sin(3 phi)\n",
    "    # r-3 cos(phi) = x-3 +x*y-2.\n",
    "    # r-3 sin(phi) = y*x-2 +y-3.\n",
    "    chi += 1 / 3 * (aberr.C21a * (u3 + u * v2) + aberr.C21b * (v3 + u2 * v))# r^3 cos(phi) + r^3 sin(phi)\n",
    "    # r-4 = x-4 +2*x-2*y-2 +y-4.\n",
    "    chi += 1 / 4 * aberr.C3 * (u4 + v4 + 2 * u2 * v2)# r^4\n",
    "    # r-4 cos(4*phi) = x-4 -6*x-2*y-2 +y-4.\n",
    "    chi += 1 / 4 * aberr.C34a * (u4 - 6 * u2 * v2 + v4)# r^4 cos(4 phi)\n",
    "    # r-4 sin(4*phi) = 4*x-3*y -4*x*y-3.\n",
    "    chi += 1 / 4 * aberr.C34b * (4 * u3 * v - 4 * u * v3) # r^4 sin(4 phi)\n",
    "    # r-4 cos(2*phi) = x-4 -y-4.\n",
    "    chi += 1 / 4 * aberr.C32a * (u4 - v4)\n",
    "    # r-4 sin(2*phi) = 2*x-3*y +2*x*y-3.\n",
    "    chi += 1 / 4 * aberr.C32b * (2 * u3 * v + 2 * u * v3)\n",
    "    # r-5 cos(phi) = x-5 +2*x-3*y-2 +x*y-4.\n",
    "    # r-5 sin(phi) = y*x\"4 +2*x-2*y-3 +y-5.\n",
    "    # r-5 cos(3*phi) = x-5 -2*x-3*y-2 -3*x*y-4.\n",
    "    # r-5 sin(3*phi) = 3*y*x-4 +2*x-2*y-3 -y-5.\n",
    "    # r-5 cos(5*phi) = x-5 -10*x-3*y-2 +5*x*y-4.\n",
    "    # r-5 sin(5*phi) = 5*y*x-4 -10*x-2*y-3 +y-5.\n",
    "\n",
    "    chi *= 2 * np.pi / lam\n",
    "\n",
    "    return chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def memory_mb(x, dtype=None):\n",
    "    if isinstance(x, th.Tensor):\n",
    "        return x.nelement() * x.element_size() / 2 ** 20\n",
    "    elif isinstance(x, tuple):\n",
    "        assert dtype is not None, 'memory_mb: dtype must not be None'\n",
    "        element_size = th.zeros(1, dtype=dtype).element_size()\n",
    "        nelement = np.prod(np.asarray(x))\n",
    "        return nelement * element_size / 2 ** 20\n",
    "\n",
    "\n",
    "def memory_gb(x, dtype=None):\n",
    "    if isinstance(x, th.Tensor):\n",
    "        return x.nelement() * x.element_size() / 2 ** 30\n",
    "    elif isinstance(x, tuple):\n",
    "        assert dtype is not None, 'memory_mb: dtype must not be None'\n",
    "        element_size = th.zeros(1, dtype=dtype).element_size()\n",
    "        nelement = np.prod(np.asarray(x))\n",
    "        return nelement * element_size / 2 ** 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fourier_coordinates_2D(N, dx=[1.0, 1.0], centered=True):\n",
    "    qxx = fftfreq(N[1], dx[1])\n",
    "    qyy = fftfreq(N[0], dx[0])\n",
    "    if centered:\n",
    "        qxx += 0.5 / N[1] / dx[1]\n",
    "        qyy += 0.5 / N[0] / dx[0]\n",
    "    qx, qy = np.meshgrid(qxx, qyy)\n",
    "    q = np.array([qy, qx]).astype(np.float32)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def array_split_divpoints(ary, indices_or_sections, axis=0):\n",
    "    \"\"\"\n",
    "    Split an array into multiple sub-arrays.\n",
    "    Please refer to the ``split`` documentation.  The only difference\n",
    "    between these functions is that ``array_split`` allows\n",
    "    `indices_or_sections` to be an integer that does *not* equally\n",
    "    divide the axis. For an array of length l that should be split\n",
    "    into n sections, it returns l % n sub-arrays of size l//n + 1\n",
    "    and the rest of size l//n.\n",
    "    See Also\n",
    "    --------\n",
    "    split : Split array into multiple sub-arrays of equal size.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.arange(8.0)\n",
    "    >>> np.array_split(x, 3)\n",
    "        [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n",
    "    >>> x = np.arange(7.0)\n",
    "    >>> np.array_split(x, 3)\n",
    "        [array([0.,  1.,  2.]), array([3.,  4.]), array([5.,  6.])]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Ntotal = ary.shape[axis]\n",
    "    except AttributeError:\n",
    "        Ntotal = len(ary)\n",
    "    try:\n",
    "        # handle array case.\n",
    "        Nsections = len(indices_or_sections) + 1\n",
    "        div_points = [0] + list(indices_or_sections) + [Ntotal]\n",
    "    except TypeError:\n",
    "        # indices_or_sections is a scalar, not an array.\n",
    "        Nsections = int(indices_or_sections)\n",
    "        if Nsections <= 0:\n",
    "            raise ValueError('number sections must be larger than 0.')\n",
    "        Neach_section, extras = divmod(Ntotal, Nsections)\n",
    "        section_sizes = ([0] +\n",
    "                         extras * [Neach_section + 1] +\n",
    "                         (Nsections - extras) * [Neach_section])\n",
    "        div_points = np.array(section_sizes, dtype=np.intp).cumsum()\n",
    "\n",
    "    return div_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def R_factor(z, a, world_size=1):\n",
    "    \"\"\"Calculate R error metric = sum(|z-a|)/sum(|a|).\"\"\"\n",
    "    num = th.norm(th.abs(z) - a,p=1)\n",
    "    denom = th.norm(a,p=1)\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(num)\n",
    "        dist.all_reduce(denom)\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def distance(z, x):\n",
    "    \"\"\"\n",
    "    Distance of two complex vectors\n",
    "    :param z: tensor\n",
    "    :param x: tensor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    c = th.vdot(z.ravel(), x.ravel())\n",
    "    phi = -th.angle(c)\n",
    "    exp_minus_phi = th.exp(1j * phi)\n",
    "    p = exp_minus_phi.to(x.device)\n",
    "    x_hat = x * p\n",
    "    res = th.norm(z - x_hat,2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rel_dist(z, x):\n",
    "    \"\"\"\n",
    "    Distance of two complex vectors\n",
    "    :param z: tensor\n",
    "    :param x: tensor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    d = distance(z, x)\n",
    "    x_norm = th.norm(x,2)\n",
    "    return d / x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "PARAM_PREFIX = 'pars'\n",
    "class Param(dict):\n",
    "    \"\"\"\n",
    "    Convenience class: a dictionary that gives access to its keys\n",
    "    through attributes.\n",
    "    \n",
    "    Note: dictionaries stored in this class are also automatically converted\n",
    "    to Param objects:\n",
    "    >>> p = Param()\n",
    "    >>> p.x = {}\n",
    "    >>> p\n",
    "    Param({})\n",
    "    \n",
    "    While dict(p) returns a dictionary, it is not recursive, so it is better in this case\n",
    "    to use p.todict(). However, p.todict does not check for infinite recursion. So please\n",
    "    don't store a dictionary (or a Param) inside itself.\n",
    "    \n",
    "    BE: Please note also that the recursive behavior of the update function will create\n",
    "    new references. This will lead inconsistency if other objects refer to dicts or Params\n",
    "    in the updated Param instance. \n",
    "    \"\"\"\n",
    "    _display_items_as_attributes = True\n",
    "    _PREFIX = PARAM_PREFIX\n",
    "\n",
    "    def __init__(self, __d__=None, **kwargs):\n",
    "        \"\"\"\n",
    "        A Dictionary that enables access to its keys as attributes.\n",
    "        Same constructor as dict.\n",
    "        \"\"\"\n",
    "        dict.__init__(self)\n",
    "        if __d__ is not None: self.update(__d__)\n",
    "        self.update(kwargs)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self.__dict__.items()\n",
    "\n",
    "    def __setstate__(self, items):\n",
    "        for key, val in items:\n",
    "            self.__dict__[key] = val\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s(%s)\" % (self.__class__.__name__, dict.__repr__(self))\n",
    "\n",
    "    # def __str__(self):\n",
    "    #     from .verbose import report\n",
    "    #     return report(self,depth=7,noheader=True)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # BE: original behavior modified as implicit conversion may destroy references\n",
    "        # Use update(value,Convert=True) instead\n",
    "        # return super(Param, self).__setitem__(key, Param(value) if type(value) == dict else value)\n",
    "        return super(Param, self).__setitem__(key, value)\n",
    "\n",
    "    def __getitem__(self, name):\n",
    "        # item = super(Param, self).__getitem__(name)\n",
    "        # return Param(item) if type(item) == dict else item\n",
    "        return super(Param, self).__getitem__(name)\n",
    "\n",
    "    def __delitem__(self, name):\n",
    "        return super(Param, self).__delitem__(name)\n",
    "\n",
    "    def __delattr__(self, name):\n",
    "        return super(Param, self).__delitem__(name)\n",
    "\n",
    "    # __getattr__ = __getitem__\n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return self.__getitem__(name)\n",
    "        except KeyError as ke:\n",
    "            raise AttributeError(ke)\n",
    "\n",
    "    __setattr__ = __setitem__\n",
    "\n",
    "    def copy(self, depth=0):\n",
    "        \"\"\"\n",
    "        :returns Param: A (recursive) copy of P with depth `depth` \n",
    "        \"\"\"\n",
    "        d = Param(self)\n",
    "        if depth > 0:\n",
    "            for k, v in d.iteritems():\n",
    "                if isinstance(v, self.__class__): d[k] = v.copy(depth - 1)\n",
    "        return d\n",
    "\n",
    "    def __dir__(self):\n",
    "        \"\"\"\n",
    "        Defined to include the keys when using dir(). Useful for\n",
    "        tab completion in e.g. ipython.\n",
    "        If you do not wish the dict key's be displayed as attributes\n",
    "        (although they are still accessible as such) set the class \n",
    "        attribute `_display_items_as_attributes` to False. Default is\n",
    "        True.\n",
    "        \"\"\"\n",
    "        if self._display_items_as_attributes:\n",
    "            return self.keys()\n",
    "            # return [item.__dict__.get('name',str(key)) for key,item in self.iteritems()]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def update(self, __d__=None, in_place_depth=0, Convert=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Update Param - almost same behavior as dict.update, except\n",
    "        that all dictionaries are converted to Param if `Convert` is set \n",
    "        to True, and update may occur in-place recursively for other Param\n",
    "        instances that self refers to.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Convert : bool \n",
    "                  If True, convert all dict-like values in self also to Param.\n",
    "                  *WARNING* \n",
    "                  This mey result in misdirected references in your environment\n",
    "        in_place_depth : int \n",
    "                  Counter for recursive in-place updates \n",
    "                  If the counter reaches zero, the Param to a key is\n",
    "                  replaced instead of updated\n",
    "        \"\"\"\n",
    "\n",
    "        def _k_v_update(k, v):\n",
    "            # If an element is itself a dict, convert it to Param\n",
    "            if Convert and hasattr(v, 'keys'):\n",
    "                # print 'converting'\n",
    "                v = Param(v)\n",
    "            # new key \n",
    "            if not k in self:\n",
    "                self[k] = v\n",
    "            # If this key already exists and is already dict-like, update it\n",
    "            elif in_place_depth > 0 and hasattr(v, 'keys') and isinstance(self[k], self.__class__):\n",
    "                self[k].update(v, in_place_depth - 1)\n",
    "                \"\"\"\n",
    "                if isinstance(self[k],self.__class__):\n",
    "                    # Param gets recursive in_place updates\n",
    "                    self[k].update(v, in_place_depth - 1)\n",
    "                else:\n",
    "                    # dicts are only updated in-place once\n",
    "                    self[k].update(v)\n",
    "                \"\"\"\n",
    "            # Otherwise just replace it\n",
    "            else:\n",
    "                self[k] = v\n",
    "\n",
    "        if __d__ is not None:\n",
    "            if hasattr(__d__, 'keys'):\n",
    "                # Iterate through dict-like argument\n",
    "                for k, v in __d__.items():\n",
    "                    _k_v_update(k, v)\n",
    "\n",
    "            else:\n",
    "                # here we assume a (key,value) list.\n",
    "                for (k, v) in __d__:\n",
    "                    _k_v_update(k, v)\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            _k_v_update(k, v)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _to_dict(self, Recursive=False):\n",
    "        \"\"\"\n",
    "        Convert to dictionary (recursively if needed).\n",
    "        \"\"\"\n",
    "        if not Recursive:\n",
    "            return dict(self)\n",
    "        else:\n",
    "            d = dict(self)\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, self.__class__): d[k] = v._to_dict(Recursive)\n",
    "        return d\n",
    "\n",
    "    @classmethod\n",
    "    def _from_dict(cls, dct):\n",
    "        \"\"\"\n",
    "        Make Param from dict. This is similar to the __init__ call\n",
    "        \"\"\"\n",
    "        # p=Param()\n",
    "        # p.update(dct.copy())\n",
    "        return Param(dct.copy())\n",
    "\n",
    "\n",
    "def validate_standard_param(sp, p=None, prefix=None):\n",
    "    \"\"\"\\\n",
    "    validate_standard_param(sp) checks if sp follows the standard parameter convention.\n",
    "    validate_standard_param(sp, p) attemps to check if p is a valid implementation of sp.\n",
    "\n",
    "    NOT VERY SOPHISTICATED FOR NOW!\n",
    "    \"\"\"\n",
    "    if p is None:\n",
    "        good = True\n",
    "        for k, v in sp.iteritems():\n",
    "            if k.startswith('_'): continue\n",
    "            if type(v) == type(sp):\n",
    "                pref = k if prefix is None else '.'.join([prefix, k])\n",
    "                good &= validate_standard_param(v, prefix=pref)\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    a, b, c = v\n",
    "                    if prefix is not None:\n",
    "                        print('    %s.%s = %s' % (prefix, k, str(v)))\n",
    "                    else:\n",
    "                        print('    %s = %s' % (k, str(v)))\n",
    "                except:\n",
    "                    good = False\n",
    "                    if prefix is not None:\n",
    "                        print('!!! %s.%s = %s <--- Incorrect' % (prefix, k, str(v)))\n",
    "                    else:\n",
    "                        print('!!! %s = %s <--- Incorrect' % (k, str(v)))\n",
    "\n",
    "        return good\n",
    "    else:\n",
    "        raise RuntimeError('Checking if a param fits with a standard is not yet implemented')\n",
    "\n",
    "\n",
    "def format_standard_param(p):\n",
    "    \"\"\"\\\n",
    "    Pretty-print a Standard Param class.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    if not validate_standard_param(p):\n",
    "        print('Standard parameter does not')\n",
    "    for k, v in p.iteritems():\n",
    "        if k.startswith('_'): continue\n",
    "        if type(v) == type(p):\n",
    "            sublines = format_standard_param(v)\n",
    "            lines += [k + '.' + s for s in sublines]\n",
    "        else:\n",
    "            lines += ['%s = %s #[%s] %s' % (k, str(v[1]), v[0], v[2])]\n",
    "    return lines\n",
    "\n",
    "\n",
    "def asParam(obj):\n",
    "    \"\"\"\n",
    "    Convert the input to a Param.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : dict_like\n",
    "        Input structure, in any format that can be converted to a Param.\n",
    "        \n",
    "    Returns:\n",
    "    out : Param\n",
    "        The Param structure built from a. No copy is done if the input\n",
    "        is already a Param.  \n",
    "    \"\"\"\n",
    "    return obj if isinstance(obj, Param) else Param(obj)\n",
    "\n",
    "\n",
    "def make_default(default_dict_or_file):\n",
    "    \"\"\"\n",
    "    convert description dict to a module dict using a possibly verbose Q & A game\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def single_sideband_reconstruction(G, Qx_all, Qy_all, Kx_all, Ky_all, aberrations, theta_rot, alpha_rad,\n",
    "                                   Ψ_Qp, Ψ_Qp_left_sb, Ψ_Qp_right_sb, eps, lam):\n",
    "    xp = sp.backend.get_array_module(G)\n",
    "    threadsperblock = 2 ** 8\n",
    "    blockspergrid = m.ceil(np.prod(G.shape) / threadsperblock)\n",
    "    strides = xp.array((np.array(G.strides) / (G.nbytes / G.size)).astype(np.int))\n",
    "    scale = 1\n",
    "    single_sideband_kernel[blockspergrid, threadsperblock](G, strides, Qx_all, Qy_all, Kx_all, Ky_all, aberrations,\n",
    "                                                           theta_rot, alpha_rad, Ψ_Qp, Ψ_Qp_left_sb,\n",
    "                                                           Ψ_Qp_right_sb, eps, lam, scale)\n",
    "    xp.cuda.Device(Ψ_Qp.device).synchronize()\n",
    "\n",
    "@cuda.jit\n",
    "def single_sideband_kernel(G, strides, Qx_all, Qy_all, Kx_all, Ky_all, aberrations, theta_rot, alpha,\n",
    "                           Ψ_Qp, Ψ_Qp_left_sb, Ψ_Qp_right_sb, eps, lam, scale):\n",
    "    def aperture2(qx, qy, lam, alpha_max, scale):\n",
    "        qx2 = qx ** 2\n",
    "        qy2 = qy ** 2\n",
    "        q = m.sqrt(qx2 + qy2)\n",
    "        ktheta = m.asin(q * lam)\n",
    "        return (ktheta < alpha_max) * scale\n",
    "\n",
    "    def chi3(qy, qx, lam, C):\n",
    "        \"\"\"\n",
    "        Zernike polynomials in the cartesian coordinate system\n",
    "        :param qx:\n",
    "        :param qy:\n",
    "        :param lam: wavelength in Angstrom\n",
    "        :param C:   (12 ,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        u = qx * lam\n",
    "        v = qy * lam\n",
    "        u2 = u ** 2\n",
    "        u3 = u ** 3\n",
    "        u4 = u ** 4\n",
    "        # u5 = u ** 5\n",
    "\n",
    "        v2 = v ** 2\n",
    "        v3 = v ** 3\n",
    "        v4 = v ** 4\n",
    "        # v5 = v ** 5\n",
    "\n",
    "        # aberr = Param()\n",
    "        # aberr.C1 = C[0]\n",
    "        # aberr.C12a = C[1]\n",
    "        # aberr.C12b = C[2]\n",
    "        # aberr.C21a = C[3]\n",
    "        # aberr.C21b = C[4]\n",
    "        # aberr.C23a = C[5]\n",
    "        # aberr.C23b = C[6]\n",
    "        # aberr.C3 = C[7]\n",
    "        # aberr.C32a = C[8]\n",
    "        # aberr.C32b = C[9]\n",
    "        # aberr.C34a = C[10]\n",
    "        # aberr.C34b = C[11]\n",
    "\n",
    "        chi = 0\n",
    "\n",
    "        # r-2 = x-2 +y-2.\n",
    "        chi += 1 / 2 * C[0] * (u2 + v2)  # r^2\n",
    "        # r-2 cos(2*phi) = x\"2 -y-2.\n",
    "        # r-2 sin(2*phi) = 2*x*y.\n",
    "        chi += 1 / 2 * (C[1] * (u2 - v2) + 2 * C[2] * u * v)  # r^2 cos(2 phi) + r^2 sin(2 phi)\n",
    "        # r-3 cos(3*phi) = x-3 -3*x*y'2. r\"3 sin(3*phi) = 3*y*x-2 -y-3.\n",
    "        chi += 1 / 3 * (C[5] * (u3 - 3 * u * v2) + C[6] * (3 * u2 * v - v3))  # r^3 cos(3phi) + r^3 sin(3 phi)\n",
    "        # r-3 cos(phi) = x-3 +x*y-2.\n",
    "        # r-3 sin(phi) = y*x-2 +y-3.\n",
    "        chi += 1 / 3 * (C[3] * (u3 + u * v2) + C[4] * (v3 + u2 * v))  # r^3 cos(phi) + r^3 sin(phi)\n",
    "        # r-4 = x-4 +2*x-2*y-2 +y-4.\n",
    "        chi += 1 / 4 * C[7] * (u4 + v4 + 2 * u2 * v2)  # r^4\n",
    "        # r-4 cos(4*phi) = x-4 -6*x-2*y-2 +y-4.\n",
    "        chi += 1 / 4 * C[10] * (u4 - 6 * u2 * v2 + v4)  # r^4 cos(4 phi)\n",
    "        # r-4 sin(4*phi) = 4*x-3*y -4*x*y-3.\n",
    "        chi += 1 / 4 * C[11] * (4 * u3 * v - 4 * u * v3)  # r^4 sin(4 phi)\n",
    "        # r-4 cos(2*phi) = x-4 -y-4.\n",
    "        chi += 1 / 4 * C[8] * (u4 - v4)\n",
    "        # r-4 sin(2*phi) = 2*x-3*y +2*x*y-3.\n",
    "        chi += 1 / 4 * C[9] * (2 * u3 * v + 2 * u * v3)\n",
    "        # r-5 cos(phi) = x-5 +2*x-3*y-2 +x*y-4.\n",
    "        # r-5 sin(phi) = y*x\"4 +2*x-2*y-3 +y-5.\n",
    "        # r-5 cos(3*phi) = x-5 -2*x-3*y-2 -3*x*y-4.\n",
    "        # r-5 sin(3*phi) = 3*y*x-4 +2*x-2*y-3 -y-5.\n",
    "        # r-5 cos(5*phi) = x-5 -10*x-3*y-2 +5*x*y-4.\n",
    "        # r-5 sin(5*phi) = 5*y*x-4 -10*x-2*y-3 +y-5.\n",
    "\n",
    "        chi *= 2 * np.pi / lam\n",
    "\n",
    "        return chi\n",
    "\n",
    "    gs = G.shape\n",
    "    N = gs[0] * gs[1] * gs[2] * gs[3]\n",
    "    n = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    iqy = n // strides[0]\n",
    "    iqx = (n - iqy * strides[0]) // strides[1]\n",
    "    iky = (n - (iqy * strides[0] + iqx * strides[1])) // strides[2]\n",
    "    ikx = (n - (iqy * strides[0] + iqx * strides[1] + iky * strides[2])) // strides[3]\n",
    "\n",
    "    if n < N:\n",
    "\n",
    "        Qx = Qx_all[iqx]\n",
    "        Qy = Qy_all[iqy]\n",
    "        Kx = Kx_all[ikx]\n",
    "        Ky = Ky_all[iky]\n",
    "\n",
    "        Qx_rot = Qx * m.cos(theta_rot) - Qy * m.sin(theta_rot)\n",
    "        Qy_rot = Qx * m.sin(theta_rot) + Qy * m.cos(theta_rot)\n",
    "\n",
    "        Qx = Qx_rot\n",
    "        Qy = Qy_rot\n",
    "\n",
    "        A = aperture2(Ky, Kx, lam, alpha, scale) * cm.exp(-1j * chi3(Ky, Kx, lam, aberrations))\n",
    "        chi_KplusQ = chi3(Ky + Qy, Kx + Qx, lam, aberrations)\n",
    "        A_KplusQ = aperture2(Ky + Qy, Kx + Qx, lam, alpha, scale) * cm.exp(-1j * chi_KplusQ)\n",
    "        chi_KminusQ = chi3(Ky - Qy, Kx - Qx, lam, aberrations)\n",
    "        A_KminusQ = aperture2(Ky - Qy, Kx - Qx, lam, alpha, scale) * cm.exp(-1j * chi_KminusQ)\n",
    "\n",
    "        Γ = A.conjugate() * A_KminusQ - A * A_KplusQ.conjugate()\n",
    "\n",
    "        Kplus = sqrt((Kx + Qx) ** 2 + (Ky + Qy) ** 2)\n",
    "        Kminus = sqrt((Kx - Qx) ** 2 + (Ky - Qy) ** 2)\n",
    "        K = sqrt(Kx ** 2 + Ky ** 2)\n",
    "        bright_field = K < alpha / lam\n",
    "        double_overlap1 = (Kplus < alpha / lam) * bright_field * (Kminus > alpha / lam)\n",
    "        double_overlap2 = (Kplus > alpha / lam) * bright_field * (Kminus < alpha / lam)\n",
    "\n",
    "        Γ_abs = abs(Γ)\n",
    "        take = Γ_abs > eps and bright_field\n",
    "        if take:\n",
    "            val = G[iqy, iqx, iky, ikx] * Γ.conjugate()\n",
    "            cuda.atomic.add(Ψ_Qp.real, (iqy, iqx), val.real)\n",
    "            cuda.atomic.add(Ψ_Qp.imag, (iqy, iqx), val.imag)\n",
    "        if double_overlap1:\n",
    "            val = G[iqy, iqx, iky, ikx] * Γ.conjugate()\n",
    "            cuda.atomic.add(Ψ_Qp_left_sb.real, (iqy, iqx), val.real)\n",
    "            cuda.atomic.add(Ψ_Qp_left_sb.imag, (iqy, iqx), val.imag)\n",
    "        if double_overlap2:\n",
    "            val = G[iqy, iqx, iky, ikx] * Γ.conjugate()\n",
    "            cuda.atomic.add(Ψ_Qp_right_sb.real, (iqy, iqx), val.real)\n",
    "            cuda.atomic.add(Ψ_Qp_right_sb.imag, (iqy, iqx), val.imag)\n",
    "        if iqx == 0 and iqy == 0:\n",
    "            val = abs(G[iqy, iqx, iky, ikx]) + 1j * 0\n",
    "            cuda.atomic.add(Ψ_Qp.real, (iqy, iqx), val.real)\n",
    "            cuda.atomic.add(Ψ_Qp_left_sb.real, (iqy, iqx), val.real)\n",
    "            cuda.atomic.add(Ψ_Qp_right_sb.real, (iqy, iqx), val.real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def sector_mask(shape, centre, radius, angle_range=(0,360)):\n",
    "    \"\"\"\n",
    "    Return a boolean mask for a circular sector. The start/stop angles in\n",
    "    `angle_range` should be given in clockwise order.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = np.ogrid[:shape[0], :shape[1]]\n",
    "    cx, cy = centre\n",
    "    tmin, tmax = np.deg2rad(angle_range)\n",
    "\n",
    "    # ensure stop angle > start angle\n",
    "    if tmax < tmin:\n",
    "        tmax += 2 * np.pi\n",
    "\n",
    "    # convert cartesian --> polar coordinates\n",
    "    r2 = (x - cx) * (x - cx) + (y - cy) * (y - cy)\n",
    "    theta = np.arctan2(x - cx, y - cy) - tmin\n",
    "\n",
    "    # wrap angles between 0 and 2*pi\n",
    "    theta %= (2 * np.pi)\n",
    "\n",
    "    # circular mask\n",
    "    circmask = r2 <= radius * radius\n",
    "\n",
    "    # angular mask\n",
    "    anglemask = theta <= (tmax - tmin)\n",
    "\n",
    "    return circmask * anglemask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from math import sqrt\n",
    "def wavelength(E_eV):\n",
    "    emass = 510.99906;  # electron rest mass in keV\n",
    "    hc = 12.3984244;  # h*c\n",
    "    lam = hc / m.sqrt(E_eV * 1e-3 * (2 * emass + E_eV * 1e-3))  # in Angstrom\n",
    "    return lam  \n",
    "\n",
    "\n",
    "def DOF(alpha, E_eV):\n",
    "    E0 = E_eV\n",
    "\n",
    "    # Calculate wavelength and electron interaction parameter\n",
    "    m = 9.109383 * 10 ** -31\n",
    "    e = 1.602177 * 10 ** -19\n",
    "    c = 299792458\n",
    "    h = 6.62607 * 10 ** -34\n",
    "\n",
    "    lam = h / sqrt(2 * m * e * E0) / sqrt(1 + e * E0 / 2 / m / c ** 2) * 10 ** 10\n",
    "    DOF = 2 * lam / alpha ** 2\n",
    "    return DOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@cuda.jit\n",
    "def dense_to_sparse_kernel(dense, indices, counts, frame_dimensions):\n",
    "    ny, nx = cuda.grid(2)\n",
    "    NY, NX, MYBIN, MXBIN = dense.shape\n",
    "    MY, MX = frame_dimensions\n",
    "    if ny < NY and nx < NX:\n",
    "        k = 0\n",
    "        for mx in range(MX):\n",
    "            for my in range(MY):\n",
    "                idx1d = my * MX + mx\n",
    "                if dense[ny,nx,my,mx] > 0:\n",
    "                    indices[ny,nx,k] = idx1d\n",
    "                    counts[ny,nx,k] = dense[ny,nx,my,mx]\n",
    "                    k += 1                    \n",
    "\n",
    "def advanced_raster_scan(ny=10, nx=10, fast_axis=1, mirror=[1, 1], theta=0, dy=1, dx=1):\n",
    "    \"\"\"\n",
    "    Generates as raster scan.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ny, nx : int\n",
    "        Number of steps in *y* (vertical) and *x* (horizontal) direction\n",
    "        *x* is the fast axis\n",
    "        \n",
    "    dy, dx : float\n",
    "        Step size (grid spacinf) in *y* and *x*  \n",
    "        2\n",
    "    Returns\n",
    "    -------\n",
    "    pos : ndarray\n",
    "        A (N,2)-array of positions.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    iix, iiy = np.indices((nx, ny))\n",
    "    if fast_axis != 1:\n",
    "        tmp = iix\n",
    "        iix = iiy\n",
    "        iiy = tmp\n",
    "\n",
    "    # print iix.shape, iiy.shape\n",
    "    positions = np.array([(dx * i, dy * j) for i, j in zip(iix.ravel(), iiy.ravel())]).astype(np.float32)\n",
    "\n",
    "    mins = np.array([positions[:, 0].min(), positions[:, 1].min()])\n",
    "    maxs = np.array([positions[:, 0].max(), positions[:, 1].max()])\n",
    "\n",
    "    center = mins + (maxs - mins) / 2.0\n",
    "    positions -= center\n",
    "\n",
    "    positions[:, 0] *= mirror[0]\n",
    "    positions[:, 1] *= mirror[1]\n",
    "\n",
    "    theta_rad = theta / 180.0 * np.pi\n",
    "    R = np.array([[np.cos(theta_rad), -np.sin(theta_rad)],\n",
    "                  [np.sin(theta_rad), np.cos(theta_rad)]])\n",
    "    # rotate counterclockwise by theta\n",
    "    positions = positions.dot(R)\n",
    "    mins = np.array([positions[:, 0].min(), positions[:, 1].min()])\n",
    "    positions -= mins\n",
    "    return positions.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def advanced_raster_scan(ny=10, nx=10, fast_axis=1, mirror=[1, 1], theta=0, dy=1, dx=1):\n",
    "    \"\"\"\n",
    "    Generates as raster scan.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ny, nx : int\n",
    "        Number of steps in *y* (vertical) and *x* (horizontal) direction\n",
    "        *x* is the fast axis\n",
    "        \n",
    "    dy, dx : float\n",
    "        Step size (grid spacinf) in *y* and *x*  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pos : ndarray\n",
    "        A (N,2)-array of positions.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    iiy, iix = np.indices((ny, nx))\n",
    "    if fast_axis != 1:\n",
    "        tmp = iix\n",
    "        iix = iiy\n",
    "        iiy = tmp\n",
    "\n",
    "    # print iix.shape, iiy.shape\n",
    "    positions = np.array([(dy * i, dx * j) for i, j in zip(iiy.ravel(), iix.ravel())]).astype(np.float32)\n",
    "\n",
    "    mins = np.array([positions[:, 0].min(), positions[:, 1].min()])\n",
    "    maxs = np.array([positions[:, 0].max(), positions[:, 1].max()])\n",
    "\n",
    "    center = mins + (maxs - mins) / 2.0\n",
    "    positions -= center\n",
    "\n",
    "    positions[:, 0] *= mirror[0]\n",
    "    positions[:, 1] *= mirror[1]\n",
    "\n",
    "    theta_rad = theta / 180.0 * np.pi\n",
    "    R = np.array([[np.cos(theta_rad), -np.sin(theta_rad)],\n",
    "                  [np.sin(theta_rad), np.cos(theta_rad)]])\n",
    "    # rotate counterclockwise by theta\n",
    "    positions = positions.dot(R)\n",
    "    mins = np.array([positions[:, 0].min(), positions[:, 1].min()])\n",
    "    positions -= mins\n",
    "    return positions.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_util.ipynb.\nConverted 10a_fasta.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "def get_qx_qy_1D(M, dx, dtype, fft_shifted=False):\n",
    "    xp = sp.backend.get_array_module(dx)\n",
    "    qxa = xp.fft.fftfreq(M[0], dx[0]).astype(dtype)\n",
    "    qya = xp.fft.fftfreq(M[1], dx[1]).astype(dtype)\n",
    "    if fft_shifted:\n",
    "        qxa = xp.fft.fftshift(qxa)\n",
    "        qya = xp.fft.fftshift(qya)\n",
    "    return qxa, qya\n",
    "\n",
    "\n",
    "def get_qx_qy_2D(M, dx, dtype, fft_shifted=False):\n",
    "    xp = sp.backend.get_array_module(dx)\n",
    "    qxa = xp.fft.fftfreq(M[0], dx[0]).astype(dtype)\n",
    "    qya = xp.fft.fftfreq(M[1], dx[1]).astype(dtype)\n",
    "    [qxn, qyn] = xp.meshgrid(qxa, qya)\n",
    "    if fft_shifted:\n",
    "        qxn = xp.fft.fftshift(qxn)\n",
    "        qyn = xp.fft.fftshift(qyn)\n",
    "    return qxn, qyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from math import sqrt\n",
    "\n",
    "def scatter_add_patches(input: th.Tensor, out: th.Tensor, axes, positions, patch_size, reduce_dim=None) -> th.Tensor:\n",
    "    \"\"\"\n",
    "    Scatter_adds K patches of size :patch_size: at axes [ax1, ax2] into the output tensor. The patches are added at\n",
    "    positions :positions:. Additionally, several dimensions of the input tensor can be summed, specified by reduce_dims.\n",
    "\n",
    "    :param input:   K x M1 x M2 at least 3-dimensional tensor of patches,\n",
    "    :param out: at least two-dimensional tensor that is the scatter_add target\n",
    "    :param axes: (2,) axes at which to scatter the input\n",
    "    :param positions: K x 2 LongTensor\n",
    "    :param patch_size: (2,) LongTensor\n",
    "    :param reduce_dims: (N,) LongTensor\n",
    "    :return: out, the target of scatter_add_\n",
    "    \"\"\"\n",
    "    if reduce_dim is not None:\n",
    "        other1 = th.split(input, 1, dim=reduce_dim)\n",
    "        other = tuple()\n",
    "        for one in other1:\n",
    "            other += (one.squeeze_().contiguous(),)\n",
    "        # now we have D tensors of shape K B M1 M2 2\n",
    "    else:\n",
    "        other = [input]\n",
    "\n",
    "    r = positions\n",
    "    s = patch_size\n",
    "    K = r.shape[0]\n",
    "\n",
    "    # patches has dimension  K x M1 x M2 x 2\n",
    "\n",
    "    index0 = th.arange(s[0], device=input.device, dtype=th.long).view(s[0], 1).expand(s[0], s[1])\n",
    "    index1 = th.arange(s[1], device=input.device, dtype=th.long).view(1, s[1]).expand(s[0], s[1])\n",
    "\n",
    "    # size is patch_size\n",
    "    # print(f\"strides at axes: {input.stride(axes[0]), input.stride(axes[1])}\")\n",
    "    index = out.stride(axes[0]) * (index0 + r[:, 0].view(K, 1, 1)) + out.stride(axes[1]) * (\n",
    "            index1 + r[:, 1].view(K, 1, 1))\n",
    "\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    higher_dim_offsets = th.arange(out.stride(axes[1]), device=input.device).view(1, 1, 1, out.stride(axes[1]))\n",
    "    index = index.view(index.shape[0], index.shape[1], index.shape[2], 1).expand(\n",
    "        (index.shape[0], index.shape[1], index.shape[2], out.stride(axes[1])))\n",
    "\n",
    "    # print(higher_dim_offsets, higher_dim_offsets.shape, index.shape)\n",
    "    index = index + higher_dim_offsets\n",
    "    # now we have the K x M1 x M2 x 2 indices into the N1 x N2 x 2 array\n",
    "\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    # index = index.view(index.shape[0], 1, index.shape[1], index.shape[2], index.shape[3]).expand(\n",
    "    #     (index.shape[0], B, index.shape[1], index.shape[2], index.shape[3]))\n",
    "\n",
    "    # print(f\"max index   : {th.max(index.view(-1))}\")\n",
    "    # print(f\"len   out   : {out.view(-1).shape[0]}\")\n",
    "    # print(f\"index shape : {index.view(-1).shape[0]}\")\n",
    "    # print(f\"others shape: {other[0].view(-1).shape[0]}\")\n",
    "\n",
    "    for i, one in enumerate(other):\n",
    "        # print(f\"others [{i}] shape: {one.view(-1).shape[0]}\")\n",
    "        # print(one.shape)\n",
    "        # print(index.shape)\n",
    "        out.view(-1).scatter_add_(0, index.view(-1), one.view(-1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gather_patches(input, axes, positions, patch_size, out=None) -> th.Tensor:\n",
    "    \"\"\"\n",
    "    Gathers K patches of size :patch_size: at axes [ax1, ax2] of the input tensor. The patches are collected started at\n",
    "    K positions pos.\n",
    "\n",
    "    if :input: is an n-dimensional tensor with size (x_0, x_1, x_2, ..., x_a, x_ax1, x_ax2, x_b, ..., x_{n-1})\n",
    "    then :out: is an n-dimensional tensor with size  (K, x_0, x_1, x_2, ..., x_a, patch_size[0], patch_size[1], x_3, ..., x_{n-1})\n",
    "\n",
    "    :param input: at least two-dimensional tensor\n",
    "    :param axes: axes at which to gather the patches\n",
    "    :param positions: K x 2 LongTensor\n",
    "    :param patch_size: (2,) LongTensor\n",
    "    :param out: n-dimensional tensor with size  (K, x_0, x_1, x_2, ..., x_a, patch_size[0], patch_size[1], x_3, ..., x_{n-1})\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # print(f\"input shape: {input.shape}\")\n",
    "    # print(f\"positions.dtype {positions.dtype}\")\n",
    "    r = positions\n",
    "    s = patch_size\n",
    "    K = positions.shape[0]\n",
    "\n",
    "    # condense all dimensions x_0 ... x_a\n",
    "    dim0size = th.prod(th.Tensor([input.shape[:axes[0]]])).int().item() if axes[0] > 0 else 1\n",
    "    view = [dim0size]\n",
    "    for d in input.shape[axes[0]:]:\n",
    "        view.append(d)\n",
    "    y = input.view(th.Size(view)).squeeze()\n",
    "\n",
    "    index0 = th.arange(s[0], device=input.device, dtype=th.long).view(s[0], 1).expand(s[0], s[1])\n",
    "    index1 = th.arange(s[1], device=input.device, dtype=th.long).view(1, s[1]).expand(s[0], s[1])\n",
    "\n",
    "    # size is patch_size\n",
    "    # print(f\"strides at axes: {input.stride(axes[0]), input.stride(axes[1])}\")\n",
    "    # print(index0.dtype, r.dtype)\n",
    "    index = input.stride(axes[0]) * (index0 + r[:, 0].view(K, 1, 1)) + input.stride(axes[1]) * (\n",
    "            index1 + r[:, 1].view(K, 1, 1))\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    higher_dim_offsets = th.arange(input.stride(axes[1]), device=input.device).view(1, 1, 1, input.stride(axes[1]))\n",
    "    index = index.view(index.shape[0], index.shape[1], index.shape[2], 1).expand(\n",
    "        (index.shape[0], index.shape[1], index.shape[2], input.stride(axes[1])))\n",
    "    # print(higher_dim_offsets, higher_dim_offsets.shape, index.shape)\n",
    "    index = index + higher_dim_offsets\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    index = index.view(index.shape[0], 1, index.shape[1], index.shape[2], index.shape[3]).expand(\n",
    "        (index.shape[0], dim0size, index.shape[1], index.shape[2], index.shape[3]))\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    lower_dim_offset = th.arange(dim0size, device=input.device) * y.stride(0)\n",
    "    lower_dim_offset = lower_dim_offset.view(1, dim0size, 1, 1, 1).long()\n",
    "    index = index + lower_dim_offset\n",
    "    # print(f\"new index shape: {index.shape}\")\n",
    "    index = index.contiguous().view(-1)\n",
    "    out = th.index_select(y.view(-1), 0, index, out=out)\n",
    "\n",
    "    out_view = (K,)\n",
    "    for ax in input.shape[:axes[0]]:\n",
    "        out_view += (ax,)\n",
    "    out_view += (patch_size[0].item(),)\n",
    "    out_view += (patch_size[1].item(),)\n",
    "    for ax in input.shape[axes[1] + 1:]:\n",
    "        out_view += (ax,)\n",
    "\n",
    "    out = out.view(out_view)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def array_split_divpoints(ary, indices_or_sections, axis=0):\n",
    "    \"\"\"\n",
    "    Split an array into multiple sub-arrays.\n",
    "    Please refer to the ``split`` documentation.  The only difference\n",
    "    between these functions is that ``array_split`` allows\n",
    "    `indices_or_sections` to be an integer that does *not* equally\n",
    "    divide the axis. For an array of length l that should be split\n",
    "    into n sections, it returns l % n sub-arrays of size l//n + 1\n",
    "    and the rest of size l//n.\n",
    "    See Also\n",
    "    --------\n",
    "    split : Split array into multiple sub-arrays of equal size.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.arange(8.0)\n",
    "    >>> np.array_split(x, 3)\n",
    "        [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n",
    "    >>> x = np.arange(7.0)\n",
    "    >>> np.array_split(x, 3)\n",
    "        [array([0.,  1.,  2.]), array([3.,  4.]), array([5.,  6.])]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Ntotal = ary.shape[axis]\n",
    "    except AttributeError:\n",
    "        Ntotal = len(ary)\n",
    "    try:\n",
    "        # handle array case.\n",
    "        Nsections = len(indices_or_sections) + 1\n",
    "        div_points = [0] + list(indices_or_sections) + [Ntotal]\n",
    "    except TypeError:\n",
    "        # indices_or_sections is a scalar, not an array.\n",
    "        Nsections = int(indices_or_sections)\n",
    "        if Nsections <= 0:\n",
    "            raise ValueError('number sections must be larger than 0.')\n",
    "        Neach_section, extras = divmod(Ntotal, Nsections)\n",
    "        section_sizes = ([0] +\n",
    "                         extras * [Neach_section + 1] +\n",
    "                         (Nsections - extras) * [Neach_section])\n",
    "        div_points = np.array(section_sizes, dtype=np.intp).cumsum()\n",
    "\n",
    "    return div_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_imports.ipynb.\nConverted 01_util.ipynb.\nConverted 01a_util_plot.ipynb.\nConverted 01b_util_kernels.ipynb.\nConverted 01c_util_ssb.ipynb.\nConverted 01d_util_illumination.ipynb.\nConverted 01e_util_io.ipynb.\nConverted 06_sparse_data.ipynb.\nConverted 10a_fasta.ipynb.\nConverted 20_setup.ipynb.\nConverted 30_operators.ipynb.\nConverted 40_operators.kernels.ipynb.\nConverted 50_functional.ipynb.\nConverted 60_loss_functions.ipynb.\nConverted 90_core.ipynb.\nConverted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
