{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for setup\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def setup_logging(path, log_filename):\n",
    "    logFormatter = logging.Formatter(\"%(asctime)s %(message)s\")\n",
    "    rootLogger = logging.getLogger()\n",
    "    fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(path, log_filename))\n",
    "    fileHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(fileHandler)\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler)\n",
    "    rootLogger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "import os\n",
    "from smpr3d.util import *\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "from numba import cuda\n",
    "import GPUtil\n",
    "import psutil\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "def configure_node(dist_backend, init_method):\n",
    "    args = Param()\n",
    "    args.dist_backend = dist_backend\n",
    "\n",
    "    is_using_slurm = os.environ.get('SLURM_NTASKS') is not None\n",
    "    if is_using_slurm:\n",
    "        SLURM_LOCALID = int(os.environ.get('SLURM_LOCALID'))\n",
    "        SLURM_PROCID = int(os.environ.get('SLURM_PROCID'))\n",
    "        SLURM_NTASKS = int(os.environ.get('SLURM_NTASKS'))\n",
    "        SLURM_NTASKS_PER_NODE = int(os.environ.get('SLURM_NTASKS_PER_NODE'))\n",
    "        # logging.info(f'SLURM_LOCALID: {SLURM_LOCALID}')\n",
    "        # logging.info(f'SLURM_PROCID: {SLURM_PROCID}')\n",
    "        # logging.info(f'SLURM_NTASKS: {SLURM_NTASKS}')\n",
    "        # logging.info(f'SLURM_NTASKS_PER_NODE: {SLURM_NTASKS_PER_NODE}')\n",
    "        args.slurm_tasks_per_node = SLURM_NTASKS_PER_NODE if SLURM_NTASKS_PER_NODE is not None else 0\n",
    "        args.rank = SLURM_PROCID if SLURM_PROCID is not None else 0\n",
    "        args.gpu = SLURM_LOCALID if SLURM_LOCALID is not None else args.rank\n",
    "        args.world_size = SLURM_NTASKS if SLURM_NTASKS is not None else 1\n",
    "        args.is_distributed = True\n",
    "        args.scheduler = 'slurm'\n",
    "    else:\n",
    "        args.rank = 0\n",
    "        args.world_size = 1\n",
    "        args.gpu = 0\n",
    "        args.is_distributed = False\n",
    "        args.scheduler = 'local'\n",
    "\n",
    "    args.device = th.device(f'cuda:{args.gpu}')\n",
    "    if args.world_size > 1:\n",
    "        # let numba know which device we are running the kernels on\n",
    "        logging.info(f'rank {args.rank} avail gpus: {[x.id for x in GPUtil.getGPUs()]}')\n",
    "        logging.info(f'Selecting device: {args.gpu}')\n",
    "        cuda.select_device(args.gpu)\n",
    "        dist.init_process_group(backend=args.dist_backend, rank=args.rank, world_size=args.world_size,\n",
    "                                init_method=init_method)\n",
    "\n",
    "    ram_gpu_free_GB = []\n",
    "    ram_cpu_free_GB = psutil.virtual_memory().available / 2 ** 30\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu = gpus[args.gpu]\n",
    "    ram_gpu_free_GB = gpu.memoryFree / 1000\n",
    "    if args.rank == 0:\n",
    "        logging.info(f'Scheduler: {args.scheduler}')\n",
    "        logging.info(f'System resources:')\n",
    "    logging.info(f'Rank {args.rank}    Free CPU RAM: {ram_cpu_free_GB} GB')\n",
    "    # if args.world_size > 1:\n",
    "    #     dist.barrier()\n",
    "    logging.info(f'Rank {args.rank}    Free GPU RAM: {ram_gpu_free_GB} GB')\n",
    "    # if args.world_size > 1:\n",
    "    #     dist.barrier()\n",
    "    logging.info(f'Rank {args.rank} is using device {args.gpu}/{len(gpus)}: {gpu.name} driver: v{gpu.driver}')\n",
    "    # if args.world_size > 1:\n",
    "    #     dist.barrier()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numpy.fft import fftshift\n",
    "\n",
    "def load_smatrix_data_list2(fn, device, rank, world_size, fftshift_data=False, subset=None, r_max=None):\n",
    "    \"\"\"\n",
    "    Load S-matrix reconstruction data. Required hdf5 keys:\n",
    "\n",
    "    Abbreviations:\n",
    "    D: number of scans/ aperture functions\n",
    "    K: number of scan positions\n",
    "    MY/MX: detector shape\n",
    "    NY/NX: S-matrix shape\n",
    "\n",
    "    lambda:                         electron wavelength in Angstrom                 scalar float\n",
    "    alpha_rad:                      convergence angle in radians                    scalar float\n",
    "    C:                              aberration coefficients                         (12, D) float\n",
    "    k_max:                          real-space Nyquist resolution (half-period)     (2,) float\n",
    "    specimen_thickness_angstrom:    appoximate thickness in Angstrom                scalar float\n",
    "    vacuum_probe:                   an image of the vacuum beam                     (MY, MX) float\n",
    "    data:                           diffraction data, fft_shifted                   (D, K, MY, MX) float or integer\n",
    "    r:                              real-space positions, in pixel coordinates      (D, K, 2) float\n",
    "    probe_fourier:                  initial aperture functions                      (D, MY, MX) complex\n",
    "\n",
    "    Optional hdf5 keys:\n",
    "\n",
    "    relative_shifts:                relative shifts of the positions for different aberrations  (D, 2) float\n",
    "    S_target                        target S-matrix from simulation                             (B, NY, NX) complex\n",
    "    Psi_target                      target aperture functions from simulation                   (D, MY, MX) complex\n",
    "    r_target                        target positions from simulation, in pixel coordinates      (D, K, 2) float\n",
    "\n",
    "    :param fn: file name. Must be a valid hdf5 file\n",
    "    :param device: target device for all data\n",
    "    :param rank: rank of the loading process\n",
    "    :param world_size: world_size of the current program\n",
    "    :return: all needed data\n",
    "    \"\"\"\n",
    "\n",
    "    if rank == 0:\n",
    "        logging.info(f'Now      loading data file {fn}')\n",
    "    with h5.File(fn, 'r') as f:\n",
    "        D = len(subset)\n",
    "        lam = f['lambda'][0]\n",
    "        # step = f['skip'][()]\n",
    "        alpha_rad = f['alpha_rad'][0]\n",
    "\n",
    "        if subset is None:\n",
    "            C = th.from_numpy(f['C'][:, :]).to(device)\n",
    "            subset = np.arange(D)\n",
    "        else:\n",
    "            C = th.from_numpy(f['C'][:, subset]).to(device)\n",
    "\n",
    "        dx = th.from_numpy(f['d_sm'][:])\n",
    "        specimen_thickness_angstrom = f['specimen_thickness_angstrom'][0]\n",
    "        vac = f['vacuum_probe'][:, :]\n",
    "\n",
    "        if fftshift_data:\n",
    "            vac = fftshift(vac)\n",
    "        vacuum_probe = th.from_numpy(vac).to(device)\n",
    "\n",
    "        data = []\n",
    "        for d in subset:\n",
    "            data.append(f[f'data_{d}'][:, :, :])\n",
    "\n",
    "        if fftshift_data:\n",
    "            for d in range(D):\n",
    "                data[d] = fftshift(data[d], (1, 2))\n",
    "\n",
    "        data = np.array(data)\n",
    "\n",
    "        r0 = []\n",
    "        for d in subset:\n",
    "            r0.append(f[f'r_{d}'][:, :])\n",
    "\n",
    "        r0 = np.array(r0)\n",
    "\n",
    "        try:\n",
    "            r_rel = f['relative_shifts'][...]\n",
    "            if rank == 0:\n",
    "                logging.info(f'Relative shifts of datasets:')\n",
    "                for rr in r_rel:\n",
    "                    logging.info(f'     {rr}')\n",
    "            for d in range(D):\n",
    "                r0[d] += r_rel[d, :]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        y_min = 1e6\n",
    "        x_min = 1e6\n",
    "        for d in range(D):\n",
    "            y_min1 = np.min(r0[d][:, 0])\n",
    "            x_min1 = np.min(r0[d][:, 1])\n",
    "            y_min = np.min([y_min, y_min1])\n",
    "            x_min = np.min([x_min, x_min1])\n",
    "\n",
    "        for d in range(D):\n",
    "            r0[d] -= [y_min, x_min]\n",
    "\n",
    "        K = data.shape[1]\n",
    "        MY = data.shape[2]\n",
    "        MX = data.shape[3]\n",
    "        detector_shape = np.array([MY, MX])\n",
    "\n",
    "        divpts = array_split_divpoints(data, world_size, 1)\n",
    "        d = data[:, divpts[rank]:divpts[rank + 1], :, :]\n",
    "        I_target = th.from_numpy(d).to(device)\n",
    "        r = th.from_numpy(r0[:, divpts[rank]:divpts[rank + 1], :]).to(device)\n",
    "\n",
    "        y_max = -1e6\n",
    "        x_max = -1e6\n",
    "        for d in range(D):\n",
    "            y_max1 = np.max(r0[d][:, 0])\n",
    "            x_max1 = np.max(r0[d][:, 1])\n",
    "            y_max = np.max([y_max, y_max1])\n",
    "            x_max = np.max([x_max, x_max1])\n",
    "        y_min = 1e6\n",
    "        x_min = 1e6\n",
    "        for d in range(D):\n",
    "            y_min1 = np.min(r0[d][:, 0])\n",
    "            x_min1 = np.min(r0[d][:, 1])\n",
    "            y_min = np.min([y_min, y_min1])\n",
    "            x_min = np.min([x_min, x_min1])\n",
    "\n",
    "        if rank == 0:\n",
    "            logging.info(f'Position array boundaries: [{y_min}:{y_max},{x_min}:{x_max}]')\n",
    "            if y_min < 0 or x_min < 0:\n",
    "                logging.warning(f'y_min = {y_min}, x_min = {x_min}, NEGATIVE INDICES ARE NOT ALLOWED!')\n",
    "        if rank == 0:\n",
    "            logging.info(f'memory allocated: {th.cuda.memory_allocated()/1024**2} MB')\n",
    "\n",
    "        K_rank = I_target.shape[1]\n",
    "\n",
    "        S_sol = None\n",
    "        Psi_sol = None\n",
    "        r_sol = None\n",
    "        try:\n",
    "            S_sol = th.as_tensor(f['S_target'][:, :, :], dtype=th.complex64).to(device)\n",
    "        except:\n",
    "            S_sol = None\n",
    "\n",
    "        try:\n",
    "            Psi_sol = []\n",
    "            for d in range(D):\n",
    "                Psi_sol.append(th.as_tensor(f[f'Psi_target_{d}'][:, :], dtype=th.complex64).to(device))\n",
    "        except:\n",
    "            Psi_sol = None\n",
    "\n",
    "        Psi_sol = th.stack(Psi_sol,0)\n",
    "\n",
    "        try:\n",
    "            r_sol = []\n",
    "            for d in range(D):\n",
    "                r_sol.append(th.from_numpy(f[f'r_target_{d}'][:, :]).to(device))\n",
    "        except:\n",
    "            r_sol = None\n",
    "\n",
    "        r_sol = th.stack(r_sol,0)\n",
    "        # Psi = []\n",
    "        # for d in range(D):\n",
    "        #     Psi.append(f[f'Psi0_{d}'][:, :])\n",
    "        #\n",
    "        # if fftshift_data:\n",
    "        #     for d in range(D):\n",
    "        #         Psi[d] = fftshift(Psi[d], (1, 2))\n",
    "        #         cb = fftshift_checkerboard(MY // 2, MX // 2)\n",
    "        #         Psi[d] *= cb\n",
    "        #\n",
    "        # Psi0 = []\n",
    "        # for d in subset:\n",
    "        #     Psi0.append(cx_from_numpy(Psi[d]).to(device).squeeze())\n",
    "\n",
    "        # S-matrix lateral dimensions.\n",
    "        # Ensure that the scattering matrix real space sampling is identical to\n",
    "        # that implied by the maximum reciprocal lattice vector of the\n",
    "        # diffraction pattern.\n",
    "        MY_max = np.max(np.array(MY))\n",
    "        MX_max = np.max(np.array(MX))\n",
    "\n",
    "        NY = int((np.ceil((y_max + MY_max) / MY_max) * MY_max).item())\n",
    "        NX = int((np.ceil((x_max + MX_max) / MX_max) * MX_max).item())\n",
    "        fy = NY // MY_max\n",
    "        fx = NX // MX_max\n",
    "        if rank == 0:\n",
    "            logging.info(f'Finished loading data file {fn}')\n",
    "\n",
    "        # Enforce same data for all arrays\n",
    "        da = th.float32\n",
    "        vacuum_probe = vacuum_probe.type(da)\n",
    "\n",
    "        r = r.type(da)\n",
    "        C = C.type(da)\n",
    "\n",
    "        # for d in subset:\n",
    "        #     Psi0[d] = Psi0[d].type(da)\n",
    "\n",
    "        if r_sol is not None:\n",
    "            r_sol = r_sol.type(da)\n",
    "        return lam, alpha_rad, C, dx, specimen_thickness_angstrom, vacuum_probe, D, K, K_rank, MY, MX, NY, NX, \\\n",
    "               fy, fx, detector_shape, r, I_target, y_max, x_max, y_min, x_min, S_sol, Psi_sol, r_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def initial_probe_amplitude(vacuum_probe, I_target, world_size, rank):\n",
    "    D, K, MY, MX = I_target.shape\n",
    "    # D x My x Mx\n",
    "    I_mean = th.sum(I_target, 1)\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(I_mean, op=dist.ReduceOp.SUM)\n",
    "    I_mean /= K\n",
    "\n",
    "    if rank == 0:\n",
    "        logging.info(f'I_mean             :{th.sum(I_mean, (1, 2)).cpu().numpy()}')\n",
    "\n",
    "    # dim: D x K_rank\n",
    "    # total intensity per diffraction pattern\n",
    "    I_tot = th.sum(I_target, (2, 3))\n",
    "\n",
    "    # max intensity over all diffraction patterns\n",
    "    I_max, I_max_inds = th.max(I_tot, 1)\n",
    "    if world_size > 1:\n",
    "        dist.all_reduce(I_max, op=dist.ReduceOp.MAX)\n",
    "\n",
    "    # max intensity over all diffraction patterns, for each defocus\n",
    "    # dim: D\n",
    "    if rank == 0:\n",
    "        logging.info(f'I_max              :{I_max.cpu().numpy()}')\n",
    "\n",
    "    # dim: D\n",
    "    I_init = vacuum_probe.unsqueeze(0).repeat((D, 1, 1))\n",
    "    I_norm = I_init.norm(1, dim=(1, 2))\n",
    "    fac = I_max / I_norm\n",
    "    I_init *= fac[:, None, None]\n",
    "    if rank == 0:\n",
    "        logging.info(f'I_init norm        :{I_init.norm(1, dim=(1, 2)).cpu().numpy()}')\n",
    "    A_init = th.sqrt(I_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def prepare_beam_parameters(take_beams, q2, specimen_thickness_angstrom, alpha_rad, lam, max_phase_error,\n",
    "                            use_full_smatrix, device):\n",
    "    # number of beams\n",
    "    B = th.sum(take_beams).item()\n",
    "    beam_numbers = th.ones_like(take_beams, dtype=th.long, device=device) * -1\n",
    "    beam_numbers[take_beams] = th.arange(0, B, device=device)\n",
    "\n",
    "    if use_full_smatrix:\n",
    "        # override tiling of the aperture\n",
    "        reduction_factor = 1.0\n",
    "        B_tile = B\n",
    "        tile_order = beam_numbers\n",
    "    else:\n",
    "        raise NotImplementedError('coming soon')\n",
    "\n",
    "    if reduction_factor == 1:\n",
    "        tile_map = beam_numbers[take_beams]\n",
    "        tile_number = beam_numbers\n",
    "    else:\n",
    "        tile_map = -1\n",
    "        tile_number = -1\n",
    "\n",
    "    return B, B_tile, tile_order, tile_number, tile_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from numpy.fft import fftfreq\n",
    "\n",
    "def initial_smatrix(shape, q_space_tiling, device, is_unitary, include_plane_waves, initial_depth=0, lam=0, q2=0,\n",
    "                    dtype=th.complex64, is_pinned=False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param shape:               (4-tuple) shape of the S-matrix\n",
    "    :param q_space_tiling:      (2D)\n",
    "    :param device:              torch.device\n",
    "    :param is_unitary:          bool, if the S-matrix should be unitary\n",
    "    :param include_plane_waves: bool, if the S-matrix should be in the plane-wave basis\n",
    "    :param initial_depth:       float, z-depth of the initial S-matrix in Angstrom, gives quadratic phase offset to beams\n",
    "    :param lam:                 float, wavelength in Angstrom\n",
    "    :param q2:                  2D, wavevector squared\n",
    "    :param dtype:               th.dtype\n",
    "    :param is_pinned:           bool, create pinned memory for CPU\n",
    "    :return: initialized S-matrix\n",
    "    \"\"\"\n",
    "    B, NY, NX = shape\n",
    "    MY, MX = q_space_tiling.shape\n",
    "    fy, fx = NY // MY, NX // MX\n",
    "    S = th.zeros(shape, dtype=dtype, device=device)\n",
    "    if is_pinned:\n",
    "        S = S.pin_memory()\n",
    "    if initial_depth > 0:\n",
    "        take_beams = q_space_tiling >= 0\n",
    "        tile_map = q_space_tiling[take_beams]\n",
    "        depth_init = th.exp(1j* -np.pi * q2 * lam * initial_depth).to(device)\n",
    "        for b in range(B):\n",
    "            S[b] = th.mean(depth_init[take_beams][tile_map == b], axis=0)\n",
    "    else:\n",
    "        depth_init = th.zeros(q2.shape)\n",
    "    if include_plane_waves:\n",
    "        qx, qy = np.meshgrid(fftfreq(MX), fftfreq(MY))\n",
    "        q = np.array([qy, qx])\n",
    "        q_dft = th.from_numpy(q).to(device).type(S.dtype)\n",
    "        coords = th.from_numpy(fftshift(np.array(np.mgrid[-MY // 2:MY // 2, -MX // 2:MX // 2]), (1, 2))).to(device)\n",
    "        for b in range(B):\n",
    "            cur_beam = q_space_tiling == b\n",
    "            cur_beam = cur_beam[None, ...].expand_as(coords)\n",
    "            c = coords[cur_beam]\n",
    "            cur_planewave = th.exp(2j * np.pi * (q_dft[0] * c[0] + q_dft[1] * c[1]))\n",
    "            S[b] = S[b] * cur_planewave.repeat((fy, fx))\n",
    "    # S += th.randn_like(S) * 1e-10\n",
    "    if is_unitary:\n",
    "        sy = NY // 2\n",
    "        sx = NX // 2\n",
    "        CS = S[:, sy:sy + MY, sx:sx + MX]\n",
    "        css = th.norm(CS,p=2, dim=(1, 2))\n",
    "        S /= css[:, None, None]\n",
    "    return S, depth_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from smpr3d.util import memory_mb\n",
    "def report_smatrix_parameters(rank, world_size, a, S, B, D, K, MY, MX, NY, NX, fy, fx, B_tile, K_rank,\n",
    "                              specimen_thickness_angstrom, depth_init, y_max, x_max, y_min, x_min):\n",
    "    if rank == 0:\n",
    "        nonzero_measurements = float(th.sum(a.cpu() > 0))\n",
    "        y_size = (y_max - y_min)\n",
    "        x_size = (x_max - x_min)\n",
    "        unknowns = y_size * x_size * B_tile\n",
    "        logging.info(f\"B (number of beams)      = {B}\")\n",
    "        logging.info(f'B_tile (number of tiles) = {B_tile}')\n",
    "        logging.info(f\"K (number of positions)  = {K}\")\n",
    "        logging.info(f\"D (number of aberrations)= {D}\")\n",
    "        logging.info(f\"M (detector size)        = {MY, MX}\")\n",
    "        logging.info(f\"N (S-matrix size)        = {NY, NX}\")\n",
    "        logging.info(f\"f (PRISM factor)         = {fy, fx}\")\n",
    "        logging.info(f\"\")\n",
    "        logging.info(f'tile reduction_factor    = {B_tile / B}')\n",
    "        logging.info(f'#unknowns                = {unknowns:3.3g}')\n",
    "        logging.info(f'#nonzero_measurements    = {nonzero_measurements:3.3g}')\n",
    "        logging.info(f'variable oversampling    = {nonzero_measurements / unknowns:-2.2f}')\n",
    "        logging.info(f\"\")\n",
    "        logging.info(f\"initial thickness est.   = {specimen_thickness_angstrom / 10} nm\")\n",
    "\n",
    "        size_smatrix_gb = memory_mb((B_tile, NY, NX, 2), th.float32)\n",
    "        size_exitwaves_gb = memory_mb((K_rank, D, MY, MX, 2), th.float32)\n",
    "        logging.info(f\"\")\n",
    "        logging.info(f\"Memory needed for S-matrix    : {size_smatrix_gb:-2.1f} MB\")\n",
    "        logging.info(f\"Memory needed for measurements: {size_exitwaves_gb / 2:-2.1f} MB\")\n",
    "        logging.info(f\"Memory needed for exitwaves   : {size_exitwaves_gb:-2.1f} MB\")\n",
    "        logging.info(f\"\")\n",
    "        if world_size > 1:\n",
    "            dist.barrier()\n",
    "        logging.info(f\"rank {rank:-3d}  K_rank  = {K_rank:-4d}\")\n",
    "    else:\n",
    "        if world_size > 1:\n",
    "            dist.barrier()\n",
    "        logging.info(f\"rank {rank:-3d} K_rank  = {K_rank:-4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def report_initial_probes(rank, world_size, Psi_gen, C, A_init, specimen_thickness_angstrom, q, lam,\n",
    "                          alpha_rad, summary=None):\n",
    "    C_exit = C.clone()\n",
    "    C_exit[0] += specimen_thickness_angstrom\n",
    "\n",
    "    Psi_model = Psi_gen(C, A_init).detach()\n",
    "    psi_model = th.ifft(Psi_model, 2, True)\n",
    "    D, MY, MX, _ = Psi_model.shape\n",
    "    cb = fftshift_checkerboard(MY // 2, MX // 2)\n",
    "\n",
    "    if rank == 0:\n",
    "        logging.info(f\"Psi_model norm: {th.norm(Psi_model[0]) ** 2}\")\n",
    "\n",
    "    Psi_exit = Psi_gen(C_exit, A_init).detach()\n",
    "    psi_exit = th.ifft(Psi_exit, 2, True)\n",
    "\n",
    "    if world_size == 1:\n",
    "        fig_Psi = plot_complex_multi(cb * fftshift(Psi_model.cpu(), (1, 2)),\n",
    "                                     'Fourier space entrance surface probes')\n",
    "        plot_complex_multi(psi_model.cpu(), 'Real Space entrance surface probes')\n",
    "        plot_complex_multi(cb * fftshift(Psi_exit.cpu(), (1, 2)), f'Fourier space exit surface probes')\n",
    "        plot_complex_multi(psi_exit.cpu(), f'Real Space exit surface probes')\n",
    "        \n",
    "        if summary is not None:\n",
    "            summary.add_figure('init/Psi_entrance', fig_Psi, 0, close=True)\n",
    "    else:\n",
    "        if rank == 0:\n",
    "            fig_Psi = plot_complex_multi(cb * fftshift(Psi_model.cpu(), (1, 2)),\n",
    "                                         'Fourier Space entrance surface probes', show=False)\n",
    "            fig_psi = plot_complex_multi(psi_model.cpu(), 'Real Space entrance surface probes', show=False)\n",
    "            fig_Psi_ex = plot_complex_multi(cb * fftshift(Psi_exit.cpu(), (1, 2)),\n",
    "                                            f'Fourier    exit surface probes', show=False)\n",
    "            fig_psi_ex = plot_complex_multi(psi_exit.cpu(), f'Real Space exit surface probes',\n",
    "                                            show=False)\n",
    "            if summary is not None:\n",
    "                summary.add_figure('init/Psi_entrance', fig_Psi, 0, close=True)\n",
    "                summary.add_figure('init/psi_entrance', fig_psi, 0, close=True)\n",
    "                summary.add_figure('init/Psi_exit', fig_Psi_ex, 0, close=True)\n",
    "                summary.add_figure('init/psi_exit', fig_psi_ex, 0, close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
