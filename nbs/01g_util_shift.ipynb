{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util io\n",
    "\n",
    "> Shift functions for Tomography in Torch & Numpy\n",
    ">Gradient based shift is implemented as a nn.Module class in Torch.\n",
    ">Correlation based shift is using part of the code in skimage, implemented in numpy, and can be found at:\n",
    ">https://github.com/scikit-image/scikit-image\n",
    ">David Ren      david.ren@berkeley.edu\n",
    ">April 23, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import smpr3d.util as util\n",
    "import smpr3d.operators as op\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "\n",
    "possible_methods = [\n",
    "                    \"gradient\",\\\n",
    "                    \"phase_correlation\",\\\n",
    "                    \"cross_correlation\",\\\n",
    "                    \"hybrid_correlation\"\n",
    "                   ]\n",
    "\n",
    "correlation_methods = [\n",
    "                    \"phase_correlation\",\\\n",
    "                    \"cross_correlation\",\\\n",
    "                    \"hybrid_correlation\"\n",
    "                   ]           \n",
    "\n",
    "def is_correlation_method(method):\n",
    "    return method in correlation_methods\n",
    "\n",
    "def is_valid_method(method):\n",
    "    return method in possible_methods\n",
    "\n",
    "class ImageShiftCorrelationBased():\n",
    "    \"\"\"\n",
    "    Class written to register stack of images for AET.\n",
    "    Uses correlation based method to determine subpixel shift between predicted and measured images.\n",
    "    Input parameters:\n",
    "        - shape: shape of the image\n",
    "        - pixel_size: pixel size of the image\n",
    "        - upsample_factor: precision of shift algorithm, to 1/upsample_factor accuracy.\n",
    "    \"\"\"    \n",
    "    def __init__(self, shape, upsample_factor=10, method=\"cross_correlation\", dtype=torch.float32, device=torch.device('cuda')):\n",
    "        pixel_size = 1.0\n",
    "        self.ky_lin, self.kx_lin = util.generate_grid_2d(shape, pixel_size, flag_fourier=True, dtype=dtype, device=device)\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.method = method\n",
    "    def _upsampled_dft(self, data, upsampled_region_size,\n",
    "                       upsample_factor=1, axis_offsets=None):\n",
    "        \"\"\"\n",
    "        Upsampled DFT by matrix multiplication.\n",
    "\n",
    "        This code is intended to provide the same result as if the following\n",
    "        operations were performed:\n",
    "            - Embed the array \"data\" in an array that is ``upsample_factor`` times\n",
    "              larger in each dimension.  ifftshift to bring the center of the\n",
    "              image to (1,1).\n",
    "            - Take the FFT of the larger array.\n",
    "            - Extract an ``[upsampled_region_size]`` region of the result, starting\n",
    "              with the ``[axis_offsets+1]`` element.\n",
    "\n",
    "        It achieves this result by computing the DFT in the output array without\n",
    "        the need to zeropad. Much faster and memory efficient than the zero-padded\n",
    "        FFT approach if ``upsampled_region_size`` is much smaller than\n",
    "        ``data.size * upsample_factor``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : array\n",
    "            The input data array (DFT of original data) to upsample.\n",
    "        upsampled_region_size : integer or tuple of integers, optional\n",
    "            The size of the region to be sampled.  If one integer is provided, it\n",
    "            is duplicated up to the dimensionality of ``data``.\n",
    "        upsample_factor : integer, optional\n",
    "            The upsampling factor.  Defaults to 1.\n",
    "        axis_offsets : tuple of integers, optional\n",
    "            The offsets of the region to be sampled.  Defaults to None (uses\n",
    "            image center)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output : ndarray\n",
    "                The upsampled DFT of the specified region.\n",
    "        \"\"\"\n",
    "        # if people pass in an integer, expand it to a list of equal-sized sections\n",
    "        if not hasattr(upsampled_region_size, \"__iter__\"):\n",
    "            upsampled_region_size = [upsampled_region_size, ] * data.ndim\n",
    "        else:\n",
    "            if len(upsampled_region_size) != data.ndim:\n",
    "                raise ValueError(\"shape of upsampled region sizes must be equal \"\n",
    "                                 \"to input data's number of dimensions.\")\n",
    "\n",
    "        if axis_offsets is None:\n",
    "            axis_offsets = [0, ] * data.ndim\n",
    "        else:\n",
    "            if len(axis_offsets) != data.ndim:\n",
    "                raise ValueError(\"number of axis offsets must be equal to input \"\n",
    "                                 \"data's number of dimensions.\")\n",
    "\n",
    "        im2pi = 1j * 2 * np.pi\n",
    "\n",
    "        dim_properties = list(zip(data.shape, upsampled_region_size, axis_offsets))\n",
    "\n",
    "        for (n_items, ups_size, ax_offset) in dim_properties[::-1]:\n",
    "            kernel = ((np.arange(ups_size) - ax_offset)[:, None]\n",
    "                      * fft.fftfreq(n_items, upsample_factor))\n",
    "            kernel = np.exp(-im2pi * kernel)\n",
    "\n",
    "            # Equivalent to:\n",
    "            #   data[i, j, k] = kernel[i, :] @ data[j, k].T\n",
    "            data = np.tensordot(kernel, data, axes=(1, -1))\n",
    "        return data\n",
    "\n",
    "    def _compute_error(self, cross_correlation_max, src_amp, target_amp):\n",
    "        \"\"\"\n",
    "        Compute RMS error metric between ``src_image`` and ``target_image``.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cross_correlation_max : complex\n",
    "            The complex value of the cross correlation at its maximum point.\n",
    "        src_amp : float\n",
    "            The normalized average image intensity of the source image\n",
    "        target_amp : float\n",
    "            The normalized average image intensity of the target image\n",
    "        \"\"\"\n",
    "        error = 1.0 - cross_correlation_max * cross_correlation_max.conj() /\\\n",
    "            (src_amp * target_amp)\n",
    "        return np.sqrt(np.abs(error))\n",
    "\n",
    "\n",
    "    def _cross_correlation(self, reference_image, moving_image, upsample_factor=1,\n",
    "                          method = \"cross_correlation\", space=\"real\", return_error=True):\n",
    "        \"\"\"Efficient subpixel image translation registration by cross-correlation.\n",
    "\n",
    "        This code gives the same precision as the FFT upsampled cross-correlation\n",
    "        in a fraction of the computation time and with reduced memory requirements.\n",
    "        It obtains an initial estimate of the cross-correlation peak by an FFT and\n",
    "        then refines the shift estimation by upsampling the DFT only in a small\n",
    "        neighborhood of that estimate by means of a matrix-multiply DFT.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reference_image : array\n",
    "            Reference image.\n",
    "        moving_image : array\n",
    "            Image to register. Must be same dimensionality as\n",
    "            ``reference_image``.\n",
    "        upsample_factor : int, optional\n",
    "            Upsampling factor. Images will be registered to within\n",
    "            ``1 / upsample_factor`` of a pixel. For example\n",
    "            ``upsample_factor == 20`` means the images will be registered\n",
    "            within 1/20th of a pixel. Default is 1 (no upsampling)\n",
    "        method: string, one of \"cross_correlation\", \"phase_correlation\", or \"hybrid_correlation\"\n",
    "        space : string, one of \"real\" or \"fourier\", optional\n",
    "            Defines how the algorithm interprets input data. \"real\" means data\n",
    "            will be FFT'd to compute the correlation, while \"fourier\" data will\n",
    "            bypass FFT of input data. Case insensitive.\n",
    "        return_error : bool, optional\n",
    "            Returns error and phase difference if on, otherwise only\n",
    "            shifts are returned\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        shifts : ndarray\n",
    "            Shift vector (in pixels) required to register ``moving_image``\n",
    "            with ``reference_image``. Axis ordering is consistent with\n",
    "            numpy (e.g. Z, Y, X)\n",
    "        error : float\n",
    "            Translation invariant normalized RMS error between\n",
    "            ``reference_image`` and ``moving_image``.\n",
    "        phasediff : float\n",
    "            Global phase difference between the two images (should be\n",
    "            zero if images are non-negative).\n",
    "\n",
    "        References\n",
    "        ----------\n",
    "        .. [1] Manuel Guizar-Sicairos, Samuel T. Thurman, and James R. Fienup,\n",
    "               \"Efficient subpixel image registration algorithms,\"\n",
    "               Optics Letters 33, 156-158 (2008). :DOI:`10.1364/OL.33.000156`\n",
    "        .. [2] James R. Fienup, \"Invariant error metrics for image reconstruction\"\n",
    "               Optics Letters 36, 8352-8357 (1997). :DOI:`10.1364/AO.36.008352`\n",
    "\n",
    "        \"\"\"\n",
    "        # images must be the same shape\n",
    "        if reference_image.shape != moving_image.shape:\n",
    "            raise ValueError(\"images must be same shape\")\n",
    "\n",
    "        # assume complex data is already in Fourier space\n",
    "        if space.lower() == 'fourier':\n",
    "            src_freq = reference_image\n",
    "            target_freq = moving_image\n",
    "        # real data needs to be fft'd.\n",
    "        elif space.lower() == 'real':\n",
    "            src_freq = fft.fftn(reference_image)\n",
    "            target_freq = fft.fftn(moving_image)\n",
    "        else:\n",
    "            raise ValueError('space argument must be \"real\" or \"fourier\"')\n",
    "        # Whole-pixel shift - Compute cross-correlation by an IFFT\n",
    "        shape = src_freq.shape\n",
    "        image_product = src_freq * target_freq.conj()\n",
    "        if method == \"phase_correlation\":\n",
    "            image_product = np.exp(1.0j*np.angle(image_product))\n",
    "        elif method == \"hybrid_correlation\":\n",
    "            image_product = np.sqrt(np.abs(image_product))*np.exp(1.0j*np.angle(image_product))\n",
    "        elif method == \"cross_correlation\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('method argument not valid.')\n",
    "        cross_correlation = fft.ifftn(image_product)\n",
    "\n",
    "        # Locate maximum\n",
    "        maxima = np.unravel_index(np.argmax(np.abs(cross_correlation)),\n",
    "                                  cross_correlation.shape)\n",
    "        midpoints = np.array([np.fix(axis_size / 2) for axis_size in shape])\n",
    "\n",
    "        shifts = np.array(maxima, dtype=np.float64)\n",
    "        shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\n",
    "\n",
    "        if upsample_factor == 1:\n",
    "            if return_error:\n",
    "                src_amp = np.sum(np.abs(src_freq) ** 2) / src_freq.size\n",
    "                target_amp = np.sum(np.abs(target_freq) ** 2) / target_freq.size\n",
    "                CCmax = cross_correlation[maxima]\n",
    "        # If upsampling > 1, then refine estimate with matrix multiply DFT\n",
    "        else:\n",
    "            # Initial shift estimate in upsampled grid\n",
    "            shifts = np.round(shifts * upsample_factor) / upsample_factor\n",
    "            upsampled_region_size = np.ceil(upsample_factor * 1.5)\n",
    "            # Center of output array at dftshift + 1\n",
    "            dftshift = np.fix(upsampled_region_size / 2.0)\n",
    "            upsample_factor = np.array(upsample_factor, dtype=np.float64)\n",
    "            normalization = (src_freq.size * upsample_factor ** 2)\n",
    "            # Matrix multiply DFT around the current shift estimate\n",
    "            sample_region_offset = dftshift - shifts*upsample_factor\n",
    "            cross_correlation = self._upsampled_dft(image_product.conj(),\n",
    "                                               upsampled_region_size,\n",
    "                                               upsample_factor,\n",
    "                                               sample_region_offset).conj()\n",
    "            cross_correlation /= normalization\n",
    "            # Locate maximum and map back to original pixel grid\n",
    "            maxima = np.unravel_index(np.argmax(np.abs(cross_correlation)),\n",
    "                                      cross_correlation.shape)\n",
    "            CCmax = cross_correlation[maxima]\n",
    "\n",
    "            maxima = np.array(maxima, dtype=np.float64) - dftshift\n",
    "\n",
    "            shifts = shifts + maxima / upsample_factor\n",
    "\n",
    "            if return_error:\n",
    "                src_amp = self._upsampled_dft(src_freq * src_freq.conj(),\n",
    "                                         1, upsample_factor)[0, 0]\n",
    "                src_amp /= normalization\n",
    "                target_amp = self._upsampled_dft(target_freq * target_freq.conj(),\n",
    "                                            1, upsample_factor)[0, 0]\n",
    "                target_amp /= normalization\n",
    "\n",
    "        # If its only one row or column the shift along that dimension has no\n",
    "        # effect. We set to zero.\n",
    "        for dim in range(src_freq.ndim):\n",
    "            if shape[dim] == 1:\n",
    "                shifts[dim] = 0\n",
    "\n",
    "        if return_error:\n",
    "            return shifts, self._compute_error(CCmax, src_amp, target_amp)\n",
    "        else:\n",
    "            return shifts        \n",
    "\n",
    "    def _shift_stack_inplace(self, stack, shift_list):\n",
    "        for img_idx in range(stack.shape[2]):\n",
    "            y_shift = shift_list[0,img_idx]\n",
    "            x_shift = shift_list[1,img_idx]\n",
    "            kernel  = torch.exp(2j * np.pi * (self.kx_lin * x_shift + self.ky_lin * y_shift))\n",
    "            stack[...,img_idx] = torch.real(op.convolve_kernel(stack[...,img_idx], kernel, n_dim=2))\n",
    "        return stack\n",
    "\n",
    "    def estimate(self, predicted, measured):\n",
    "        \"\"\"\n",
    "        A function to estimate shift error and return the shift correct image stack\n",
    "        Input parameters:\n",
    "            - predicted: predicted amplitudes, should be torch array\n",
    "            - measured: measured amplitudes, should be torch array\n",
    "        \"\"\"\n",
    "        assert predicted.shape == measured.shape\n",
    "        shift_list = np.zeros((2,measured.shape[2]), dtype=\"float32\")\n",
    "        err_list = []\n",
    "\n",
    "        #Change from torch array to numpy array\n",
    "        flag_predicted_gpu = predicted.is_cuda\n",
    "        if flag_predicted_gpu:\n",
    "            predicted = predicted.cpu()\n",
    "\n",
    "        flag_measured_gpu = measured.is_cuda\n",
    "        if flag_measured_gpu:\n",
    "            measured = measured.cpu()        \n",
    "        \n",
    "        predicted_np = np.array(predicted.detach())\n",
    "        measured_np  = np.array(measured.detach())\n",
    "        \n",
    "        #For each image, estimate the shift error\n",
    "        for img_idx in range(measured_np.shape[2]):\n",
    "            shift, err = self._cross_correlation(predicted_np[...,img_idx], \\\n",
    "                                                 measured_np[...,img_idx], \\\n",
    "                                                 method = self.method, \\\n",
    "                                                 upsample_factor=self.upsample_factor)\n",
    "            shift_list[:,img_idx] = shift.astype(\"float32\")\n",
    "            err_list.append(err)\n",
    "        \n",
    "        #Change data back to torch tensor format\n",
    "        if flag_predicted_gpu:\n",
    "            predicted = predicted.cuda()\n",
    "\n",
    "        measured_np = torch.tensor(measured_np)\n",
    "        if flag_measured_gpu:\n",
    "            measured    = measured.cuda()        \n",
    "            measured_np = measured_np.cuda()\n",
    "\n",
    "        #Shift measured image\n",
    "        measured_np = self._shift_stack_inplace(measured_np, -1. * shift_list)\n",
    "        if (abs(shift_list) > 40.0).any():\n",
    "        \tprint(\"Shift too large!\", np.max(np.abs(shift_list)))\n",
    "        \tshift_list[:] = 0.0\n",
    "        return measured_np, torch.tensor(shift_list), torch.tensor(err_list)\n",
    "\n",
    "class ImageShiftGradientBased(nn.Module):\n",
    "    \"\"\"\n",
    "    A class that solves for shift between measurement and prediction. This uses pytorch autograd, and is gradient based.\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, dtype=torch.float32, device=torch.device('cuda'), **kwargs):\n",
    "        super(ImageShiftGradientBased, self).__init__()\n",
    "        pixel_size = 1.0\n",
    "        self.ky_lin, self.kx_lin = util.generate_grid_2d(shape, pixel_size, flag_fourier=True, dtype=dtype, device=device)\n",
    "\n",
    "    def forward(self, field, shift=None):   \n",
    "        \"\"\"\n",
    "        Input parameters:\n",
    "            - field: refocused field, before cropping\n",
    "            - shift: estimated shift [y_shift, x_shift], default None (shift estimation off)\n",
    "        \"\"\"\n",
    "        if shift is None:\n",
    "            return field\n",
    "        field_out = field.clone()\n",
    "        for img_idx in range(field.shape[2]):\n",
    "            y_shift = shift[0,img_idx]\n",
    "            x_shift = shift[1,img_idx]\n",
    "            kernel  = torch.exp(2j * np.pi * (self.kx_lin * x_shift + self.ky_lin * y_shift))\n",
    "            field_out[...,img_idx] = op.convolve_kernel(field[...,img_idx], kernel, 2, True)\n",
    "        return field_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
