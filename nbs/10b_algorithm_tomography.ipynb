{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase contrast tomography solver\n",
    "\n",
    "> Initial implementation by David Ren, Waller Group, UC Berkeley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import sys\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(precision=10)\n",
    "from tqdm import trange, tqdm\n",
    "#data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import smpr3d.operators as op\n",
    "import smpr3d.util as utilities\n",
    "from smpr3d.operators import Pupil\n",
    "from smpr3d.modules import SingleSlicePropagation, Defocus, MultislicePropagation\n",
    "from smpr3d.regularizers import Regularizer\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "bin_obj       = op.BinObject.apply\n",
    "complex_abs   = op.ComplexAbs.apply\n",
    "\n",
    "possible_methods = [\n",
    "                    \"gradient\",\\\n",
    "                    \"phase_correlation\",\\\n",
    "                    \"cross_correlation\",\\\n",
    "                    \"hybrid_correlation\"\n",
    "                   ]\n",
    "correlation_methods = [\n",
    "                    \"phase_correlation\",\\\n",
    "                    \"cross_correlation\",\\\n",
    "                    \"hybrid_correlation\"\n",
    "                   ]                    \n",
    "def is_correlation_method(method):\n",
    "    return method in correlation_methods\n",
    "\n",
    "def is_valid_method(method):\n",
    "    return method in possible_methods\n",
    "\n",
    "class TorchTomographySolver:\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Creating tomography solver object.\n",
    "        Required Args:\n",
    "            shape: shape of the object in [y, x, z]\n",
    "            voxel_size: size of voxel in [y, x, z]\n",
    "            wavelength: wavelength of probing wave, scalar\n",
    "            sigma: sigma used in calculating transmittance function (exp(1i * sigma * object)), scalar\n",
    "            tilt_angles: an array of sample rotation angles\n",
    "            defocus_list: an array of defocus values\n",
    "\n",
    "        Optional Args [default]\n",
    "            amplitude_measurements: (NY, NX, N_defocus, N_sample_tilt) measurements [None]\n",
    "            numerical_aperture: numerical aperture of the system, scalar [1.0]\n",
    "            binning_factor: bins the number of slices together to save computation, scalar [1]\n",
    "            pad_size: padding reconstruction from measurements in [dy,dx], final size will be measurement.shape + 2*[dy, dx], [0, 0]\n",
    "            shuffle: random shuffle of measurements, boolean [True]\n",
    "            pupil: inital value for the pupil function [None]\n",
    "            maxitr: maximum number of iterations [100]\n",
    "            step_size: step_size for each gradient update [0.1]\n",
    "            momentum: [0.0 NOTIMPLEMENTED]\n",
    "\n",
    "            -- transform alignment parameters (currently only support rigid body transform alignment) --\n",
    "            transform_align: whether to turn on transform alignment, boolean, [False]\n",
    "            ta_method: \"turboreg\"\n",
    "            ta_start_iteration: alignment process will not start until then, int, [0]\n",
    "            ta_iterations: iterations during which the alignment process will be on, [0, max_itr]\n",
    "\n",
    "            -- Shift alignment parameters --\n",
    "            shift_align: whether to turn on alignment, boolean, [False]\n",
    "            sa_method: shift alignment method, can be \"gradient\", \"hybrid_correlation\", \"cross_correlation\", or \"phase_correlation\", string, [\"gradient\"]\n",
    "            sa_step_size: step_size of shift parameters, float, [0.1]\n",
    "            sa_start_iteration: alignment process will not start until then, int, [0]\n",
    "            sa_iterations: iterations during which the alignment process will be on, [0, max_itr]\n",
    "\n",
    "            -- Defocus refinement parameters --\n",
    "            defocus_refine: whether to turn on defocus refinement for each measurement, boolean, [False]\n",
    "            dr_method: defocus refinement method, can be \"gradient\", string, [\"gradient\"]\n",
    "            dr_step_size: step_size of defocus refinement parameters, float, [0.1]\n",
    "            dr_start_iteration: refinement process will not start until then, int, [0]\n",
    "            dr_iterations: iterations during which the defocus refocus process will be on, [0, max_itr]\n",
    "\n",
    "            -- regularizer parameters --\n",
    "            regularizer_total_variation: boolean [False]\n",
    "            regularizer_total_variation_gpu: boolean [False]\n",
    "            regularizer_total_variation_parameter: controls amount of total variation, scalar or vector of length maxitr. [scalar 1.0]\n",
    "            regularizer_total_variation_maxitr: number of iterations for total variation, integer [15]\n",
    "            regularizer_total_variation_order: differential order, scalar [1], higher order not yet implemented\n",
    "            regularizer_pure_real: boolean [False]\n",
    "            regularizer_pure_imag: boolean [False]\n",
    "            regularizer_pure_amplitude: boolean [False]\n",
    "            regularizer_pure_phase: boolean [False]\n",
    "            regularizer_positivity_real: boolean [False]\n",
    "            regularizer_positivity_imag: boolean [False]\n",
    "            regularizer_negativity_real: boolean [False]\n",
    "            regularizer_negativity_imag: boolean [False]\n",
    "            regularizer_dtype: torch dtype class [torch.float32]\n",
    "        \"\"\"\n",
    "\n",
    "        self.shape = kwargs.get(\"shape\")\n",
    "        self.beam_batch_size = kwargs.get(\"beam_batch_size\", 1)\n",
    "        self.shuffle = kwargs.get(\"shuffle\", True)\n",
    "        self.optim_max_itr = kwargs.get(\"maxitr\", 100)\n",
    "        self.optim_step_size = kwargs.get(\"step_size\", 0.1)\n",
    "        self.optim_momentum = kwargs.get(\"momentum\", 0.0)\n",
    "\n",
    "        # self.s_meta = kwargs.get(\"smeta\")\n",
    "        # self.smeta = kwargs.get(\"smeta\", True)\n",
    "        self.obj_update_iterations = kwargs.get(\n",
    "            \"obj_update_iterations\", np.arange(self.optim_max_itr))\n",
    "\n",
    "        self.flag_gpu = kwargs.get(\"flag_gpu\", True)\n",
    "        self.device = torch.device(\n",
    "            'cuda') if self.flag_gpu else torch.device('cpu')\n",
    "        kwargs[\"device\"] = self.device\n",
    "        # parameters for transform alignment\n",
    "        self.transform_align = kwargs.get(\"transform_align\", False)\n",
    "        self.ta_method = kwargs.get(\"ta_method\", \"turboreg\")\n",
    "        self.ta_start_iteration = kwargs.get(\"ta_start_iteration\", 0)\n",
    "        self.ta_iterations = kwargs.get(\"ta_iterations\", None)\n",
    "        if self.ta_iterations is None:\n",
    "            self.ta_iterations = np.arange(\n",
    "                self.ta_start_iteration, self.optim_max_itr)\n",
    "\n",
    "        # parameters for shift alignment\n",
    "        self.shift_align = kwargs.get(\"shift_align\", False)\n",
    "        self.sa_method = kwargs.get(\"sa_method\", \"gradient\")\n",
    "        self.sa_step_size = kwargs.get(\"sa_step_size\", 0.1)\n",
    "        self.sa_start_iteration = kwargs.get(\"sa_start_iteration\", 0)\n",
    "        self.sa_iterations = kwargs.get(\"sa_iterations\", None)\n",
    "        if self.sa_iterations is None:\n",
    "            self.sa_iterations = np.arange(\n",
    "                self.sa_start_iteration, self.optim_max_itr)\n",
    "\n",
    "        # parameters for defocus refinement\n",
    "        self.defocus_refine = kwargs.get(\"defocus_refine\", False)\n",
    "        self.dr_method = kwargs.get(\"dr_method\", \"gradient\")\n",
    "        self.dr_step_size = kwargs.get(\"dr_step_size\", 0.1)\n",
    "        self.dr_start_iteration = kwargs.get(\"dr_start_iteration\", 0)\n",
    "        self.dr_iterations = kwargs.get(\"dr_iterations\", None)\n",
    "        if self.dr_iterations is None:\n",
    "            self.dr_iterations = np.arange(\n",
    "                self.dr_start_iteration, self.optim_max_itr)\n",
    "\n",
    "        if not is_valid_method(self.sa_method):\n",
    "            raise ValueError('Shift alignment method not valid.')\n",
    "        if self.shift_align and is_correlation_method(self.sa_method):\n",
    "            self.shift_obj = op.ImageShiftCorrelationBased(kwargs[\"amplitude_measurements\"].shape[0:2],\n",
    "                                                                  upsample_factor=10, method=self.sa_method,\n",
    "                                                                  device=torch.device('cpu'))\n",
    "\n",
    "        if self.transform_align:\n",
    "            self.transform_obj = op.ImageTransformOpticalFlow(kwargs[\"amplitude_measurements\"].shape[0:2],\n",
    "                                                                     method=self.ta_method)\n",
    "\n",
    "        self.dataset = AETDataset(**kwargs)\n",
    "        self.num_defocus = self.dataset.get_all_defocus_lists().shape[0]\n",
    "        self.num_rotation = len(self.dataset.tilt_angles)\n",
    "        self.tomography_obj = PhaseContrastScattering(**kwargs)\n",
    "        reg_temp_param = kwargs.get(\n",
    "            \"regularizer_total_variation_parameter\", None)\n",
    "        if reg_temp_param is not None:\n",
    "            if not np.isscalar(reg_temp_param):\n",
    "                assert self.optim_max_itr == len(\n",
    "                    kwargs[\"regularizer_total_variation_parameter\"])\n",
    "        self.regularizer_obj = Regularizer(**kwargs)\n",
    "        self.rotation_obj = op.ImageRotation(self.shape, axis=0, device=torch.device('cuda'))\n",
    "\n",
    "        self.cost_function = nn.MSELoss(reduction='sum')\n",
    "        self.s_meta = kwargs.get(\"s_meta\")\n",
    "\n",
    "    def run(self, obj_init=None, forward_only=False, callback=None):\n",
    "        \"\"\"\n",
    "        run tomography solver\n",
    "        Args:\n",
    "        forward_only: True  -- only runs forward model on estimated object\n",
    "                      False -- runs reconstruction\n",
    "        \"\"\"\n",
    "        if forward_only:\n",
    "            self.shuffle = False\n",
    "            amplitude_list = []\n",
    "        previous_angle = 0\n",
    "        self.dataloader = DataLoader(\n",
    "            self.dataset, batch_size=1, shuffle=self.shuffle)\n",
    "\n",
    "        error = []\n",
    "        # initialize object\n",
    "        self.obj = obj_init\n",
    "        if self.obj is None:\n",
    "            self.obj = op.r2c(torch.zeros(self.shape).to(self.device))\n",
    "        else:\n",
    "            if self.device == torch.device('cuda'):\n",
    "                if not self.obj.is_cuda:\n",
    "                    self.obj = self.obj.to(self.device)\n",
    "            self.obj = op.r2c(self.obj)\n",
    "\n",
    "        # initialize shift parameters\n",
    "        self.yx_shifts = None\n",
    "        if self.shift_align:\n",
    "            self.sa_pixel_count = []\n",
    "            self.yx_shift_all = []\n",
    "            self.yx_shifts = torch.zeros(\n",
    "                (2, self.num_defocus, self.num_rotation))\n",
    "\n",
    "        if self.transform_align:\n",
    "            self.xy_transform_all = []\n",
    "            self.xy_transforms = torch.zeros(\n",
    "                (6, self.num_defocus, self.num_rotation))\n",
    "        #\t\t\tself.xy_transforms = torch.zeros((3, self.num_defocus, self.num_rotation))\n",
    "        # TEMPP\n",
    "        # defocus_list_grad = torch.zeros((self.num_defocus, self.num_rotation), dtype = torch.float32)\n",
    "        ref_rot_idx = None\n",
    "        # begin iteration\n",
    "        for itr_idx in range(self.optim_max_itr):\n",
    "            # sys.stdout.flush()\n",
    "            running_cost = 0.0\n",
    "            # defocus_list_grad[:] = 0.0\n",
    "            if self.shift_align and itr_idx in self.sa_iterations:\n",
    "                running_sa_pixel_count = 0.0\n",
    "            for data_idx, data in enumerate(self.dataloader, 0):\n",
    "                # parse data\n",
    "                if not forward_only:\n",
    "                    amplitudes, rotation_angle, defocus_list, rotation_idx = data\n",
    "                    if ref_rot_idx is None and abs(rotation_angle - 0.0) < 1e-2:\n",
    "                        ref_rot_idx = rotation_idx\n",
    "                        print(\"reference index is:\", ref_rot_idx)\n",
    "                    amplitudes = torch.squeeze(amplitudes)\n",
    "                    if len(amplitudes.shape) < 3:\n",
    "                        amplitudes = amplitudes.unsqueeze(-1)\n",
    "\n",
    "                else:\n",
    "                    rotation_angle, defocus_list, rotation_idx = data[-3:]\n",
    "                # prepare tilt specific parameters\n",
    "                defocus_list = torch.flatten(defocus_list).to(self.device)\n",
    "            \n",
    "            rotation_angle = rotation_angle.item()\n",
    "            yx_shift = None\n",
    "            if self.shift_align and self.sa_method == \"gradient\" and itr_idx in self.sa_iterations:\n",
    "                yx_shift = self.yx_shifts[:, :, rotation_idx]\n",
    "                yx_shift = yx_shift.to(self.device)\n",
    "                yx_shift.requires_grad_()\n",
    "            if self.defocus_refine and self.dr_method == \"gradient\" and itr_idx in self.dr_iterations:\n",
    "                defocus_list.requires_grad_()\n",
    "            # rotate object\n",
    "            if data_idx == 0:\n",
    "                self.obj = self.rotation_obj.forward(self.obj, rotation_angle)\n",
    "            else:\n",
    "                if abs(rotation_angle - previous_angle) > 90:\n",
    "                    self.obj = self.rotation_obj.forward(\n",
    "                        self.obj, -1 * previous_angle)\n",
    "                    self.obj = self.rotation_obj.forward(\n",
    "                        self.obj, rotation_angle)\n",
    "                else:\n",
    "                    self.obj = self.rotation_obj.forward(\n",
    "                        self.obj, rotation_angle - previous_angle)\n",
    "            if not forward_only:\n",
    "                # define optimizer\n",
    "                optimizer_params = []\n",
    "\n",
    "                if itr_idx in self.obj_update_iterations:\n",
    "                    self.obj.requires_grad_()\n",
    "                    optimizer_params.append(\n",
    "                        {'params': self.obj, 'lr': self.optim_step_size})\n",
    "                if self.shift_align and self.sa_method == \"gradient\" and itr_idx in self.sa_iterations:\n",
    "                    optimizer_params.append(\n",
    "                        {'params': yx_shift, 'lr': self.sa_step_size})\n",
    "                if self.defocus_refine and self.dr_method == \"gradient\" and itr_idx in self.dr_iterations:\n",
    "                    optimizer_params.append(\n",
    "                        {'params': defocus_list, 'lr': self.dr_step_size})\n",
    "                optimizer = optim.SGD(optimizer_params)\n",
    "\n",
    "            beam_coordinates = self.s_meta.all_beams_coords.to(self.device)\n",
    "            q_dft = self.s_meta.q_dft.to(self.device)\n",
    "\n",
    "            # field_in is (N_batch, NY, NX)\n",
    "            # forward scattering\n",
    "            sampler = BatchSampler(SequentialSampler(range(beam_coordinates.shape[0])), \n",
    "                                   batch_size=self.beam_batch_size, drop_last=False)\n",
    "            \n",
    "            # for i_beam in trange(beam_coordinates.shape[0], desc='Beams: '):\n",
    "            for i_beam in tqdm(sampler, desc='Beams: '):\n",
    "                w = th.exp(2j * np.pi * th.sum(q_dft[None, :, :, :] * beam_coordinates[i_beam, :, None, None], 1))\n",
    "                field_in = th.tile(w, (1, *self.s_meta.f))\n",
    "                sy = field_in.shape[1] // 2\n",
    "                sx = field_in.shape[2] // 2\n",
    "                CS = field_in[:, sy:sy + self.s_meta.M[0], sx:sx + self.s_meta.M[1]]\n",
    "                field_in /= th.linalg.norm(CS, axis=(1, 2))[:, None, None]\n",
    "                field_in.requires_grad = False\n",
    "                estimated_amplitudes = self.tomography_obj(self.obj, defocus_list[i_beam], field_in, yx_shift)\n",
    "                # in-plane rotation estimation\n",
    "            \n",
    "                if not forward_only:\n",
    "                    if self.transform_align and itr_idx in self.ta_iterations:\n",
    "                        if rotation_idx != ref_rot_idx:\n",
    "                            amplitudes2, xy_transform = self.transform_obj.estimate(estimated_amplitudes, amplitudes[..., i_beam])\n",
    "                            xy_transform = xy_transform.unsqueeze(-1)\n",
    "                    #\t\t\t\t\t\tself.dataset.update_amplitudes(amplitudes, rotation_idx)\n",
    "                    # Correlation based shift estimation\n",
    "                    if self.shift_align and utilities.is_correlation_method(self.sa_method) and itr_idx in self.sa_iterations:\n",
    "                        if rotation_idx != ref_rot_idx:\n",
    "                            amplitudes2, yx_shift, _ = self.shift_obj.estimate(estimated_amplitudes, amplitudes[..., i_beam])\n",
    "                            yx_shift = yx_shift.unsqueeze(-1)\n",
    "                            \n",
    "                    \n",
    "                    #\t\t\t\t\t\tself.dataset.update_amplitudes(amplitudes, rotation_idx)\n",
    "                    # if itr_idx == self.optim_max_itr - 1:\n",
    "                    #     print(\"Last iteration: updated amplitudes\")\n",
    "                    #     self.dataset.update_amplitudes(amplitudes, rotation_idx)\n",
    "    \n",
    "                    # compute cost\n",
    "                    estimated_amplitudes = estimated_amplitudes * field_in.conj()\n",
    "                    \n",
    "                    cost = self.cost_function(th.view_as_real(estimated_amplitudes), \n",
    "                                              th.view_as_real(amplitudes[i_beam].to(self.device)))\n",
    "                    running_cost += cost.item()\n",
    "    \n",
    "                    # backpropagation\n",
    "                    cost.backward()\n",
    "                    # update object\n",
    "                    # if itr_idx >= self.dr_start_iteration:\n",
    "                    # \t# print(torch.norm(defocus_list.grad.data))\n",
    "                    # \tdefocus_list_grad[:,data_idx] = defocus_list.grad.data *  self.dr_step_size\n",
    "                    # optimizer.step()\n",
    "                    # optimizer.zero_grad()\n",
    "                    del cost\n",
    "                else:\n",
    "                    # store measurement\n",
    "                    amplitude_list.append(estimated_amplitudes.cpu().detach())\n",
    "                    \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            del estimated_amplitudes\n",
    "            self.obj.requires_grad = False\n",
    "            if not forward_only:\n",
    "                # keep track of shift alignment for the tilt\n",
    "                if self.shift_align and itr_idx in self.sa_iterations:\n",
    "                    if yx_shift is not None:\n",
    "                        yx_shift.requires_grad = False\n",
    "                        if rotation_idx != ref_rot_idx:\n",
    "                            self.yx_shifts[:, :,\n",
    "                                rotation_idx] = yx_shift[:].cpu()\n",
    "                            running_sa_pixel_count += torch.sum(\n",
    "                                torch.abs(yx_shift.cpu().flatten()))\n",
    "\n",
    "                # keep track of transform alignment for the tilt\n",
    "                if self.transform_align and itr_idx in self.ta_iterations:\n",
    "                    if rotation_idx != ref_rot_idx:\n",
    "                        self.xy_transforms[...,\n",
    "                            rotation_idx] = xy_transform[:].cpu()\n",
    "\n",
    "                # keep track of defocus alignment for the tilt\n",
    "                if self.defocus_refine and itr_idx in self.dr_iterations:\n",
    "                    defocus_list.requires_grad = False\n",
    "                    self.dataset.update_defocus_list(\n",
    "                        defocus_list[:].cpu().detach(), rotation_idx)\n",
    "\n",
    "            previous_angle = rotation_angle\n",
    "\n",
    "            # rotate object back\n",
    "            if data_idx == (self.dataset.__len__() - 1):\n",
    "                previous_angle = 0.0\n",
    "                self.obj = self.rotation_obj.forward(\n",
    "                    self.obj, -1.0 * rotation_angle)\n",
    "            print(\"Rotation {:03d}/{:03d}.\".format(data_idx +\n",
    "                  1, self.dataset.__len__()), end=\"\\r\")\n",
    "\n",
    "            # apply regularization\n",
    "\n",
    "            amplitudes = None\n",
    "            if self.device == torch.device(\"cuda\"):\n",
    "                torch.cuda.empty_cache()\n",
    "            if not forward_only:\n",
    "                if itr_idx in self.obj_update_iterations:\n",
    "                    self.obj = self.regularizer_obj.apply(self.obj)\n",
    "            error.append(running_cost)\n",
    "    \n",
    "            # keep track of shift alignment results\n",
    "            if self.shift_align and itr_idx in self.sa_iterations:\n",
    "                self.sa_pixel_count.append(running_sa_pixel_count)\n",
    "                self.yx_shift_all.append(np.array(self.yx_shifts).copy())\n",
    "    \n",
    "            # keep track of transform alignment results\n",
    "            if self.transform_align and itr_idx in self.ta_iterations:\n",
    "                self.xy_transform_all.append(np.array(self.xy_transforms).copy())\n",
    "    \n",
    "            if callback is not None:\n",
    "                callback(self.obj.cpu().detach(), error)\n",
    "            # TEMPPPPP\n",
    "            # callback(defocus_list_grad, self.dataset.get_all_defocus_lists(), error)\n",
    "            if forward_only and itr_idx == 0:\n",
    "                return torch.cat([torch.unsqueeze(amplitude_list[idx], -1) for idx in range(len(amplitude_list))], axis=-1)\n",
    "            print(\"Iteration {:03d}/{:03d}. Error: {:03f}\".format(itr_idx +\n",
    "                  1, self.optim_max_itr, np.log10(running_cost)))\n",
    "\n",
    "        self.defocus_list = self.dataset.get_all_defocus_lists()\n",
    "        return self.obj.cpu().detach(), error\n",
    "\n",
    "\n",
    "\n",
    "class AETDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 amplitude_measurements=None,\n",
    "                 tilt_angles=[0],\n",
    "                 defocus_list=None,\n",
    "                 beam_coordinates=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.amplitude_measurements = amplitude_measurements\n",
    "        self.beam_coordinates = beam_coordinates\n",
    "        if self.amplitude_measurements is not None:\n",
    "            self.amplitude_measurements = amplitude_measurements \n",
    "        if tilt_angles is not None:\n",
    "            self.tilt_angles = tilt_angles * 1.0\n",
    "        if defocus_list is not None:\n",
    "            if not torch.is_tensor(defocus_list):\n",
    "                defocus_list = torch.tensor(defocus_list)\n",
    "            if len(defocus_list.shape) == 1:\n",
    "                self.defocus_list = defocus_list.unsqueeze(\n",
    "                    1).repeat(1, len(self.tilt_angles)) * 1.0\n",
    "            elif len(defocus_list.shape) == 2:\n",
    "                assert defocus_list.shape[1] == len(tilt_angles)\n",
    "                self.defocus_list = defocus_list * 1.0\n",
    "            else:\n",
    "                raise ValueError('Invalid defocus_list shape.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tilt_angles.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # X x Y x #defocus\n",
    "        if self.amplitude_measurements is not None:\n",
    "            return self.amplitude_measurements[..., idx], self.tilt_angles[idx], self.defocus_list[:,idx], idx\n",
    "        else:\n",
    "            return self.tilt_angles[idx], self.defocus_list[:, idx], idx\n",
    "\n",
    "    def update_defocus_list(self, defocus_list, idx):\n",
    "        self.defocus_list[:, idx] = defocus_list.unsqueeze(-1)\n",
    "        return\n",
    "\n",
    "    def update_amplitudes(self, amplitudes, idx):\n",
    "        self.amplitude_measurements[..., idx] = amplitudes\n",
    "        return\n",
    "\n",
    "    def get_all_defocus_lists(self):\n",
    "        return self.defocus_list\n",
    "\n",
    "    def get_all_measurements(self):\n",
    "        return self.amplitude_measurements\n",
    "    \n",
    "\n",
    "from smpr3d.operators import ImageShiftGradientBased\n",
    "\n",
    "class PhaseContrastScattering(nn.Module):\n",
    "\n",
    "    def __init__(self, shape, voxel_size, wavelength, s_meta, sigma=None, binning_factor=1, pad_size=[0, 0], **kwargs):\n",
    "        \"\"\"\n",
    "        Phase contrast scattering model\n",
    "        Starts from a plane wave, 3D object, and a list of defocus distance (in Angstrom).\n",
    "        Computes intensity phase contrast image after electron scatters through the sample using multislice algorithm\n",
    "        Required Args:\n",
    "                shape: shape of the object in [z, y, x]\n",
    "                voxel_size: size of voxel in [z, y, x]\n",
    "                wavelength: wavelength of probing wave, scalar\n",
    "\n",
    "        Optional Args [default]:\n",
    "                sigma: sigma used in calculating transmittance function (exp(1i * sigma * object)), scalar [None]\n",
    "                binning_factor: bins the number of slices together to save computation (loses accuracy), scalar [1]\n",
    "                pad_size: padding reconstruction from measurements in [dy,dx], final size will be measurement.shape + 2*[dy, dx], [0, 0]\n",
    "        \"\"\"\n",
    "        super(PhaseContrastScattering, self).__init__()\n",
    "        self.s_meta = s_meta\n",
    "        self.binning_factor = binning_factor\n",
    "        self.shape = shape\n",
    "        self.pad_size = pad_size\n",
    "        self.voxel_size = voxel_size\n",
    "        self.wavelength = wavelength\n",
    "\n",
    "        # forward propagation\n",
    "        self.shape_prop = self.shape.copy()\n",
    "        self.shape_prop[0] //= self.binning_factor\n",
    "        self.voxel_size_prop = self.voxel_size.copy()\n",
    "        self.voxel_size_prop[0] *= self.binning_factor\n",
    "        self._propagation = MultislicePropagation(self.shape_prop, self.voxel_size_prop, self.wavelength, **kwargs)\n",
    "\n",
    "        self.sigma = sigma\n",
    "        if self.sigma is None:\n",
    "            self.sigma = (2 * np.pi / self.wavelength) * \\\n",
    "                          self.voxel_size_prop[0]\n",
    "\n",
    "        # filter with aperture\n",
    "        self._pupil = Pupil(self.shape[1:], self.voxel_size[0], self.wavelength, **kwargs)\n",
    "\n",
    "        # defocus operator\n",
    "        self._defocus = Defocus(**kwargs)\n",
    "\n",
    "        # shift correction\n",
    "        self._shift = ImageShiftGradientBased(self.shape[1:], **kwargs)\n",
    "\n",
    "    def forward(self, obj, defocus_list, field_in, yx_shift=None):\n",
    "        # bin object\n",
    "        obj = bin_obj(obj, self.binning_factor)\n",
    "        # raise to transmittance\n",
    "        obj = torch.exp(1j * self.sigma * obj)\n",
    "        # forward propagation & defocus add field_in\n",
    "        field = self._propagation(obj, field_in)\n",
    "        # pupil\n",
    "        # field = self._pupil(field)\n",
    "        # defocus\n",
    "        # field = self._defocus(field, self._propagation.propagate.kernel_phase, defocus_list)\n",
    "        # # shift\n",
    "        # field = self._shift(field, yx_shift)\n",
    "        # # crop\n",
    "        # field = F.pad(field, (0, 0, \\\n",
    "        #                       -1 * self.pad_size[1], -1 * self.pad_size[1], \\\n",
    "        #                                           -1 * self.pad_size[0], -1 * self.pad_size[0]))\n",
    "        # compute amplitude\n",
    "        # amplitudes = complex_abs(field)\n",
    "\n",
    "        return field"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
