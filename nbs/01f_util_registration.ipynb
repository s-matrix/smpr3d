{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util io\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage import transform\n",
    "from pystackreg import StackReg\n",
    "\n",
    "class ImageTransformOpticalFlow():\n",
    "    \"\"\"\n",
    "    Class written to register stack of images for AET.\n",
    "    Uses correlation based method to determine subpixel shift between predicted and measured images.\n",
    "    Input parameters:\n",
    "        - shape: shape of the image\n",
    "    \"\"\" \n",
    "    def __init__(self, shape, method=\"turboreg\"):\n",
    "        self.shape = shape\n",
    "        self.x_lin, self.y_lin = np.meshgrid(np.arange(self.shape[1]), np.arange(self.shape[0]))\n",
    "        self.xy_lin = np.concatenate((self.x_lin[np.newaxis,], self.y_lin[np.newaxis,])).astype('float32')\n",
    "        self.sr = StackReg(StackReg.RIGID_BODY)\n",
    "\n",
    "    def _estimate_single(self, predicted, measured):\n",
    "        assert predicted.shape == self.shape\n",
    "        assert measured.shape == self.shape\n",
    "        aff_mat = self.sr.register(measured, predicted)\n",
    "        tform = transform.AffineTransform(matrix = aff_mat)\n",
    "        measured_warp = transform.warp(measured, tform.inverse, cval = 1.0, order = 5)\n",
    "        transform_final = aff_mat.flatten()[0:6]\n",
    "        return measured_warp, transform_final\n",
    "\n",
    "    def estimate(self, predicted_stack, measured_stack):\n",
    "        assert predicted_stack.shape == measured_stack.shape\n",
    "        transform_vec_list = np.zeros((6,measured_stack.shape[2]), dtype=\"float32\")\n",
    "\n",
    "        #Change from torch array to numpy array\n",
    "        flag_predicted_gpu = predicted_stack.is_cuda\n",
    "        if flag_predicted_gpu:\n",
    "            predicted_stack = predicted_stack.cpu()\n",
    "\n",
    "        flag_measured_gpu = measured_stack.is_cuda\n",
    "        if flag_measured_gpu:\n",
    "            measured_stack = measured_stack.cpu()        \n",
    "        \n",
    "        predicted_np = np.array(predicted_stack.detach())\n",
    "        measured_np  = np.array(measured_stack.detach())\n",
    "        \n",
    "        #For each image, estimate the affine transform error\n",
    "        for img_idx in range(measured_np.shape[2]):\n",
    "            measured_np[...,img_idx], transform_vec = self._estimate_single(predicted_np[...,img_idx], \\\n",
    "                                                                      measured_np[...,img_idx])\n",
    "            transform_vec_list[...,img_idx] = transform_vec\n",
    "        \n",
    "        #Change data back to torch tensor format\n",
    "        if flag_predicted_gpu:\n",
    "            predicted_stack = predicted_stack.cuda()\n",
    "\n",
    "        measured_np = torch.tensor(measured_np)\n",
    "        if flag_measured_gpu:\n",
    "            measured_stack  = measured_stack.cuda()        \n",
    "            measured_np     = measured_np.cuda()\n",
    "\n",
    "        return measured_np, torch.tensor(transform_vec_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
